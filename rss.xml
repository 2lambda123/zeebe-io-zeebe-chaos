<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Zeebe Chaos Blog</title>
        <link>https://zeebe-io.github.io/zeebe-chaos/</link>
        <description>Zeebe Chaos Blog</description>
        <lastBuildDate>Wed, 06 Dec 2023 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Job push resiliency]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency</guid>
            <pubDate>Wed, 06 Dec 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[In today's chaos day we experimented with job push resiliency.]]></description>
            <content:encoded><![CDATA[<p>In today's chaos day we experimented with job push resiliency.</p>
<p>The following experiments we have done today:</p>
<ol>
<li>Job streams should be resilient to gateway restarts/crash</li>
<li>Job streams should be resilient to leadership changes/leader restarts</li>
<li>Job streams should be resilient to cluster restarts</li>
</ol>
<p><strong>TL;DR;</strong> All experiments succeeded and showcased the resiliency even on component restarts. <!-- -->🚀</p>
<p>To reduce the blast radius and to better verify that everything works as expected we use a trimmed version of our benchmark setup. This means three brokers, one partition, replication factor three, and one gateway. No starter deployed. We deployed one worker with a very high polling interval, to make sure that we rely on streaming.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="gateway-restarts">Gateway restarts<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#gateway-restarts" class="hash-link" aria-label="Direct link to Gateway restarts" title="Direct link to Gateway restarts">​</a></h2>
<p>In our first experiment, we wanted to verify that: Job streaming should be resilient to gateway restarts/crashes.</p>
<p>The experiment will look like the following:</p>
<ul>
<li>Verify steady state:<!-- -->
<ul>
<li>Cluster is healthy</li>
<li>When creating an instance, and start streaming we can retrieve and complete the corresponding job</li>
</ul>
</li>
<li>Chaos injection:<!-- -->
<ul>
<li>Restarting the gateway</li>
</ul>
</li>
<li>Verify steady state:<!-- -->
<ul>
<li>Cluster is healthy</li>
<li>When creating an instance, and start streaming we can retrieve and complete the corresponding job</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>We expect that even after a gateway restart we can retrieve a job (the stream should be recreated) and complete our new instance.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<p>We deployed the worker (with a replica of one), and configured it with a high polling interval <code>-Dapp.worker.pollingDelay=24h</code>.</p>
<p>To run any instances we need to deploy once the benchmark process model</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">zbchaos deploy process</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Deployed given process model , under key 2251799813685249!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="verify-steady-state">Verify steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#verify-steady-state" class="hash-link" aria-label="Direct link to Verify steady state" title="Direct link to Verify steady state">​</a></h4>
<p>We verify the readiness and the instance creation.</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify readiness</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify instance-creation --awaitResult --verbose</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Flags: {1 LEADER -1  10  msg true 1 LEADER -1 2 LEADER -1 1701853048870 false false true false false 30 false -1 benchmark 30   1 1 benchmark-task}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connecting to ck-np-chaos-day-job-push</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Running experiment in self-managed environment.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Port forward to ck-np-chaos-day-job-push-zeebe-gateway-68695d9cb5-lhgg5</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Successfully created port forwarding tunnel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">We await the result of the process instance creation, thus we skip the partition id check.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Send create process instance command, with BPMN process ID 'benchmark' and version '-1' (-1 means latest) [variables: '', awaitResult: true]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Created process instance with key 2251799813685251 on partition 1, required partition 0.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="injecting-chaos">Injecting chaos<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#injecting-chaos" class="hash-link" aria-label="Direct link to Injecting chaos" title="Direct link to Injecting chaos">​</a></h4>
<p>Next, we will restart the gateway.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos restart gateway --verbose</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Flags: {1 LEADER -1  10  msg false 1 LEADER -1 2 LEADER -1 1701853221588 false false true false false 30 false -1 benchmark 30   1 1 benchmark-task}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connecting to ck-np-chaos-day-job-push</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Running experiment in self-managed environment.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Restarted ck-np-chaos-day-job-push-zeebe-gateway-68695d9cb5-lhgg5</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="verify-steady-state-1">Verify steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#verify-steady-state-1" class="hash-link" aria-label="Direct link to Verify steady state" title="Direct link to Verify steady state">​</a></h4>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify readiness</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify instance-creation --awaitResult</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">​</a></h3>
<p>The experiment succeeded. We were able to verify the steady state after the chaos injection. Furthermore, we observe in the metrics as well that the jobs have been pushed after the gateway restart. <!-- -->✅</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/job-push-gw-restart-16711afa005a27b6101bbd940f6f1489.png" width="939" height="667" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="with-termination">With termination<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#with-termination" class="hash-link" aria-label="Direct link to With termination" title="Direct link to With termination">​</a></h3>
<p>We wanted to verify the same by terminating the gateway instead of a graceful shutdown (which is done within the restart command).</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos terminate gateway --verbose</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Flags: {1 LEADER -1  10  msg false 1 LEADER -1 2 LEADER -1 1701853482263 false false true false false 30 false -1 benchmark 30   1 1 benchmark-task}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connecting to ck-np-chaos-day-job-push</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Running experiment in self-managed environment.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Terminated ck-np-chaos-day-job-push-zeebe-gateway-68695d9cb5-jqfzg</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Verifying the steady stated again showed no unexpected issues.</p>
<p>Out of interest we checked what is happening in worker:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">09:05:44.047 [pool-5-thread-3] WARN  io.camunda.zeebe.client.job.worker - Failed to stream jobs of type 'benchmark-task' to worker 'benchmark-worker'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">io.grpc.StatusRuntimeException: UNAVAILABLE: io exception</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We see as expected several <code>UNAVAILABLE: io exception</code> and later the worker recovered.</p>
<p>Based on the metrics we can observe the same. Jobs are pushed to the workers even after restarting the gateway.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/job-push-gw-terminate-0600fa2a9e4d0c5696531dc2da3bf391.png" width="941" height="658" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="leader-restart">Leader restart<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#leader-restart" class="hash-link" aria-label="Direct link to Leader restart" title="Direct link to Leader restart">​</a></h2>
<p>In this experiment, we want to verify how resilient job push is on leader changes/restarts.</p>
<p>The verification of the steady state is the same as above, so I will skip this description here.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-1">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#expected-1" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>Workers shouldn't care about leader change, this should be handled fully by the gateway.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-1">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#actual-1" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="verify-steady-state-2">Verify steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#verify-steady-state-2" class="hash-link" aria-label="Direct link to Verify steady state" title="Direct link to Verify steady state">​</a></h4>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify readiness</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify instance-creation --awaitResult</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="inject-chaos">Inject chaos<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#inject-chaos" class="hash-link" aria-label="Direct link to Inject chaos" title="Direct link to Inject chaos">​</a></h4>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos restart broker --partitionId 1 --role LEADER</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Restarted ck-np-chaos-day-job-push-zeebe-0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="verify-steady-state-3">Verify steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#verify-steady-state-3" class="hash-link" aria-label="Direct link to Verify steady state" title="Direct link to Verify steady state">​</a></h4>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify readiness</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify instance-creation --awaitResult</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="result-1">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#result-1" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">​</a></h3>
<p>We were able to verify that a leader restart doesn't cause issues and job push can handle such events.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/job-push-leader-restart-6e33baa1365cba88fc41cc9bbe92442b.png" width="926" height="866" class="img_ev3q"></p>
<p>We can see that the leader was changed, and also switched back shortly after.
<img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/leaderchanges-2760fa1660e1759211f9b7c3351b0ab7.png" width="475" height="311" class="img_ev3q"></p>
<p>This is caused by our leader-balancing cron job.
<img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/job-push-leader-restart-cronjob-fed9e516c29fde4f814cdfcb68e3f4c2.png" width="1799" height="421" class="img_ev3q"></p>
<p>This also means we had two leader changes, and the push was even pushed by the restarted node.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="complete-cluster-restart">Complete cluster restart<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#complete-cluster-restart" class="hash-link" aria-label="Direct link to Complete cluster restart" title="Direct link to Complete cluster restart">​</a></h2>
<p>In this experiment, we wanted to verify whether job push can also handle a complete cluster restart.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-2">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#expected-2" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>Job push can handle a cluster restart and a corresponding job is pushed to the worker afterwards.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-2">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#actual-2" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="verify-steady-state-4">Verify steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#verify-steady-state-4" class="hash-link" aria-label="Direct link to Verify steady state" title="Direct link to Verify steady state">​</a></h4>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">❯ zbchaos verify readiness</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">❯ zbchaos verify instance-creation --awaitResult</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="inject-chaos-1">Inject chaos<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#inject-chaos-1" class="hash-link" aria-label="Direct link to Inject chaos" title="Direct link to Inject chaos">​</a></h4>
<p>Right now <code>zbchaos</code> doesn't support restarting a complete cluster, so we had to fall back to <code>kubectl</code>.</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ kubectl delete pod -l=app=camunda-platform</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "ck-np-chaos-day-job-push-zeebe-0" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "ck-np-chaos-day-job-push-zeebe-1" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "ck-np-chaos-day-job-push-zeebe-2" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "ck-np-chaos-day-job-push-zeebe-gateway-68695d9cb5-hj2pf" deleted</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="verify-steady-state-5">Verify steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#verify-steady-state-5" class="hash-link" aria-label="Direct link to Verify steady state" title="Direct link to Verify steady state">​</a></h4>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify readiness</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify instance-creation --awaitResult</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Failed to retrieve SaaS CRD, fallback to self-managed mode. the server could not find the requested resource</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="result-2">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#result-2" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">​</a></h3>
<p>Again we were able to show that job push is resilient, and can even handle a complete cluster restart.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/job-push-cluster-restart-69a928cd76f5613126f41c66f5fd7644.png" width="930" height="677" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="found-bugs">Found Bugs<a href="https://zeebe-io.github.io/zeebe-chaos/2023/12/06/Job-Push-resiliency#found-bugs" class="hash-link" aria-label="Direct link to Found Bugs" title="Direct link to Found Bugs">​</a></h2>
<ul>
<li>On restart (especially on cluster restart) it looks like job push engine metrics are counted multiple times</li>
<li><a href="https://github.com/camunda/zeebe/blob/a86decce9a46218798663e3466267a49adef506e/transport/src/main/java/io/camunda/zeebe/transport/stream/impl/RemoteStreamPusher.java#L55-L56C14" target="_blank" rel="noopener noreferrer">We found a place where we should better handle the exception in pushing async.</a></li>
</ul>]]></content:encoded>
            <category>availability</category>
            <category>resiliency</category>
        </item>
        <item>
            <title><![CDATA[Job push overloading]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading</guid>
            <pubDate>Thu, 30 Nov 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[In today's chaos day we (Nicolas and I) want to verify how job push behaves and in general, the Zeebe system when we have slow workers.]]></description>
            <content:encoded><![CDATA[<p>In today's chaos day we (Nicolas and I) want to verify how job push behaves and in general, the Zeebe system when we have slow workers.</p>
<p><strong>TL;DR;</strong> Right now it seems that even if we have a slow worker it doesn't impact the general system, and only affects the corresponding process instance, not other instances. We found no unexpected issues, everything performed pretty well.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">​</a></h2>
<p>Firstly we want to verify that job push will not overload a worker or gateway when workers are slow.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>We expect that if the workers are slowing down, the load is distributed to other workers (if available), and it is expected that the general performance (of the affected process instance) should be slowed down. We wouldn't expect any restarts/failures on the gateway or workers.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<p>We deployed a normal benchmark, with <a href="https://github.com/camunda/zeebe/blob/main/benchmarks/setup/default/values.yaml" target="_blank" rel="noopener noreferrer">default configurations</a>.</p>
<p>We slowed the workers down, in the sense that we changed <a href="https://github.com/zeebe-io/benchmark-helm/blob/main/charts/zeebe-benchmark/templates/worker.yaml#L30" target="_blank" rel="noopener noreferrer">the completionDelay to 1250 ms</a></p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp1-general-de6a6f7f1d6b52ae218f3c55ae8b33ce.png" width="1249" height="654" class="img_ev3q"></p>
<p>The throughput is lower than normal, as expected.</p>
<p>We see no significant increase in memory usage on the gateway, nor any outages because of this.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp1-gw-memory-220a9ab49a649d351bb58040bde2c4a0.png" width="628" height="307" class="img_ev3q"></p>
<p>We see that a high amount of job pushes fail (due to capacity constraints now in the workers).
!Jobs are yielded back to the engine.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp1-records-26fd0549438faf9475280e80678bc2ce.png" width="1249" height="344" class="img_ev3q"></p>
<p>So far so good, first experiment worked as expected <!-- -->✅</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="second-chaos-experiment">Second Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#second-chaos-experiment" class="hash-link" aria-label="Direct link to Second Chaos Experiment" title="Direct link to Second Chaos Experiment">​</a></h2>
<p>The normal scenario when something is slow is for a user to scale up. This is what we did in the next experiment, we scaled the workers to 10 replicas (from 3), to verify how the system behaves in this case.</p>
<p>Something to keep in mind when the completion delay is 1250ms, we <a href="https://github.com/camunda/zeebe/blob/7002d53a079c06ab3a94f5485f022681a41dc9ed/benchmarks/project/src/main/java/io/camunda/zeebe/Worker.java#L113" target="_blank" rel="noopener noreferrer">multiply the activation timeout by 6 in our workers</a>. This means completionDelay: 1250 -&gt; job timeout 7.5s</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-1">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#expected-1" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>We expect that we can reach a higher throughput.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-1">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#actual-1" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<p>Scaling the workers to 10:</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">k scale deployment worker --replicas=10</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp2-general-fcdc544e61dee39561dd634ff2259c8e.png" width="1240" height="647" class="img_ev3q"></p>
<p>We can see that after scaling we can complete more jobs.</p>
<p>The gateway memory seems to be not really affected.
<img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp2-gw-mem-1c710a1cc021fd9a369efee7871a6eef.png" width="633" height="307" class="img_ev3q"></p>
<p>In the job push metrics we see less job push failures.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp2-job-push-56d12fe3469c8287fdc4b6fca3d7175f.png" width="1247" height="638" class="img_ev3q"></p>
<p>When we check the written records we can see a decrease in yield, but an increase in timeouts. The reason is that we have to try several workers before giving it back.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp2-records-37ead57c1e5b9bf03bb812ee7d58abf0.png" width="1254" height="342" class="img_ev3q">
<img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp2-records2-b3733ab69b894a659d211e164c939e9e.png" width="1244" height="344" class="img_ev3q"></p>
<p>Experiment two worked as expected. <!-- -->✅</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="third-chaos-experiment">Third Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#third-chaos-experiment" class="hash-link" aria-label="Direct link to Third Chaos Experiment" title="Direct link to Third Chaos Experiment">​</a></h2>
<p>In a real-world scenario, it will not happen if you have a slow dependency, for which for example a worker waits that you can scale and this will solve your problems. Likely you will get even slower because more pressure is put on the dependency. To mimic this scenario we experimented with increasing the completion time again. A completion delay set to 2500ms, means a job timeout of 15s.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-2">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#expected-2" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>We expect after slowing down all workers again, that our throughput goes down again, but we should see no general error. Potentially a slight memory increase because of buffering of jobs.</p>
<p>This also means more yields and fewer timeouts.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-2">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#actual-2" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<p>As expected again we see a drop in throughput, but it is still a bit higher than at the first experiment.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp3-general-88403398292f5c5cdbac3a1b9b8ee63d.png" width="1253" height="648" class="img_ev3q"></p>
<p>No difference at all in the memory consumption, by the gateway.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp3-memory-769d10a88790ea58ca00a995effcfa7c.png" width="628" height="306" class="img_ev3q"></p>
<p>In the records we can also again see that yield increase, and timeouts have been decreased.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp3-records-bf6c88f09631f951d4d272c346ee7768.png" width="1257" height="686" class="img_ev3q"></p>
<p>Experiment three worked as expected. <!-- -->✅</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="several-further-experiments">Several further experiments<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#several-further-experiments" class="hash-link" aria-label="Direct link to Several further experiments" title="Direct link to Several further experiments">​</a></h2>
<p>We did several further experiments where we scaled the workers, played with the completion delay, reduced the starter load etc. At some point, we reached a state size that was too big (~2 Gig) such that this impacted our processing. We had to drain the cluster and stop the starters completely.</p>
<p>Interestingly was that when we reduced the completion delay, we just had a slight increase in completion, when we scaled down the workers (marked with the annotation in the graph), to reduce activations, we saw no difference.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp6-general-f35222d6e1d66526ef6eb07c53f10923.png" width="1258" height="646" class="img_ev3q"></p>
<p>Only when we hit a certain threshold in RocksDb (it seems to be at least), the completion went up by a lot.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp6-state-f33212be78503a223b0741b9d7a340e1.png" width="615" height="304" class="img_ev3q"></p>
<p>This is because the record processing latency was heavily reduced (likely the commit latency or iteration latency in RocksDb).</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp6-latency-0b30edf17db48cf5d056bafe677cced4.png" width="1259" height="276" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="experiment-with-worker-impact">Experiment with worker impact<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#experiment-with-worker-impact" class="hash-link" aria-label="Direct link to Experiment with worker impact" title="Direct link to Experiment with worker impact">​</a></h2>
<p>We wanted to understand and experiment with the impact of a slow worker on different process instances.</p>
<p>To see such an impact in our metrics we had to patch our current execution metrics, such that includes the BPMN processId, so we can differentiate between execution times of different processes.</p>
<p>See the related branch for more details <a href="https://github.com/camunda/zeebe/tree/ck-latency-metrics" target="_blank" rel="noopener noreferrer">ck-latency-metrics</a></p>
<p>Furthermore, a new process model was added <code>slow-task.bpm</code> and new deployments to create such instances and work on them. The process model was similar to the benchmark model, only the job type has been changed.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-3">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#expected-3" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>To verify was that whether a slow worker would impact other instances, this was uncertain territory we were hitting.</p>
<p>To be honest we expected it would affect them.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-3">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#actual-3" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<p>We started the benchmark (default configs for broker and gateway), with additional configurations:</p>
<ul>
<li>benchmark starter with 75 PI/s rate</li>
<li>3 benchmark worker (60 capacity) and completion delay of 50 ms</li>
<li>slow-task starter with 75 PI/s rate</li>
<li>3 slow-worker (60 capacity) and a completion delay of 50 ms (at the begin)</li>
</ul>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/slow-exp-base-ea8adfd10aa658d81ca76a4c342f5df7.png" width="2539" height="871" class="img_ev3q"></p>
<p>We can see based on the metrics that the execution latency is the same for both process instances, and we are able to complete our 150 PI/s.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/slow-exp-base-general-25e62c9332f1ecad2df0cb8253bb188d.png" width="1894" height="644" class="img_ev3q"></p>
<p>We slowed now the worker for the type <code>slow-task</code> down to a completion delay of 2500ms.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/slow-exp-slow-worker-2500ms-records-388a523821cc584224d95d43b30c8c6d.png" width="1694" height="682" class="img_ev3q"></p>
<p>We can see that we start to get <code>Job.YIELD</code> commands from the gateway, and we can see that the process instance execution is slowed down.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/slow-exp-slow-worker-2500ms-9c93bc66fc1f410535f45a170ba6b96a.png" width="2544" height="875" class="img_ev3q"></p>
<p>Interestingly that is only for the affected process instance, which we wanted to validate/verify.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="reasoning">Reasoning<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#reasoning" class="hash-link" aria-label="Direct link to Reasoning" title="Direct link to Reasoning">​</a></h3>
<p>Our first assumption was that both instance latencies would be impacted, because are writing YIELD commands, instead of being able to complete them.</p>
<p>But another consequence comes into play. If fewer jobs are worked on, there are also fewer jobs completed, this means fewer process instances have to be continued (with batch processing until the end).</p>
<p>This means a load of yield underweights the normal load of job completions, with additional process instance continuation. That was an interesting insight for us.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/30/Job-push-overloading#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">​</a></h2>
<p>Right now it seems that even if we have a slow worker it doesn't impact badly the general system, and only affects the corresponding process instance, not other instances.</p>
<p>What we should or need to investigate further what if the job completion delay is much larger than the timeout. This is something we might want to test soon.</p>]]></content:encoded>
            <category>availability</category>
        </item>
        <item>
            <title><![CDATA[Hot backups impact on processing]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing</guid>
            <pubDate>Tue, 07 Nov 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[Today, we want to experiment with hot backups in SaaS and a larger runtime state in Zeebe and how it impacts the ongoing processing in Zeebe (or not?). This is part of the investigation of a recently created bug issue we wanted to verify/reproduce #14696.]]></description>
            <content:encoded><![CDATA[<p>Today, we want to experiment with hot backups in SaaS and a larger runtime state in Zeebe and how it impacts the ongoing processing in Zeebe (or not?). This is part of the investigation of a recently created bug issue we wanted to verify/reproduce <a href="https://github.com/camunda/zeebe/issues/14696" target="_blank" rel="noopener noreferrer">#14696</a>.</p>
<p><strong>TL;DR;</strong> We were able to prove that hot backups are indeed not impacting overall processing throughput in Zeebe. We found that having a full Elasticsearch disk might impact or even fail your backups, which is intransparent to the user.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">​</a></h2>
<p>For the experiment, we have set up a Camunda SaaS cluster (G3-M configuration), and run the <a href="https://github.com/camunda/zeebe/tree/main/benchmarks/setup/cloud-default" target="_blank" rel="noopener noreferrer">cloud benchmark</a> workload against it. During the experiment, we will run a stable load, which will cause to increase in the runtime state. We will create/initiate in different stages backups to verify the impact on processing depending on state size.</p>
<p>We kept the starter rate (creation of process instance 100 PI/s) but reduced the worker capacity and replicas.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>Hot backups were built with the premise of not disrupting the processing throughput in Zeebe, which is why we define the following hypothesis:</p>
<blockquote>
<p><strong>Hypothesis</strong></p>
<p>Creating hot backups should not impact Zeebe's <em>processing throughput <em>no</em> matter how</em> large the runtime state is in Zeebe.</p>
</blockquote>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<p>We created a cluster in the Camunda SaaS environment (in our internal stage).</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="step-one">Step one<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#step-one" class="hash-link" aria-label="Direct link to Step one" title="Direct link to Step one">​</a></h4>
<p>We created a first backup to verify that it works without issues.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">​</a></h5>
<p>Success on stage one creating a backup with no actual state.</p>
<p><img loading="lazy" alt="first-backup" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/first-backup-5d70b491b31ac0fd1eb11d052277570c.png" width="1890" height="683" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="step-two">Step two<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#step-two" class="hash-link" aria-label="Direct link to Step two" title="Direct link to Step two">​</a></h4>
<p>We started a stable load as mentioned <a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#chaos-experiment">above</a>. After reaching around ~100 MB runtime state at each partition we triggered a backup.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="result-1">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#result-1" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">​</a></h5>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/general-sec-bk-c0c03a786b5e701fd6ccc9bd75f9bd78.png" width="1887" height="498" class="img_ev3q"></p>
<p>The backup was successful and we were not able to observe any disruption in the processing throughput. We can see that during the backup is taken the exporting is paused (which is expected) and afterwards it is starting to export again. <!-- -->✅</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="step-three">Step three<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#step-three" class="hash-link" aria-label="Direct link to Step three" title="Direct link to Step three">​</a></h4>
<p>At a later stage, we tried to take a backup again with around ~300MB of runtime state in Zeebe.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="result-2">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#result-2" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">​</a></h5>
<p>Based on the output from Console the backup was successful and took around one hour.</p>
<p><img loading="lazy" alt="third-console" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/sec-bk-console-8af4a5c33d75d3628548f9d7b21c4a66.png" width="1364" height="276" class="img_ev3q"></p>
<p>Based on our internal metrics we can also see that there is no impact on the processing throughput</p>
<p><img loading="lazy" alt="general-third" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/general-third-bk-3ac8aaa53e75ac20345f7ab64c6a27e3.png" width="1888" height="688" class="img_ev3q"></p>
<p>What is unclear to me is that it looks like we only took a backup of partition two. This needs to be further investigated, it might be also that the metrics are just confusing since it is resetting after the pod restarts.<!-- -->🐛</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="step-four">Step four<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#step-four" class="hash-link" aria-label="Direct link to Step four" title="Direct link to Step four">​</a></h4>
<p>Here we come into struggle after running the load on the cluster for quite some time we reached a runtime state size of ~1 gig. Furthermore, we filled our Elasticsearch disk tremendously.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="result-3">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#result-3" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">​</a></h5>
<p>At this time we were no longer able to successfully create backups. Here I tried it first without interacting with the cluster. It failed after 1.5 hours, which is potentially the timeout.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/third-bk-console-8c301c13085c61e11b5d5cafc6e245bb.png" width="1833" height="271" class="img_ev3q"></p>
<p>The backup failed, because of elastic was full.</p>
<p><img loading="lazy" alt="elastic-full" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/deleting-indices4-c2d15986b9499ae4ac28f1c264b1709e.png" width="1889" height="369" class="img_ev3q"></p>
<p>I went ahead to remove some data from Elastic to keep experimenting.</p>
<p><img loading="lazy" alt="elastic-indices" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/deleting-indices3-2051dac5d38acbe4b05b930e152283e7.png" width="1240" height="321" class="img_ev3q">
<img loading="lazy" alt="delete-indices" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/deleting-indices2-c6c439bda96f933647a197156063af9e.png" width="1260" height="407" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="step-five">Step five<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#step-five" class="hash-link" aria-label="Direct link to Step five" title="Direct link to Step five">​</a></h4>
<p>After cleaning the Elasticsearch we retried taking a backup again. At this step, we already reached a runtime state of ~1.25G for each partition, which is quite huge.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="result-4">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#result-4" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">​</a></h5>
<p>The backup took quite a while and failed again.</p>
<p><img loading="lazy" alt="last-bk" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/last-bk-failed-ec7ad090bc219c0a563e44cc123b3942.png" width="1814" height="398" class="img_ev3q"></p>
<p>What we can see based on the times it is likely that it here timed out again. Taking a look at the metrics we see that a backup was processed in Zeebe.</p>
<p>It had no impact on the ongoing processing throughput.</p>
<p><img loading="lazy" alt="fifth-bk" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/general-fifth-bk-162b830758b48c2b2a2d4359960c40e8.png" width="1895" height="685" class="img_ev3q"></p>
<p>At a later stage, we tried another backup with ~1.45G of runtime state even here we were not able to observe any issues related to the impact on processing throughput.</p>
<p><img loading="lazy" alt="sixth" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/general-sixth-bk-8c901d74d9665263b9436406aaeac29d.png" width="1890" height="688" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h3>
<p>✅<!-- --> We were able to prove that even on a large runtime state there is no observable impact on processing throughput in Zeebe.</p>
<p>Furthermore, we have seen that having a large Elastic state (almost full disk) will impact taking backups and is likely to fail them. We might need to iterate here, whether we want to tune the backup strategy, give elastic more space when taking backups, or adjust watermarks, etc.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="follow-ups">Follow-ups<a href="https://zeebe-io.github.io/zeebe-chaos/2023/11/07/Hot-backups-impact-on-processing#follow-ups" class="hash-link" aria-label="Direct link to Follow-ups" title="Direct link to Follow-ups">​</a></h4>
<p>We have to investigate the marking of failed backups, whether it is because of a timeout in the Operator or whether these backups are failed. It looks to me like they are marked as failed, even if they may succeed.</p>
<p>Furthermore, the completed backups seem to be misleading and are reset which causes inconsistent views.</p>]]></content:encoded>
            <category>availability</category>
        </item>
        <item>
            <title><![CDATA[Using Large Multi-Instance]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance</guid>
            <pubDate>Fri, 02 Jun 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[New day new chaos. In today's chaos day I want to pick up a topic, which had bothered people for long time. I created a chaos day three years ago around this topic as well.]]></description>
            <content:encoded><![CDATA[<p>New day new chaos. <!-- -->💀<!-- --> In today's chaos day I want to pick up a topic, which had bothered people for long time. I created a <a href="https://zeebe-io.github.io/zeebe-chaos/2020/07/16/big-multi-instance/" target="_blank" rel="noopener noreferrer">chaos day three years ago</a> around this topic as well.</p>
<p>Today, we experiment with large multi-instances again. In the recent patch release <a href="https://github.com/camunda/zeebe/releases/tag/8.2.5" target="_blank" rel="noopener noreferrer">8.2.5</a> we fixed an issue with spawning larger multi instances. Previously if you have created a process instance with a large multi-instance it was likely that this caused to blacklist the process instance, since the multi-instance spawning ran into <code>maxMessageSize</code> limitations.</p>
<p>This means the process instance was stuck and was no longer executable. In Operate this was not shown and caused a lot of friction or confusion to users. With the recent fix, Zeebe should chunk even large collections into smaller batches to spawn/execute the multi-instance without any issues.</p>
<p><strong>TL;DR;</strong> We were able to see that even large multi-instances can be executed now. <!-- -->✅<!-- --> At some point, we experienced performance regressions (during creating new multi-instance elements) but the execution of the process instance doesn't fail anymore. One problem at a time, we will likely investigate further to improve the performance of such a use case.</p>
<p>When we reached the <code>maxMessageSize</code> we got a rejection, if the input collection is too large we see some weird unexpected errors from NGINX.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">​</a></h2>
<p>We do regularly game days in Camunda, and for such we also create projects to make incidents, etc. reproducible. In today's chaos day, I will reuse some code created by <a href="https://github.com/saig0" target="_blank" rel="noopener noreferrer">Philipp Ossler</a>, thanks for that :bow: Since we mimic in such game days customers, the process is a bit more complex than necessary for such chaos day, but I will keep it like that.</p>
<p><img loading="lazy" alt="order-process" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/order-process-0eb9e9dc5b698919f847deb859f67f2d.png" width="3213" height="1152" class="img_ev3q"></p>
<p>The input collection <code>items</code>, which is used in the multi-instance is generated via:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">    // input size</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    final var items = IntStream.range(0, size).mapToObj(i -&gt; Map.ofEntries(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        entry("id", i)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    )).toList();</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>In the following experiment, we will play around with the <code>size</code> value.</p>
<p>For the experiment, we will use a Camunda 8 SaaS cluster with the generation <code>Zeebe 8.2.5</code> (G3-S).</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>When creating a process instance with a large collection, we expect based on the recent bug fix that the multi-instance creation is batched and created without issues.</p>
<p>One limiting factor might be the <code>maxMessageSize</code> with regard to the input collection, but in this case, I would expect that the creation of the process instance is already rejected before.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<p>Between the following experiments, I always recreated the clusters, to reduce the blast radius and better understand and isolate the impact.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="starting-small-20k">Starting small (20k)<a href="https://zeebe-io.github.io/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance#starting-small-20k" class="hash-link" aria-label="Direct link to Starting small (20k)" title="Direct link to Starting small (20k)">​</a></h4>
<p>In previous versions, the multi-instance creation failed already quite early. For example in the game day reproducer project, we had a collection defined with <code>20.000</code> items, which we are now reusing for the start.</p>
<p>The creation of the process instance worked without any issues. We can observe in Operate the incremental creation of sub-process instances, which is great.</p>
<p><img loading="lazy" alt="incremental-creation-20k" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/20k-operate-inc-b0e507b77799c7f950ff444259c8341f.png" width="1757" height="868" class="img_ev3q"></p>
<p>We can see in the metrics that batch processing is limited by only 2-4 commands in a batch. That is an interesting fact that might explain why it takes a while until all instances of the multi-instance sub-process are created. We can even see rollbacks during batch processing, visible in the "Number of batch processing retries" panel.</p>
<p><img loading="lazy" alt="processing-metrics-20k" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/20k-processing-metrics-f3f057027ec451f9024d242df2d1bef6.png" width="1894" height="755" class="img_ev3q"></p>
<p>The processing queue seems to increase dramatically.</p>
<p>After a while, we can see that all 20k instances are created without any bigger issues. <!-- -->🚀</p>
<p><img loading="lazy" alt="complete-20k" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/20k-operate-complete-31c5d2b848c51c7b1a96e8dc6f23b5d6.png" width="1912" height="834" class="img_ev3q"></p>
<p>It took around 10 minutes. Taking a look at the metrics again we see that in between big command batches have been created/processed, which allowed us to reduce the processing queue.</p>
<p><img loading="lazy" alt="processing-metrics-20k-pt2" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/20k-processing-metrics-2-7976048beb0f6300cf5577d40f2c9f47.png" width="1896" height="762" class="img_ev3q"></p>
<p>In between the backpressure was quite high, but after the creation of all instances, the cluster is in a healthy state again. The creation of such multi-instance worked <!-- -->✅</p>
<p><img loading="lazy" alt="general-metrics-20k" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/20k-general-metrics-a525d7f1500dac0fd03d460b849e12e4.png" width="1893" height="940" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="increase-collection-200k">Increase collection (200k)<a href="https://zeebe-io.github.io/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance#increase-collection-200k" class="hash-link" aria-label="Direct link to Increase collection (200k)" title="Direct link to Increase collection (200k)">​</a></h4>
<p>Again, the creation of such a process instance was not a problem itself. We can observe the creation of the sub-process instances (multi-instance) in Operate, which happens incrementally.</p>
<p><img loading="lazy" alt="incremental-creation-200k" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/200k-operate-inc-586ee3f6c124c92cc6700df1b6213950.png" width="1905" height="871" class="img_ev3q"></p>
<p>It takes ages until the instances are created (After 3h ~66k instances are created). Again we see here small chunks of batches, and there are also rollbacks during batch processing.</p>
<p><img loading="lazy" alt="processing-metrics-200k" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/200k-processing-metrics-7a21b4741eec54581b30f819b05f3de2.png" width="1881" height="753" class="img_ev3q"></p>
<p>The processing of that partitions is in this case blocked by the multi-instance creation, we can see that on the 100% back pressure. <!-- -->❌</p>
<p><img loading="lazy" alt="general-metrics-200k" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/200k-general-metrics-3975fc0c4c761c321194cd69598a8d11.png" width="1883" height="868" class="img_ev3q"></p>
<p>Even after one hour, not all instances are created (not even 20k), it takes longer than before the creation of 20.000 instances.</p>
<p><img loading="lazy" alt="incremental-creation-200k-part2" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/200k-operate-inc2-8e393502149c7dc21706229b02979515.png" width="2251" height="931" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="make-it-really-big-2-million">Make it really big (2 million)<a href="https://zeebe-io.github.io/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance#make-it-really-big-2-million" class="hash-link" aria-label="Direct link to Make it really big (2 million)" title="Direct link to Make it really big (2 million)">​</a></h4>
<p>To escalate this even more I increase the input collection again by a factor of 10 to 2 million.</p>
<p>After creation, I see as a response the following log message in my log:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Failed to create process instance of 'order-process'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">io.camunda.zeebe.client.api.command.ClientStatusException: HTTP status code 502</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">invalid content-type: text/html</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">headers: Metadata(:status=502,date=Fri, 02 Jun 2023 11:44:57 GMT,content-type=text/html,strict-transport-security=max-age=63072000; includeSubDomains,content-length=150)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">DATA-----------------------------</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;html&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;head&gt;&lt;title&gt;502 Bad Gateway&lt;/title&gt;&lt;/head&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;body&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;center&gt;&lt;h1&gt;502 Bad Gateway&lt;/h1&gt;&lt;/center&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/body&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/html&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.zeebe.client.impl.ZeebeClientFutureImpl.transformExecutionException(ZeebeClientFutureImpl.java:93) ~[zeebe-client-java-8.0.5.jar:8.0.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.zeebe.client.impl.ZeebeClientFutureImpl.join(ZeebeClientFutureImpl.java:50) ~[zeebe-client-java-8.0.5.jar:8.0.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.cloud.gameday.ProcessApplication.createProcessInstance(ProcessApplication.java:90) ~[classes/:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.cloud.gameday.ProcessApplication.createInstanceOfProcess(ProcessApplication.java:71) ~[classes/:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.cloud.gameday.ProcessApplication.run(ProcessApplication.java:58) ~[classes/:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at org.springframework.boot.SpringApplication.callRunner(SpringApplication.java:791) ~[spring-boot-2.5.2.jar:2.5.2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at org.springframework.boot.SpringApplication.callRunners(SpringApplication.java:775) ~[spring-boot-2.5.2.jar:2.5.2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at org.springframework.boot.SpringApplication.run(SpringApplication.java:345) ~[spring-boot-2.5.2.jar:2.5.2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1343) ~[spring-boot-2.5.2.jar:2.5.2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1332) ~[spring-boot-2.5.2.jar:2.5.2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.cloud.gameday.ProcessApplication.main(ProcessApplication.java:46) ~[classes/:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Caused by: java.util.concurrent.ExecutionException: io.grpc.StatusRuntimeException: UNAVAILABLE: HTTP status code 502</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">invalid content-type: text/html</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">headers: Metadata(:status=502,date=Fri, 02 Jun 2023 11:44:57 GMT,content-type=text/html,strict-transport-security=max-age=63072000; includeSubDomains,content-length=150)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">DATA-----------------------------</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;html&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;head&gt;&lt;title&gt;502 Bad Gateway&lt;/title&gt;&lt;/head&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;body&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;center&gt;&lt;h1&gt;502 Bad Gateway&lt;/h1&gt;&lt;/center&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/body&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/html&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396) ~[na:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073) ~[na:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.zeebe.client.impl.ZeebeClientFutureImpl.join(ZeebeClientFutureImpl.java:48) ~[zeebe-client-java-8.0.5.jar:8.0.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	... 9 common frames omitted</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>I tried to incrementally decrease the input collection until it is working again, when reaching 250k I finally see a better understandable error.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">2023-06-02 13:53:51.485 ERROR 29870 --- [           main] i.c.cloud.gameday.ProcessApplication     : Failed to create process instance of 'order-process'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">io.camunda.zeebe.client.api.command.ClientStatusException: Command 'CREATE' rejected with code 'EXCEEDED_BATCH_RECORD_SIZE': </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.zeebe.client.impl.ZeebeClientFutureImpl.transformExecutionException(ZeebeClientFutureImpl.java:93) ~[zeebe-client-java-8.0.5.jar:8.0.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.zeebe.client.impl.ZeebeClientFutureImpl.join(ZeebeClientFutureImpl.java:50) ~[zeebe-client-java-8.0.5.jar:8.0.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.cloud.gameday.ProcessApplication.createProcessInstance(ProcessApplication.java:90) ~[classes/:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.cloud.gameday.ProcessApplication.createInstanceOfProcess(ProcessApplication.java:71) ~[classes/:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.cloud.gameday.ProcessApplication.run(ProcessApplication.java:58) ~[classes/:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at org.springframework.boot.SpringApplication.callRunner(SpringApplication.java:791) ~[spring-boot-2.5.2.jar:2.5.2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at org.springframework.boot.SpringApplication.callRunners(SpringApplication.java:775) ~[spring-boot-2.5.2.jar:2.5.2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at org.springframework.boot.SpringApplication.run(SpringApplication.java:345) ~[spring-boot-2.5.2.jar:2.5.2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1343) ~[spring-boot-2.5.2.jar:2.5.2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1332) ~[spring-boot-2.5.2.jar:2.5.2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.cloud.gameday.ProcessApplication.main(ProcessApplication.java:46) ~[classes/:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Caused by: java.util.concurrent.ExecutionException: io.grpc.StatusRuntimeException: UNKNOWN: Command 'CREATE' rejected with code 'EXCEEDED_BATCH_RECORD_SIZE': </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396) ~[na:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073) ~[na:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.camunda.zeebe.client.impl.ZeebeClientFutureImpl.join(ZeebeClientFutureImpl.java:48) ~[zeebe-client-java-8.0.5.jar:8.0.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	... 9 common frames omitted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Caused by: io.grpc.StatusRuntimeException: UNKNOWN: Command 'CREATE' rejected with code 'EXCEEDED_BATCH_RECORD_SIZE': </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.grpc.Status.asRuntimeException(Status.java:535) ~[grpc-api-1.45.1.jar:1.45.1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:478) ~[grpc-stub-1.45.1.jar:1.45.1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:562) ~[grpc-core-1.45.1.jar:1.45.1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70) ~[grpc-core-1.45.1.jar:1.45.1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:743) ~[grpc-core-1.45.1.jar:1.45.1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:722) ~[grpc-core-1.45.1.jar:1.45.1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37) ~[grpc-core-1.45.1.jar:1.45.1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133) ~[grpc-core-1.45.1.jar:1.45.1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023-06-02 13:53:51.485  INFO 29870 --- [           main] i.c.cloud.gameday.ProcessApplication     : Created process instances with large collection. [order-id: 'ba65b59b-1584-48bb-af05-3724ea15fac9']</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="results">Results<a href="https://zeebe-io.github.io/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance#results" class="hash-link" aria-label="Direct link to Results" title="Direct link to Results">​</a></h3>
<p>As we have seen above we are able now to create much larger multi instances than before, with some drawbacks in performance, which needs to be investigated further.</p>
<p>When reaching a certain limit (maxMessageSize) we get a described rejection by the broker, until we reach the limit of NGINX where the description is not that optimal. Here we can and should improve further.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="found-bugs">Found Bugs<a href="https://zeebe-io.github.io/zeebe-chaos/2023/06/02/Using-Large-Multi-Instance#found-bugs" class="hash-link" aria-label="Direct link to Found Bugs" title="Direct link to Found Bugs">​</a></h2>
<ul>
<li>in a previous test I run into <a href="https://github.com/camunda/zeebe/issues/12918" target="_blank" rel="noopener noreferrer">https://github.com/camunda/zeebe/issues/12918</a></li>
<li>Related bug regarding the input collection <a href="https://github.com/camunda/zeebe/issues/12873" target="_blank" rel="noopener noreferrer">https://github.com/camunda/zeebe/issues/12873</a></li>
</ul>]]></content:encoded>
            <category>availability</category>
        </item>
        <item>
            <title><![CDATA[Continuing SST Partitioning toggle]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle</guid>
            <pubDate>Fri, 19 May 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[Today we want to continue with the experiment from last Chaos day, but this time]]></description>
            <content:encoded><![CDATA[<p>Today we want to continue with the experiment from <a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle">last Chaos day</a>, but this time
with a bit more load. This should make sure that we trigger the compaction of RocksDB and cause the SST partitioning to happen, for real.</p>
<p>The reasons stay the same we want to find out whether it would be possible to enable and disable the flag/configuration without issues.</p>
<p><strong>TL;DR;</strong> Today's, experiments succeeded <!-- -->🚀<!-- -->. We were able to show that even with a higher number of process instances (bigger state) we can easily disable and enable the SST partitioning flag without issues. I also got a confirmation from a RocksDb contributor that our observations are correct, and that we can easily toggle this feature without issues.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">​</a></h2>
<p>Similar setup to the <a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle#chaos-experiment">last Chaos day</a>.
Except this time we will enable Operate as well, in order to verify easily whether all instances have been completed.
Other than that we use the standard benchmark configuration, without clients.</p>
<p>The verification of the steady state will consist, of checking the readiness and healthiness of the cluster, via zbchaos and metrics. Furthermore, we will verify that we can access operate and that no instances are running. As defined in chaos engineering principles the process of a chaos experiment looks always the same, Verify the steady state, introduce chaos, and verify the steady state.</p>
<p>In our first experiment, we will enable the SST partitioning.</p>
<p><strong>First chaos action</strong></p>
<ul>
<li>Deploy a process model (which contains a <a href="https://github.com/zeebe-io/zeebe-chaos/blob/main/go-chaos/internal/bpmn/one_task.bpmn" target="_blank" rel="noopener noreferrer">simple model</a>)</li>
<li>Start 1000 process instances (PIs), with a service task</li>
<li>Enable the SST partitioning</li>
<li>Restart the cluster, and await readiness</li>
<li>Complete the jobs (in consequence the PIs)</li>
</ul>
<p>In our second experiment, we will disable the SST partitioning again.</p>
<p><strong>Second chaos action:</strong></p>
<ul>
<li>Start 1000 process instances (PIs), with a service task</li>
<li>Disable the SST partitioning</li>
<li>Restart the cluster, and await readiness</li>
<li>Complete the jobs (in consequence the PIs)</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<blockquote>
<p>When operating a cluster, I can enable and disable the SST partitioning without an impact on executing existing process instances. Existing PIs should still be executable and completable.</p>
</blockquote>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<p>As linked above I used again our <a href="https://github.com/camunda/zeebe/tree/main/benchmarks/setup" target="_blank" rel="noopener noreferrer">benchmark/setup</a> scripts to set up a cluster.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ diff ../default/values.yaml values.yaml </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">40c40</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;   replicas: 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;   replicas: 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">47c47</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;   replicas: 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;   replicas: 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">85a86</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;     zeebe.broker.experimental.rocksdb.enableSstPartitioning: "false"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">96a98,100</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;     identity:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;       auth:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;         enabled: false</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">326c330</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;     enabled: false</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;     enabled: true</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="first-experiment-verify-steady-state">First Experiment: Verify Steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#first-experiment-verify-steady-state" class="hash-link" aria-label="Direct link to First Experiment: Verify Steady state" title="Direct link to First Experiment: Verify Steady state">​</a></h4>
<p>To verify the readiness and run all actions I used the <a href="https://github.com/zeebe-io/zeebe-chaos/tree/zbchaos-v1.0.0" target="_blank" rel="noopener noreferrer">zbchaos</a> tool.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify readiness</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Looking at the metrics shows that everything looks healthy. The only weird part is the topology panel which seems to be broken.
<img loading="lazy" alt="start" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/start-bfbabb5034107afa1b8f0a19e81c72eb.png" width="1853" height="906" class="img_ev3q"></p>
<p>When requesting the topology via <code>zbchaos</code> we retrieve this:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos topology</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{1 LEADER -1  10  msg false 1 LEADER -1 2 LEADER -1 1684476531915 false false true false false 30 false -1 benchmark 30  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Node      |Partition 1         |Partition 2         |Partition 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1         |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)    |FOLLOWER (HEALTHY)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">0         |LEADER (HEALTHY)    |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2         |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>For now, we assume the dashboard has an issue and continue with the experiment.</p>
<p>We are able to access operate without issues, and see no instances yet.</p>
<p><img loading="lazy" alt="operate" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/operate-c8609205a0832ffb0852c1c14c527e7e.png" width="1901" height="752" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="first-experiment-chaos-action">First Experiment: Chaos Action<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#first-experiment-chaos-action" class="hash-link" aria-label="Direct link to First Experiment: Chaos Action" title="Direct link to First Experiment: Chaos Action">​</a></h4>
<p>After the verification stage, we start with our chaos action, injecting chaos into the system.
The first step is to deploy the mentioned simple process model:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos deploy process -v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connecting to zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Running experiment in self-managed environment.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Port forward to zell-chaos-zeebe-gateway-7bbdf9fd58-dl97j</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Successfully created port forwarding tunnel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Deploy file bpmn/one_task.bpmn (size: 2526 bytes).</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Deployed process model bpmn/one_task.bpmn successful with key 2251799813685249.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Deployed given process model , under key 2251799813685249!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This is then as well visible in operate.</p>
<p><img loading="lazy" alt="operate-process" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/operate-process-c2f4b5eac01d3b5334749518b3ed7eed.png" width="1091" height="503" class="img_ev3q"></p>
<p>As the next step, we will create 1000 process instances of our simple process model, with one service task.
For that, we can <a href="https://github.com/zeebe-io/zeebe-chaos/tree/zell-chaos-create-count-of-instances" target="_blank" rel="noopener noreferrer">use a new functionality</a> of <code>zbchaos</code> I built for this chaos day.</p>
<p>On the first try, I had smaller issues, with timeouts etc.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Send create process instance command, with BPMN process ID 'benchmark' and version '-1' (-1 means latest) [variables: '', awaitResult: false]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[299/999] Created process instance with key 6755399441056339 on partition 3.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">panic: Expected to create 999 process instances, but timed out after 30s created 299 instances.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This is the reason why I had to retry the creations in the end the count is not exactly 1000 :)</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">./dist/zbchaos verify instance-count --instanceCount 697 -v --timeoutInSec 300</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[695/697] Created process instance with key 4503599627372489 on partition 2.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Send create process instance command, with BPMN process ID 'benchmark' and version '-1' (-1 means latest) [variables: '', awaitResult: false]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[696/697] Created process instance with key 6755399441057737 on partition 3.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Send create process instance command, with BPMN process ID 'benchmark' and version '-1' (-1 means latest) [variables: '', awaitResult: false]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[697/697] Created process instance with key 2251799813687255 on partition 1.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img loading="lazy" alt="pi" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/operate-pi-14b1db18f29dfd9c2858179dde92da41.png" width="1905" height="510" class="img_ev3q"></p>
<p>Now we are coming to the interesting part. Enabling SST partitioning.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ diff ../default/values.yaml values.yaml </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">85a86</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;     zeebe.broker.experimental.rocksdb.enableSstPartitioning: "true"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ make update </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm upgrade --namespace zell-chaos zell-chaos zeebe-benchmark/zeebe-benchmark -f values.yaml</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<blockquote>
<p><strong>Note</strong>
Changing the configmap doesn't restart pods! We need to delete all Zeebe pods, to apply the configuration.</p>
</blockquote>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ k delete pod -l app=camunda-platform</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zell-chaos-zeebe-0" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zell-chaos-zeebe-1" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zell-chaos-zeebe-2" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zell-chaos-zeebe-gateway-7bbdf9fd58-8j7d6" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zell-chaos-zeebe-gateway-7bbdf9fd58-dl97j" deleted</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify readiness </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Now starting to complete the previously created jobs, we can use again a new feature in <code>zbchaos</code> (<a href="https://github.com/zeebe-io/zeebe-chaos/tree/zell-chaos-create-count-of-instances" target="_blank" rel="noopener noreferrer">which has been added during the chaos day</a>)
Unfortunately, I missed using the verbose flag.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ ./dist/zbchaos verify job-completion --jobCount 1001 --timeoutInSec 1200</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="first-experiment-verify-steady-state-1">First Experiment: Verify Steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#first-experiment-verify-steady-state-1" class="hash-link" aria-label="Direct link to First Experiment: Verify Steady state" title="Direct link to First Experiment: Verify Steady state">​</a></h4>
<p>The job completions worked without issues. The metrics are looking good, the topology panel seems to work again as well.</p>
<p><img loading="lazy" alt="complete" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/metrics-complete-6a55f56851581c51bf703a1431d75c3b.png" width="1845" height="894" class="img_ev3q"></p>
<p>In operate we can see that there are no longer any running instances and all of them have been completed.</p>
<p><img loading="lazy" alt="complete-operate" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/operate-complete-d4f703e6d9711b157856fd244294999a.png" width="1894" height="500" class="img_ev3q">
<img loading="lazy" alt="complete-operate2" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/operate-complete2-9a77531ed33a8b2a74c2d2b4bf5ff090.png" width="1887" height="793" class="img_ev3q"></p>
<p>The first part of the experiment worked as expected <!-- -->✅</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="second-experiment-chaos-action">Second Experiment: Chaos Action<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#second-experiment-chaos-action" class="hash-link" aria-label="Direct link to Second Experiment: Chaos Action" title="Direct link to Second Experiment: Chaos Action">​</a></h4>
<p>We are skipping the verification step, due to previous verification, we directly start with creating 1000 process instances.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ ./dist/zbchaos verify instance-count --instanceCount 1000 -v --timeoutInSec 300</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Send create process instance command, with BPMN process ID 'benchmark' and version '-1' (-1 means latest) [variables: '', awaitResult: false]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[1000/1000] Successful command sent, got response with key 2251799813690599 on partition 1.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img loading="lazy" alt="second" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/second-exp-e3fd7780bec7f168375839276a153572.png" width="1890" height="892" class="img_ev3q"></p>
<p>Disable the SST partitioning flag and update the cluster.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ make update </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ k delete pod -l app=camunda-platform</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify readiness</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Complete all jobs:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ ./dist/zbchaos verify job-completion --jobCount 1000 --timeoutInSec 1200 -v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[999/1000] Successful command sent, got response with key 6755399441061073 on partition 3.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Send job activate command, with job type 'benchmark-task'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[1000/1000] Successful command sent, got response with key 2251799813690604 on partition 1.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="second-experiment-verify-steady-state">Second Experiment: Verify Steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#second-experiment-verify-steady-state" class="hash-link" aria-label="Direct link to Second Experiment: Verify Steady state" title="Direct link to Second Experiment: Verify Steady state">​</a></h4>
<p>Again the experiment succeeded, we were able to show that even with a higher number of process instances we can easily disable and enable the SST partitioning flag.</p>
<p><img loading="lazy" alt="verify" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/second-exp-verify-027ddb4d82b084f1da4fb7cf0804cd31.png" width="1840" height="892" class="img_ev3q">
<img loading="lazy" alt="op-complete" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/second-exp-operate-complete-fb1b93e473c3b44f74af441a0758c6e0.png" width="1087" height="614" class="img_ev3q"></p>
<p>In the snapshots at we can see that some more files are used.</p>
<p><img loading="lazy" alt="snap" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/second-exp-snap-619bf47a82dce280aed6013c81dde883.png" width="878" height="850" class="img_ev3q"></p>
<p>But in RocksDb metrics we see no real compaction going on, which is why we will retry the same with a higher amount of data.</p>
<p><img loading="lazy" alt="rocks" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/second-exp-rocks-ad699b1447a827a6cadc97e38b7e4536.png" width="884" height="422" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="sst-partitioning-and-compaction">SST Partitioning and compaction<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#sst-partitioning-and-compaction" class="hash-link" aria-label="Direct link to SST Partitioning and compaction" title="Direct link to SST Partitioning and compaction">​</a></h4>
<p>I tried to run the experiment again but with more data (~11K instances).</p>
<p>Even when the metrics don't show the compaction, I was able to see in the RocksDB that compacting is happening.</p>
<p>Around 11:56 between different loads</p>
<p><img loading="lazy" alt="thirdrun" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/thirdrun-d169e0524892c8521172f5d181e3c59d.png" width="1849" height="891" class="img_ev3q"></p>
<p>We see in the metrics of RocksDB that nothing</p>
<p><img loading="lazy" alt="rocks" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/compacting-16d643497e24f39e3aef93cabb91a0b7.png" width="1860" height="451" class="img_ev3q"></p>
<p>But when checking the RocksDB logs</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ cat data/raft-partition/partitions/1/runtime/LOG.old.1684493206724692 </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/19-09:56:40.652111 140580419004160  Options.sst_partitioner_factory: SstPartitionerFixedPrefixFactory</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/19-09:56:41.354244 140579153618688 (Original Log Time 2023/05/19-09:56:41.354149) EVENT_LOG_v1 {"time_micros": 1684490201354123, "job": 2, "event": "compaction_finished", "compaction_time_micros": 374078, "compaction_time_cpu_micros": 72361, "output_level": 3, "num_output_files": 14, "total_output_size": 6283132, "num_input_records": 69787, "num_output_records": 39118, "num_subcompactions": 1, "output_compression": "NoCompression", "num_single_delete_mismatches": 0, "num_single_delete_fallthrough": 0, "lsm_state": [0, 0, 0, 14]}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/19-09:56:41.354763 140579153618688 [le/delete_scheduler.cc:77] Deleted file /usr/local/zeebe/data/raft-partition/partitions/1/runtime/000045.sst immediately, rate_bytes_per_sec 0, total_trash_size 0 max_trash_db_ratio 0.250000</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/19-09:56:41.354786 140579153618688 EVENT_LOG_v1 {"time_micros": 1684490201354782, "job": 2, "event": "table_file_deletion", "file_number": 45}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/19-09:56:41.355217 140579153618688 [le/delete_scheduler.cc:77] Deleted file /usr/local/zeebe/data/raft-partition/partitions/1/runtime/000044.sst immediately, rate_bytes_per_sec 0, total_trash_size 0 max_trash_db_ratio 0.250000</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/19-09:56:41.355247 140579153618688 EVENT_LOG_v1 {"time_micros": 1684490201355243, "job": 2, "event": "table_file_deletion", "file_number": 44}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/19-09:56:41.355765 140579153618688 [le/delete_scheduler.cc:77] Deleted file /usr/local/zeebe/data/raft-partition/partitions/1/runtime/000043.sst immediately, rate_bytes_per_sec 0, total_trash_size 0 max_trash_db_ratio 0.250000</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We see several lines which indicate the compaction.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>We have seen that even when we toggle the SST partitioning, we are able to make progress and our stored data is not impacted. This is a great out come since it means we can easily enable such configuration on existing clusters and gains the performance benefits for larger states as we have seen in previous benchmarks.</p>
<p>I have posted a question related to this topic in the <a href="https://groups.google.com/g/rocksdb/c/Ys-yZIznZwU" target="_blank" rel="noopener noreferrer">RocksDb google group</a> and I got a private answer which contains the following:</p>
<blockquote>
<p>Partitioner is just a hinter when compaction should split the file. Default compaction is also splitting by file size. So it has no functional effect and you can change configuration anytime.</p>
<p>Partitioner does not need to be simple prefix only, but one can use more complicated strategy.</p>
</blockquote>
<p>This confirms our observation and makes it much more trustworthy.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="found-bugs">Found Bugs<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle#found-bugs" class="hash-link" aria-label="Direct link to Found Bugs" title="Direct link to Found Bugs">​</a></h2>
<ul>
<li>Grafana Topology Panel seems to be buggy from time to time</li>
<li>RocksDB compaction panel seems to show no data (might be related to a short time frame)</li>
</ul>]]></content:encoded>
            <category>availability</category>
            <category>data</category>
        </item>
        <item>
            <title><![CDATA[SST Partitioning toggle]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle</guid>
            <pubDate>Mon, 15 May 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[On this chaos day I wanted to experiment with a new experimental feature we have released recently. The enablement of the partitioning of the SST files in RocksDB. This is an experimental feature from RocksDb, which we made available now for our users as well, since we have seen great benefits in performance, especially with larger runtime data.]]></description>
            <content:encoded><![CDATA[<p>On this chaos day I wanted to experiment with a new experimental feature we have released recently. The <a href="https://github.com/camunda/zeebe/pull/12483" target="_blank" rel="noopener noreferrer">enablement of the partitioning of the SST files in RocksDB</a>. This is an experimental feature from RocksDb, which we made available now for our users as well, since we have seen great benefits in performance, especially with larger runtime data.</p>
<p>I wanted to experiment a bit with the SST partitioning and find out whether it would be possible to enable and disable the flag/configuration without issues.</p>
<p><strong>TL;DR;</strong> The first experiment was successful, it looks like we can enable and disable the partitioning without impacting the execution of one existing PI. We need to experiment a bit more with larger data sets to force RocksDB compaction, to be fully sure.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">​</a></h2>
<p>For our chaos experiment we set up again our <a href="https://github.com/camunda/zeebe/tree/main/benchmarks/setup" target="_blank" rel="noopener noreferrer">normal benchmark cluster</a>, this time without any clients (no workers/starters).</p>
<p>Setting all client replicas to zero:</p>
<div class="language-diff codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-diff codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ diff default/values.yaml zell-chaos/values.yaml </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">40c40</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;   replicas: 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;   replicas: 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">47c47</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;   replicas: 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;   replicas: 0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The experiment we want to do on this chaos day will look like the following:</p>
<p><strong>First part:</strong></p>
<ul>
<li>Verify steady state:<!-- -->
<ul>
<li>verify the readiness of the cluster</li>
<li>deploy a process model (which contains a <a href="https://github.com/zeebe-io/zeebe-chaos/blob/main/go-chaos/internal/bpmn/one_task.bpmn" target="_blank" rel="noopener noreferrer">simple model</a>)</li>
</ul>
</li>
<li>Chaos Action:<!-- -->
<ul>
<li>start a process instance (PI), with a service task</li>
<li>enable the SST partitioning</li>
<li>restart the cluster</li>
<li>verify the readiness</li>
<li>verify that job is activatable</li>
<li>complete the job (in consequence the PI)</li>
</ul>
</li>
</ul>
<p><strong>Second part:</strong></p>
<ul>
<li>Chaos Action:<!-- -->
<ul>
<li>start a process instance (PI), with a service task</li>
<li>disable the SST partitioning</li>
<li>restart the cluster</li>
<li>verify the readiness</li>
<li>verify that job is activatable</li>
<li>complete the job (in consequence the PI)</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>When operating a cluster, I can enable the SST partitioning without an impact on executing existing process instances. Existing PIs should still be executable and completable.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<p>As linked above I used again our <a href="https://github.com/camunda/zeebe/tree/main/benchmarks/setup" target="_blank" rel="noopener noreferrer">benchmark/setup</a> scripts to set up a cluster.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="first-part-verify-steady-state">First Part: Verify Steady state<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle#first-part-verify-steady-state" class="hash-link" aria-label="Direct link to First Part: Verify Steady state" title="Direct link to First Part: Verify Steady state">​</a></h4>
<p>To verify the readiness and run all actions I used the <a href="https://github.com/zeebe-io/zeebe-chaos/tree/zbchaos-v1.0.0" target="_blank" rel="noopener noreferrer">zbchaos</a> tool.</p>
<p>Verifying readiness is fairly easy with zbchaos.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify readiness -v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connecting to zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Running experiment in self-managed environment.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Pod zell-chaos-zeebe-0 is in phase Pending, and not ready. Wait for some seconds.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[...]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Pod zell-chaos-zeebe-0 is in phase Running, and not ready. Wait for some seconds.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Pod zell-chaos-zeebe-0 is in phase Running, and not ready. Wait for some seconds.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We then deploy the mentioned simple process model:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos deploy process -v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connecting to zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Running experiment in self-managed environment.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Port forward to zell-chaos-zeebe-gateway-7bbdf9fd58-dl97j</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Successfully created port forwarding tunnel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Deploy file bpmn/one_task.bpmn (size: 2526 bytes).</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Deployed process model bpmn/one_task.bpmn successful with key 2251799813685249.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Deployed given process model , under key 2251799813685249!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="first-part-chaos-action">First Part: Chaos Action<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle#first-part-chaos-action" class="hash-link" aria-label="Direct link to First Part: Chaos Action" title="Direct link to First Part: Chaos Action">​</a></h4>
<p>As the first step in the chaos action we create a process instance.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify instance-creation -v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connecting to zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Running experiment in self-managed environment.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Port forward to zell-chaos-zeebe-gateway-7bbdf9fd58-dl97j</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Successfully created port forwarding tunnel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Send create process instance command, with BPMN process ID 'benchmark' and version '-1' (-1 means latest) [variables: '', awaitResult: false]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Created process instance with key 2251799813685251 on partition 1, required partition 1.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Next, we enable the SST partitioning in our broker configuration, we can do this in the <code>values.yaml</code> file and run a <code>helm update</code>.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ diff ../default/values.yaml values.yaml </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">85a86</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;     zeebe.broker.experimental.rocksdb.enableSstPartitioning: "true"</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ make update</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm upgrade --namespace zell-chaos zell-chaos zeebe-benchmark/zeebe-benchmark -f values.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Release "zell-chaos" has been upgraded. Happy Helming!</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME: zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">LAST DEPLOYED: Mon May 15 15:54:24 2023</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAMESPACE: zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">STATUS: deployed</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">REVISION: 2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NOTES:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Zeebe Benchmark</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Installed Zeebe cluster with:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * 3 Brokers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * 2 Gateways</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The benchmark is running with:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * Starter replicas=0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * Worker replicas=0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * Publisher replicas=0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * Timer replicas=0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<blockquote>
<p><strong>Note</strong>
Changing the configmap doesn't restart pods! We need to delete all Zeebe pods, to apply the configuration.</p>
</blockquote>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ k delete pod -l app=camunda-platform</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zell-chaos-zeebe-0" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zell-chaos-zeebe-1" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zell-chaos-zeebe-2" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zell-chaos-zeebe-gateway-7bbdf9fd58-8j7d6" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zell-chaos-zeebe-gateway-7bbdf9fd58-dl97j" deleted</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Next we can use <code>zbchaos verify readiness</code> again to await the readiness of the cluster.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Taking a look at the logs of the broker we can also see that the broker configuration was correctly set:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">   \"disableWal\" : true,\n      \"enableSstPartitioning\" : true\n    }</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<blockquote>
<p><strong>Note</strong>
Right now zbchaos can't complete an job (missing feature). We use zbctl for that, we need to port-forward to the gateway in order to send the commands.</p>
</blockquote>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ k port-forward svc/zell-chaos-zeebe-gateway 26500</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Forwarding from 127.0.0.1:26500 -&gt; 26500</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Forwarding from [::1]:26500 -&gt; 26500</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Activating the right job.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbctl --insecure activate jobs benchmark-task</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  "jobs":  [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "key":  "2251799813685256",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "type":  "benchmark-task",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "processInstanceKey":  "2251799813685251",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "bpmnProcessId":  "benchmark",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "processDefinitionVersion":  1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "processDefinitionKey":  "2251799813685249",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "elementId":  "task",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "elementInstanceKey":  "2251799813685255",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "customHeaders":  "{}",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "worker":  "zbctl",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "retries":  3,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "deadline":  "1684173544716",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "variables":  "{}"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Completing the job and the PI.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbctl complete job 2251799813685256 --insecure</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Completed job with key '2251799813685256' and variables '{}'</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="second-part">Second Part:<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle#second-part" class="hash-link" aria-label="Direct link to Second Part:" title="Direct link to Second Part:">​</a></h4>
<p>Create again a process instance <code>$ zbchaos verify instance-creation</code></p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Created process instance with key 2251799813685263 on partition 1, required partition 1.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady-state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Disabling the configuration again, and running the update.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ diff default/values.yaml zell-chaos/values.yaml </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">85a86</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;     zeebe.broker.experimental.rocksdb.enableSstPartitioning: "false"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ make update </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm upgrade --namespace zell-chaos zell-chaos zeebe-benchmark/zeebe-benchmark -f values.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Release "zell-chaos" has been upgraded. Happy Helming!</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME: zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">LAST DEPLOYED: Mon May 15 20:00:53 2023</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ k delete pod -l app=camunda-platform</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify readiness</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Again the job completion worked without problems (skipping here the port-forward and activate output)</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbctl complete job 2251799813685268 --insecure</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Completed job with key '2251799813685268' and variables '{}'</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>✅<!-- --> The experiment was successful.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="further-investigation">Further investigation<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle#further-investigation" class="hash-link" aria-label="Direct link to Further investigation" title="Direct link to Further investigation">​</a></h4>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/general-after2-e0b4149303fb10808ec4d1e9215ed7af.png" width="1848" height="701" class="img_ev3q"></p>
<p>When running the experiment I also observed the metrics of the cluster and was not able to see any differences in the snapshot file counts, which we would expect on the SST partitioning (there should be more files).</p>
<p>Before the experiment:
<img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/snapshot-before-2140893bacefcc15a0d450c89274d8e2.png" width="932" height="814" class="img_ev3q"></p>
<p>After the experiment, we still see that for each partition we have around ~6 files.
<img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/snapshot-after2-ca6970a41ba78ee802c74de8b18c195d.png" width="938" height="818" class="img_ev3q"></p>
<p>In order to make sure whether the options have been applied correctly I investigated the RocksDB log files and option files.</p>
<p>In the current LOG file, we can see the current options printed, which is indeed the disabled partitioner. Since this is the default as well it is not a proof yet.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/15-18:01:46.223234 139711509092096 [/column_family.cc:621] --------------- Options for column family [default]:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/15-18:01:46.223237 139711509092096               Options.comparator: leveldb.BytewiseComparator</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/15-18:01:46.223239 139711509092096           Options.merge_operator: None</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/15-18:01:46.223241 139711509092096        Options.compaction_filter: None</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/15-18:01:46.223242 139711509092096        Options.compaction_filter_factory: None</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023/05/15-18:01:46.223244 139711509092096  Options.sst_partitioner_factory: None</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>What we can see in the runtime folder of the partition is that there exist two Options files, an older one <code>OPTIONS-000014</code>, and a newer one <code>OPTIONS-000023</code>.</p>
<p>The older one contains the expected configuration for the SST partitioning:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ cat OPTIONS-000014 </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[CFOptions "default"]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  sst_partitioner_factory={id=SstPartitionerFixedPrefixFactory;length=8;}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The most recent options file has the configuration set to null.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ cat OPTIONS-000023</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[CFOptions "default"]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sst_partitioner_factory=nullptr</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We can see that the current snapshot only copied the most recent options file:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ ll ../snapshots/188-4-230-244</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">total 56</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">drwxr-xr-x 2 root root 4096 May 15 18:13 ./</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">drwxr-xr-x 3 root root 4096 May 15 18:13 ../</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-rw-r--r-- 2 root root 7015 May 15 18:01 OPTIONS-000023</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-rw-r--r-- 1 root root   92 May 15 18:13 zeebe.metadata</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://zeebe-io.github.io/zeebe-chaos/2023/05/15/SST-Partitioning-toggle#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h3>
<p>We were able to toggle the SST partitioning flag without problems back and forth. We were able to make still progress on an existing process instance, which we wanted to prove.</p>
<p>Nevertheless, we need to prove this once more for multiple process instances (100-1000 PIs), which cause or forces compaction of the SST files. Right now I'm not 100% convinced whether this experiment was enough, but it was a good first step.</p>]]></content:encoded>
            <category>availability</category>
            <category>data</category>
        </item>
        <item>
            <title><![CDATA[Gateway Termination]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination</guid>
            <pubDate>Thu, 06 Apr 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[In today's chaos day, we wanted to experiment with the gateway and resiliency of workers.]]></description>
            <content:encoded><![CDATA[<p>In today's chaos day, we wanted to experiment with the gateway and resiliency of workers.</p>
<p>We have seen in recent weeks some issues within our benchmarks when gateways have been restarted,
see <a href="https://github.com/camunda/zeebe/issues/11975" target="_blank" rel="noopener noreferrer">zeebe#11975</a>.</p>
<p>We did a similar experiment <a href="https://zeebe-io.github.io/zeebe-chaos/2022/02/15/Standalone-Gateway-in-CCSaaS">in the past</a>,
today we want to focus on self-managed (<a href="https://helm.camunda.io/" target="_blank" rel="noopener noreferrer">benchmarks with our helm charts</a>).
Ideally, we can automate this as well soon.</p>
<p>Today <a href="https://github.com/npepinpe" target="_blank" rel="noopener noreferrer">Nicolas</a> joined me on the chaos day <!-- -->🎉</p>
<p><strong>TL;DR;</strong> We were able to show that the workers (clients) can reconnect after a gateway is shutdown <!-- -->✅<!-- -->
Furthermore, we have discovered a potential performance issue on lower load, which impacts process execution latency (<a href="https://github.com/camunda/zeebe/issues/12311" target="_blank" rel="noopener noreferrer">zeebe#12311</a>).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">​</a></h2>
<p>We will use our <a href="https://github.com/zeebe-io/benchmark-helm" target="_blank" rel="noopener noreferrer">Zeebe benchmark helm charts</a> to set up the test cluster, and
our helper scripts <a href="https://github.com/camunda/zeebe/tree/main/benchmarks/setup" target="_blank" rel="noopener noreferrer">here</a>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="setup">Setup:<a href="https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination#setup" class="hash-link" aria-label="Direct link to Setup:" title="Direct link to Setup:">​</a></h3>
<p>We will run with the default benchmark configuration, which means:</p>
<ul>
<li>three brokers</li>
<li>three partitions</li>
<li>replication count three</li>
<li>two gateways</li>
</ul>
<p>We will run the benchmark with a low load, 10 process instances per second created and completed. For that,
we deploy one starter and worker. This reduces the blast radius and allows us to observe more easily how the workers
behave when a gateway is restarted.</p>
<p>During the experiment, we will use our <a href="https://github.com/camunda/zeebe/tree/main/monitor/grafana" target="_blank" rel="noopener noreferrer">grafana dashboard</a> to
observe to which gateway the worker will connect and which gateway we need to stop/restart.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">LAST DEPLOYED: Thu Apr  6 10:21:27 2023</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAMESPACE: zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">STATUS: deployed</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">REVISION: 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NOTES:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Zeebe Benchmark</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Installed Zeebe cluster with:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * 3 Brokers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * 2 Gateways</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The benchmark is running with:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * Starter replicas=1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * Worker replicas=1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * Publisher replicas=0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> * Timer replicas=0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>When we terminate a gateway to which the worker has connected, <strong>we expect</strong> that the worker connects to the different
replica and starts completing jobs again.</p>
<p>The performance drop is expected to be not significant, or at least should recover fast.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<p>We will run the experiment in two ways, first via terminating the gateway (using <a href="https://github.com/zeebe-io/zeebe-chaos/releases/tag/zbchaos-v1.0.0" target="_blank" rel="noopener noreferrer">zbchaos</a>)
and later via scaling down the gateway deployment to one replica.</p>
<p>We want to verify whether this makes any difference, since terminating will cause Kubernetes to recreate immediately the pod.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="termination">Termination<a href="https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination#termination" class="hash-link" aria-label="Direct link to Termination" title="Direct link to Termination">​</a></h4>
<p>Before we start the experiment we check our current deployed state:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ kgpo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                        READY   STATUS      RESTARTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">camunda-platform-curator-28012860-zk72q     0/1     Completed   0          7m24s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-0                      1/1     Running     0          45m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-1                      1/1     Running     0          45m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-2                      1/1     Running     0          45m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">leader-balancer-28012860-7cwmd              0/1     Completed   0          7m25s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">starter-cb69c447f-l2zbh                     1/1     Running     0          45m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">worker-cb7f7c469-qvqqv                      1/1     Running     0          45m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-0                          1/1     Running     0          45m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-1                          1/1     Running     0          45m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-2                          1/1     Running     0          45m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-vs28f   1/1     Running     0          45m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-xc6d9   1/1     Running     0          45m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Via our Grafana dashboard (and the gRPC metrics) we are able to track to which gateway the worker connects to:</p>
<p><img loading="lazy" alt="grpc" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/grpc-13224311ab5e142b1d17c5bfeb3369d7.png" width="1545" height="840" class="img_ev3q"></p>
<p>It is <code>zell-chaos-zeebe-gateway-7bbdf9fd58-vs28f</code>.
Via zbchaos we can easily terminate the gateway (it will always take the first in the pod list).</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos terminate gateway </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{1 LEADER -1  10  msg false 1 LEADER -1 2 LEADER -1 1680772377704 false false true false false 30 false -1 benchmark 30  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Terminated zell-chaos-zeebe-gateway-7bbdf9fd58-vs28f</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>After terminating we can see that a new gateway pod has started.</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ kgpo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                        READY   STATUS      RESTARTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">camunda-platform-curator-28012860-zk72q     0/1     Completed   0          13m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-0                      1/1     Running     0          52m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-1                      1/1     Running     0          52m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-2                      1/1     Running     0          52m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">leader-balancer-28012860-7cwmd              0/1     Completed   0          13m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">starter-cb69c447f-l2zbh                     1/1     Running     0          52m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">worker-cb7f7c469-qvqqv                      1/1     Running     0          52m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-0                          1/1     Running     0          52m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-1                          1/1     Running     0          52m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-2                          1/1     Running     0          52m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-pkj48   1/1     Running     0          33s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-xc6d9   1/1     Running     0          52m</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>In the metrics, we can see that due to the restart, the throughput slightly dropped, but recovered pretty fast. The worker
was able to connect to the different gateway. <!-- -->✅</p>
<p><img loading="lazy" alt="restart" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/restart-fba3c5902c9b5523ca1f2fe9ba45def5.png" width="1848" height="883" class="img_ev3q"></p>
<blockquote>
<p><strong>Note</strong></p>
<p><em>In the panel <code>Pod Restarts</code> on the top right, we don't see any restarts and that is something
we should always be aware of that the <em>metrics are just samples of data</em>. If a pod, like a gateway, restarts fast enough
and the metric collect interval is higher (per default we have ~30 s (?)) then you might not see a change.</em></p>
</blockquote>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="scale-down">Scale down<a href="https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination#scale-down" class="hash-link" aria-label="Direct link to Scale down" title="Direct link to Scale down">​</a></h4>
<p>As described earlier we wanted to verify whether it makes a difference if we scale down the replica instead of terminating/restarting
it, which causes restarting a new pod (which might get the same IP).</p>
<p>For scaling down Nicolas found this annotation: <code>controller.kubernetes.io/pod-deletion-cost</code></p>
<p><a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/#pod-deletion-cost" target="_blank" rel="noopener noreferrer">That annotation allows giving hints to the schedule which pod to turn-down, because another pod might have a higher cost
to be deleted (this is of course best-effort).</a></p>
<p>This means we edit one pod and gave the following annotation:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">annotations</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">controller.kubernetes.io/pod-deletion-cost</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">  </span><span class="token string" style="color:#e3116c">"-1"</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We have similarly chosen the pod as we have seen above, based on the gRPC metrics.</p>
<p>Checking the running pods and editing the correct gateway:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[cqjawa 2023-04-06-gateway-termination/ cluster: zeebe-cluster ns:zell-chaos]$ kgpo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                        READY   STATUS      RESTARTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">camunda-platform-curator-28012875-tntdv     0/1     Completed   0          6m26s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-0                      1/1     Running     0          59m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-1                      1/1     Running     0          59m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-2                      1/1     Running     0          59m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">leader-balancer-28012875-sctwq              0/1     Completed   0          6m26s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">starter-cb69c447f-l2zbh                     1/1     Running     0          59m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">worker-cb7f7c469-qvqqv                      1/1     Running     0          59m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-0                          1/1     Running     0          59m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-1                          1/1     Running     0          59m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-2                          1/1     Running     0          59m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-pkj48   1/1     Running     0          8m29s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-xc6d9   1/1     Running     0          59m</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>When I did the following I was wondering why it didn't scale down the deployment, one pod was recreated.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[cqjawa 2023-04-06-gateway-termination/ cluster: zeebe-cluster ns:zell-chaos]$ k scale replicaset zell-chaos-zeebe-gateway-7bbdf9fd58 --replicas=1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Warning: spec.template.spec.containers[0].env[16].name: duplicate name "ZEEBE_LOG_LEVEL"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">replicaset.apps/zell-chaos-zeebe-gateway-7bbdf9fd58 scaled</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[cqjawa 2023-04-06-gateway-termination/ cluster: zeebe-cluster ns:zell-chaos]$ kgpo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                        READY   STATUS            RESTARTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">camunda-platform-curator-28012875-tntdv     0/1     Completed         0          6m53s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-0                      1/1     Running           0          60m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-1                      1/1     Running           0          60m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-2                      1/1     Running           0          60m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">leader-balancer-28012875-sctwq              0/1     Completed         0          6m53s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">starter-cb69c447f-l2zbh                     1/1     Running           0          60m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">worker-cb7f7c469-qvqqv                      1/1     Running           0          60m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-0                          1/1     Running           0          60m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-1                          1/1     Running           0          60m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-2                          1/1     Running           0          60m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-2v6gs   0/1     PodInitializing   0          7s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-pkj48   1/1     Running           0          8m56s</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<blockquote>
<p><strong>Note:</strong></p>
<p>During the experiment I learned that when you have deployed a <a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/" target="_blank" rel="noopener noreferrer">deployment</a>, you need to scale down the deployment, not the <a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/" target="_blank" rel="noopener noreferrer">ReplicaSet</a>.
Otherwise your Kubernetes deployment controller will recreate the ReplicaSet in the next reconcile loop, which means you
will have again the same replicas as defined in the deployment.</p>
</blockquote>
<p>So correct is to scale down the deployment (!), if you ever wonder.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[cqjawa 2023-04-06-gateway-termination/ cluster: zeebe-cluster ns:zell-chaos]$ k edit pod zell-chaos-zeebe-gateway-7bbdf9fd58-pkj48</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod/zell-chaos-zeebe-gateway-7bbdf9fd58-pkj48 edited</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[cqjawa 2023-04-06-gateway-termination/ cluster: zeebe-cluster ns:zell-chaos]$ kgpo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                        READY   STATUS      RESTARTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">camunda-platform-curator-28012875-tntdv     0/1     Completed   0          10m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-0                      1/1     Running     0          63m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-1                      1/1     Running     0          63m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-2                      1/1     Running     0          63m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">leader-balancer-28012875-sctwq              0/1     Completed   0          10m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">starter-cb69c447f-l2zbh                     1/1     Running     0          63m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">worker-cb7f7c469-qvqqv                      1/1     Running     0          63m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-0                          1/1     Running     0          63m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-1                          1/1     Running     0          63m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-2                          1/1     Running     0          63m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-2v6gs   1/1     Running     0          3m40s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-pkj48   1/1     Running     0          12m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[cqjawa 2023-04-06-gateway-termination/ cluster: zeebe-cluster ns:zell-chaos]$ k scale deployment zell-chaos-zeebe-gateway --replicas=1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Warning: spec.template.spec.containers[0].env[16].name: duplicate name "ZEEBE_LOG_LEVEL"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">deployment.apps/zell-chaos-zeebe-gateway scaled</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[cqjawa 2023-04-06-gateway-termination/ cluster: zeebe-cluster ns:zell-chaos]$ kgpo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                        READY   STATUS      RESTARTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">camunda-platform-curator-28012875-tntdv     0/1     Completed   0          10m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-0                      1/1     Running     0          64m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-1                      1/1     Running     0          64m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-2                      1/1     Running     0          64m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">leader-balancer-28012875-sctwq              0/1     Completed   0          10m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">starter-cb69c447f-l2zbh                     1/1     Running     0          64m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">worker-cb7f7c469-qvqqv                      1/1     Running     0          64m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-0                          1/1     Running     0          64m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-1                          1/1     Running     0          64m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-2                          1/1     Running     0          64m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-7bbdf9fd58-2v6gs   1/1     Running     0          4m</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>With that, we have only one gateway pod left, and all traffic goes to that gateway. Based on the metrics
we can see that the workers recovered everytime when we restarted/terminated or scaled down.</p>
<p><img loading="lazy" alt="activate" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/activate-bd04e48187522a661ce740667de5dae7.png" width="917" height="414" class="img_ev3q"></p>
<p><img loading="lazy" alt="general" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/general-eccb10353f089541f74a3f82593a836d.png" width="1845" height="903" class="img_ev3q"></p>
<p>The experiment itself succeeded <!-- -->💪<!-- --> :white_check_marks:</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="found-bugs">Found Bugs<a href="https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination#found-bugs" class="hash-link" aria-label="Direct link to Found Bugs" title="Direct link to Found Bugs">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="zbchaos-print-verbose-logs">Zbchaos print verbose logs<a href="https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination#zbchaos-print-verbose-logs" class="hash-link" aria-label="Direct link to Zbchaos print verbose logs" title="Direct link to Zbchaos print verbose logs">​</a></h3>
<p>I realized that we still have <a href="https://github.com/zeebe-io/zeebe-chaos/issues/323" target="_blank" rel="noopener noreferrer">the issue with zbchaos</a> which is printing verbose logs:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos terminate gateway </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{1 LEADER -1  10  msg false 1 LEADER -1 2 LEADER -1 1680772377704 false false true false false 30 false -1 benchmark 30  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Terminated zell-chaos-zeebe-gateway-7bbdf9fd58-vs28f</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="segment-creation-impact">Segment creation impact<a href="https://zeebe-io.github.io/zeebe-chaos/2023/04/06/gateway-termination#segment-creation-impact" class="hash-link" aria-label="Direct link to Segment creation impact" title="Direct link to Segment creation impact">​</a></h3>
<p>During checking the metrics together with Nicolas, we realized that even on low load (10 PI/s) we have high spikes
in our processing execution latency.</p>
<p><img loading="lazy" alt="latency" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/latency-9fda0fdb0283c3af3831aef3813997e6.png" width="1852" height="822" class="img_ev3q"></p>
<p>The spikes are going up to 1-1.5 seconds, while the avg is at 0.06s. This happens every 6 minutes.</p>
<p>We can see that the commit latency is as well at the same time high, which might be an issue because of the high IO.</p>
<p><img loading="lazy" alt="commit" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/commit-541f81ca663ae80835fa6ef8357d94a7.png" width="1841" height="250" class="img_ev3q"></p>
<p>We first expected that to be related to snapshotting, but snapshots happen much more often.</p>
<p><img loading="lazy" alt="snapshot" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/snapshot-count-1b18a9a53eeaf2d45ab3a6f109b5d981.png" width="923" height="276" class="img_ev3q"></p>
<p>Interestingly is that it seems to be related to our segment creation (again), even if we have
async segment creation in our journal built recently. We need to investigate this further within <a href="https://github.com/camunda/zeebe/issues/12311" target="_blank" rel="noopener noreferrer">zeebe#12311</a>.</p>
<p><img loading="lazy" alt="segment" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/segment-176d6a262460c14aa4dce22bdce1dab2.png" width="1850" height="402" class="img_ev3q"></p>]]></content:encoded>
            <category>availability</category>
            <category>resiliency</category>
        </item>
        <item>
            <title><![CDATA[Recursive call activity]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2023/02/23/Recursive-call-activity</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2023/02/23/Recursive-call-activity</guid>
            <pubDate>Thu, 23 Feb 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[Long time no see. Happy to do my first chaos day this year. In the last week have implemented interesting features, which I would like to experiment with.]]></description>
            <content:encoded><![CDATA[<p>Long time no see. Happy to do my first chaos day this year. In the last week have implemented interesting features, which I would like to experiment with.
<a href="https://github.com/camunda/zeebe/issues/11416" target="_blank" rel="noopener noreferrer">Batch processing</a> was one of them.</p>
<p><strong>TL;DR;</strong> Chaos experiment failed. <!-- -->💥<!-- --> Batch processing doesn't seem to respect the configured limit, which causes issues with processing and influences the health of the system. We found a bug <!-- -->💪</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2023/02/23/Recursive-call-activity#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">​</a></h2>
<p>In today's chaos experiment, we want to experiment with <a href="https://github.com/camunda/zeebe/issues/11416" target="_blank" rel="noopener noreferrer">Batch processing</a> and how it can handle error conditions, like deploying an endless recursive process model.</p>
<p><img loading="lazy" alt="recursive process" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/call-8d5375c7dcbd4d2e36d20706dd178d3d.png" width="903" height="276" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2023/02/23/Recursive-call-activity#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>When we deploy such a process model and create an instance of it, we expect that the execution is done endlessly. In normal process models with batch processing, the execution of a process instance is done until a wait state is reached. In this process model, there exists no wait state. To handle such cases, we have implemented a batch limit, which can be configured via <a href="https://github.com/camunda/zeebe/blob/main/dist/src/main/config/broker.standalone.yaml.template#L695" target="_blank" rel="noopener noreferrer">maxCommandsInBatch</a>. This configuration is by default set to 100 commands. Meaning the stream processor will process 100 commands until it stops, to make room for other things.</p>
<p>We expect that our limit handling steps in during the execution and we can execute also other instances or, cancel the problematic process instance. Furthermore, we expect to stay healthy, we should be able to update our health check continuously.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2023/02/23/Recursive-call-activity#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<p>Before we can start with our experiment we need to start our benchmark Zeebe cluster. This has become easier now since I have written the last post. Previously we had to use the scripts and Makefile in the <a href="https://github.com/camunda/zeebe/tree/main/benchmarks/setup" target="_blank" rel="noopener noreferrer">zeebe/benchmark sub-directory</a>.</p>
<p>We have now provided new <a href="https://github.com/zeebe-io/benchmark-helm" target="_blank" rel="noopener noreferrer">Benchmark Helm charts</a>, based on our Camunda Platform Helm charts. They allow us to deploy a new zeebe benchmark setup via:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl create namespace zell-chaos # create a new namespace</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubens zell-chaos  # change context to a new namespace</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># deploy zeebe benchmark cluster - without starter and worker</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm install zell-chaos \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    zeebe-benchmark/zeebe-benchmark \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    --set starter.replicas=0 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    --set worker.replicas=0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>To deploy the model we can use <a href="https://github.com/zeebe-io/zeebe-chaos/releases/tag/zbchaos-v1.0.0" target="_blank" rel="noopener noreferrer">zbchaos v1.0.0</a>.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos deploy process --processModelPath call.bpmn </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{1 LEADER -1 call.bpmn 10  msg false 1 LEADER -1 2 LEADER -1 1677157340943 false false true false false 30 false -1 benchmark 30  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Deployed given process model call.bpmn, under key 2251799813685249!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><em>Note: Looks like we have some left-over debug logs, which we should remove.</em></p>
<p>To create an instance we can use:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ zbchaos verify instance-creation --bpmnProcessId super</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{1 LEADER -1  10  msg false 1 LEADER -1 2 LEADER -1 1677157569058 false false true false false 30 false -1 super 30  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The steady state was successfully verified!</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>After creating the instance we can observe the behavior of the Zeebe via <a href="https://grafana.dev.zeebe.io/" target="_blank" rel="noopener noreferrer">grafana</a>.</p>
<p>We can see that the processing starts immediately quite high and is continuously going on.</p>
<p><img loading="lazy" alt="general" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/general-96c61dbea3faf18172737f97412ce400.png" width="1842" height="421" class="img_ev3q"></p>
<p><strong>We have two instances running, one on partition three and one on partition one.</strong></p>
<p><em>One interesting fact is that the topology request rate is also up to 0.400 per second, so potentially every 2.5 seconds we send a topology request to the gateway. But there is no application deployed that does this. <a href="https://github.com/camunda/zeebe/pull/11599#discussion_r1109846523" target="_blank" rel="noopener noreferrer">I have recently found out again</a>, that we have the Zeebe client usage in the gateway to request the topology. Might be worth investigating whether this is an issue.</em></p>
<p>After observing this cluster for a while we can see that after around five minutes the cluster fails. The processing for the partitions breaks down to 1/10 of what was processed before. A bit later it looks like it tries to come back but, failed again.</p>
<p><img loading="lazy" alt="fail-general" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/fail-general-7f21e7fd29654bb0b4bac784a956c203.png" width="1853" height="975" class="img_ev3q"></p>
<p><em>We can see in the metrics that in between also the balancing was triggered. A feature we have as part of our Benchmark Helm charts.</em></p>
<p>The logs (at stack driver) doesn't give us many insights, <a href="https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Aresource.labels.project_id%3D%22zeebe-io%22%0Aresource.labels.location%3D%22europe-west1-b%22%0Aresource.labels.cluster_name%3D%22zeebe-cluster%22%0Aresource.labels.namespace_name%3D%22zell-chaos%22%0Alabels.k8s-pod%2Fapp%3D%22camunda-platform%22%0Alabels.k8s-pod%2Fapp_kubernetes_io%2Fcomponent%3D%22zeebe-broker%22%0Alabels.k8s-pod%2Fapp_kubernetes_io%2Finstance%3D%22zell-chaos%22%0Alabels.k8s-pod%2Fapp_kubernetes_io%2Fmanaged-by%3D%22Helm%22%0Alabels.k8s-pod%2Fapp_kubernetes_io%2Fname%3D%22zeebe%22%0Alabels.k8s-pod%2Fapp_kubernetes_io%2Fpart-of%3D%22camunda-platform%22;timeRange=2023-02-23T12:17:49.128812Z%2F2023-02-23T14:18:59.101Z;pinnedLogId=2023-02-23T13:13:40.945376476Z%2Fdr4gxdklsxtgx6h6;cursorTimestamp=2023-02-23T13:13:40.945376476Z?project=zeebe-io" target="_blank" rel="noopener noreferrer">except that we see that nodes becoming unhealthy</a>. Similar information we can see in the metrics, that followers are unhealthy.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Partition-1 failed, marking it as unhealthy: Broker-2{status=HEALTHY}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Detected 'UNHEALTHY' components. The current health status of components: [Partition-2{status=HEALTHY}, Partition-1{status=UNHEALTHY, issue=HealthIssue[message=null, throwable=null, cause=Broker-2-StreamProcessor-1{status=UNHEALTHY, issue=HealthIssue[message=actor appears blocked, throwable=null, cause=null]}]}, Partition-3{status=HEALTHY}]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Interesting insights we can get in our new Batch processing metrics. We see that at the beginning we use our limit of 100 commands per batch, but soon as we start with the recursion we use an enormous high batch processing command count.</p>
<p><img loading="lazy" alt="fail-batchprocessing.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/fail-batchprocessing-1db16026a70bf497036fdaf1df98bf26.png" width="1829" height="552" class="img_ev3q"></p>
<p>The new sequence metric shows similar results, so there must be a problem with not respecting the limit.</p>
<p><img loading="lazy" alt="sequencer" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/sequencer-e1680cd2da0acc84faf51d494411962b.png" width="1855" height="513" class="img_ev3q"></p>
<p>With this, I mark this chaos experiment as failed. We need to investigate this further and fix the related issue.<!-- -->💥</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="found-bugs">Found Bugs<a href="https://zeebe-io.github.io/zeebe-chaos/2023/02/23/Recursive-call-activity#found-bugs" class="hash-link" aria-label="Direct link to Found Bugs" title="Direct link to Found Bugs">​</a></h2>
<ul>
<li><a href="https://github.com/zeebe-io/zeebe-chaos/issues/323" target="_blank" rel="noopener noreferrer">zbchaos logs debug message on normal usage</a></li>
<li><a href="https://github.com/camunda/zeebe/issues/11799" target="_blank" rel="noopener noreferrer">Every 2.5 seconds we send a topology request, which is shown in the metrics</a></li>
<li><a href="https://github.com/camunda/zeebe/issues/11798" target="_blank" rel="noopener noreferrer">Batch processing doesn't respect the limit</a></li>
</ul>]]></content:encoded>
            <category>availability</category>
        </item>
        <item>
            <title><![CDATA[Message Correlation after Network Partition]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2022/08/31/Message-Correlation-after-Network-Partition</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2022/08/31/Message-Correlation-after-Network-Partition</guid>
            <pubDate>Wed, 31 Aug 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[In the last weeks, we made several changes in our core components, we introduce some new abstractions, and changed how we communicate between partitions.]]></description>
            <content:encoded><![CDATA[<p>In the last weeks, we made several changes in our core components, we introduce some new abstractions, and changed how we communicate between partitions.</p>
<p>Due to these changes, we thought it might make sense to run some more chaos experiments in that direction and area since our benchmarks also recently found some interesting edge cases.</p>
<p>Today we experimented with Message Correlation and what happens when a network partition disturbs the correlation process.</p>
<p><strong>TL;DR;</strong> The experiment was partially successful (after retry), we were able to publish messages during a network partition that have been correlated after the network partition. We need to verify whether we can also publish messages before a network partition and during the partition create the related instances.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2022/08/31/Message-Correlation-after-Network-Partition#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">​</a></h2>
<p>The experiment is related to our previously described <a href="https://zeebe-io.github.io/zeebe-chaos/2022/08/02/deployment-distribution">deployment distribution experiment</a>.</p>
<p>When a user/client publishes a message, the message will be sent to a certain partition, based on the correlation key. There is some calculation going on related to the hashcode and the partition count.
This calculation is deterministic in order to find later the message again if we reach a message catch event.</p>
<p>A message can specify a time-to-live (TTL), <a href="https://docs.camunda.io/docs/components/concepts/messages/#message-buffering" target="_blank" rel="noopener noreferrer">which allows buffering that message</a>. If later a process instance is created and the TTL is not exceeded the message can be still correlated. The creation of process instances
happens round-robin on the existing/available partitions (this is controlled by the gateway). When a process instance is created and reaches a message catch event it will be based on the correlation key search for a message on the expected partition. <em>Actually this happens based on subscriptions, for more details see the <a href="https://docs.camunda.io/docs/components/concepts/messages/#message-subscriptions" target="_blank" rel="noopener noreferrer">docs</a> or the <a href="https://github.com/zeebe-io/enhancements/blob/master/ZEP004-wf-stream-processing.md#message-intermediate-catch-event" target="_blank" rel="noopener noreferrer">ZEP-4</a>.</em> If the message still exists (TTL didn't expire) and this message <a href="https://docs.camunda.io/docs/components/concepts/messages/#message-cardinality" target="_blank" rel="noopener noreferrer">wasn't already correlated to the same process definition</a> then it will be correlated.</p>
<p>Since both partitions can be on different leader nodes this requires some network communication, which can be interrupted/disturbed.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2022/08/31/Message-Correlation-after-Network-Partition#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>We expect that if the network between the partition where the message was published and where the process instance was created is interrupted that no message correlation happens. But after the network recovers, we expect further that the message will be correlated and the process instance can continue.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2022/08/31/Message-Correlation-after-Network-Partition#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<p>As a setup, I installed our benchmarks, with Operate enabled.
This allows us to also view the details in Operate.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ diff zeebe-values.yaml ../default/zeebe-values.yaml </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">5,8d4</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;   identity:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;     auth:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;       enabled: false</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt; </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">28c24</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;   containerSecurityContext:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;   podSecurityContext:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">139c135</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;   enabled: true</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;   enabled: false</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>During the experiment, it turned out that the <code>podSecurityContext</code> is outdated.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="experiment-description">Experiment Description<a href="https://zeebe-io.github.io/zeebe-chaos/2022/08/31/Message-Correlation-after-Network-Partition#experiment-description" class="hash-link" aria-label="Direct link to Experiment Description" title="Direct link to Experiment Description">​</a></h4>
<p>Since we want to automate this experiment soon, or later I thought it would be a good idea to use the <a href="https://docs.camunda.io/docs/components/concepts/process-instance-creation/#create-and-await-results" target="_blank" rel="noopener noreferrer">create process instance with result</a>. We would start the following process:</p>
<p><img loading="lazy" alt="msg-catch" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/msg-catch-dba2526317c719b66db25ef1dfaff2a4.png" width="723" height="207" class="img_ev3q"></p>
<p>Before we start the process we need to publish the message to a certain partition and create a network partition between two partitions. After that, we can create the PI and verify that the message correlation shouldn't happen. Afterward, we would delete the network partition and verify that the process instance is completed.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="details">Details<a href="https://zeebe-io.github.io/zeebe-chaos/2022/08/31/Message-Correlation-after-Network-Partition#details" class="hash-link" aria-label="Direct link to Details" title="Direct link to Details">​</a></h4>
<p>To make the experiment easier to reproduce and allow us to experiment in different directions later as well I extend our new chaos cli (zbchaos), which I created during the last hack days. I will write a separate blog post about this tool soon.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="message-publish">Message Publish<a href="https://zeebe-io.github.io/zeebe-chaos/2022/08/31/Message-Correlation-after-Network-Partition#message-publish" class="hash-link" aria-label="Direct link to Message Publish" title="Direct link to Message Publish">​</a></h5>
<p>I added a new feature (<a href="https://github.com/zeebe-io/zeebe-chaos/pull/166" target="_blank" rel="noopener noreferrer">PR #166</a>) that allows us to publish a message to a specific partition:</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ ./zbchaos publish message -v --partitionId 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connecting to zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Successfully created port forwarding tunnel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Send message 'msg', with correaltion key '2' (ASCII: 50) </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Message was sent and returned key 6755399441055796, which corresponds to partition: 3</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="extend-steady-state-verification">Extend Steady-state verification<a href="https://zeebe-io.github.io/zeebe-chaos/2022/08/31/Message-Correlation-after-Network-Partition#extend-steady-state-verification" class="hash-link" aria-label="Direct link to Extend Steady-state verification" title="Direct link to Extend Steady-state verification">​</a></h5>
<p>For the steady-state verification, multiple enhancements have been added.</p>
<ol>
<li>Previously the <code>zbchaos</code> didn't allow us to create instances of specific models, which is now added as new feature (<a href="https://github.com/zeebe-io/zeebe-chaos/pull/167" target="_blank" rel="noopener noreferrer">PR #167</a>).</li>
<li>In order to await the process instance completion a new flag was added <code>--awaitResult</code>, which allows us to await the PI completeness.</li>
<li>To make sure that our message can be correlated we have to set the right correlationKey/value. This means we need to create instances with certain variables, which is now possible as well (<code>--variables</code>).</li>
</ol>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">./zbchaos verify steady-state -h</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Verifies the steady state of the Zeebe system.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">A process model will be deployed and process instances are created until the required partition is reached.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Usage:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  zbchaos verify steady-state [flags]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Flags:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      --awaitResult               Specify whether the completion of the created process instance should be awaited.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -h, --help                      help for steady-state</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      --partitionId int           Specify the id of the partition (default 1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      --processModelPath string   Specify the path to a BPMN process model, which should be deployed and an instance should be created of.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      --variables string          Specify the variables for the process instance. Expect json string.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Global Flags:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -v, --verbose   verbose output</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="execution-of-the-experiment">Execution of the Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2022/08/31/Message-Correlation-after-Network-Partition#execution-of-the-experiment" class="hash-link" aria-label="Direct link to Execution of the Experiment" title="Direct link to Execution of the Experiment">​</a></h4>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$./zbchaos verify readiness -v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connecting to zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">All Zeebe nodes are running.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>After checking the readiness we can check what the current topology is:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ ./zbchaos topology</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Node      |Partition 1         |Partition 2         |Partition 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">0         |LEADER (HEALTHY)    |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1         |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)    |FOLLOWER (HEALTHY)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2         |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We can see that the leaders are well distributed. I pick partition 3 as our message publish partition, and partition 1 as our partition for the process instance. Since we can't control really the round-robin mechanism, we need to create multiple messages and multiple process instances (for each partition). During our experiment, we will only look at the instance on partition one.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ ./zbchaos publish message -v --partitionId 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connecting to zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Successfully created port forwarding tunnel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Send message 'msg', with correaltion key '2' (ASCII: 50) </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Message was sent and returned key 6755399441055745, which corresponds to partition: 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[zell go-chaos/ cluster: zeebe-cluster ns:zell-chaos]$ ./zbchaos publish message -v --partitionId 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connecting to zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Successfully created port forwarding tunnel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Send message 'msg', with correaltion key '2' (ASCII: 50) </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Message was sent and returned key 6755399441055746, which corresponds to partition: 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[zell go-chaos/ cluster: zeebe-cluster ns:zell-chaos]$ ./zbchaos publish message -v --partitionId 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connecting to zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Successfully created port forwarding tunnel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Send message 'msg', with correaltion key '2' (ASCII: 50) </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Message was sent and returned key 6755399441055747, which corresponds to partition: 3</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Creating the network partition:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">./zbchaos disconnect brokers --broker1PartitionId 3 --broker1Role LEADER --broker2PartitionId 1 --broker2Role LEADER -v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Successfully created port forwarding tunnel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Found Broker zell-chaos-zeebe-2 as LEADER for partition 3.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Found Broker zell-chaos-zeebe-0 as LEADER for partition 1.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Execute ["apt" "-qq" "update"] on pod zell-chaos-zeebe-2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Disconnect zell-chaos-zeebe-2 from zell-chaos-zeebe-0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Disconnect zell-chaos-zeebe-0 from zell-chaos-zeebe-2</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Creating the process instance and await the result:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ ./zbchaos verify steady-state --awaitResult --partitionId 1 --processModelPath ../msg-catch.bpmn --variables '{"key":"2"}'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Unfortunately, I missed the verbose flag so we can't really see the output. But if failed later with:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Encountered an error during process instance creation. Error: rpc error: code = DeadlineExceeded desc = Time out between gateway and broker: Request ProtocolRequest{id=422, subject=command-api-1, sender=10.0.20.4:26502, payload=byte[]{length=153, hash=1559826040}} to zell-chaos-zeebe-2.zell-chaos-zeebe.zell-chaos.svc:26501 timed out in PT15S</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Encountered an error during process instance creation. Error: rpc error: code = DeadlineExceeded desc = Time out between gateway and broker: Request ProtocolRequest{id=441, subject=command-api-2, sender=10.0.20.4:26502, payload=byte[]{length=153, hash=-1786651527}} to zell-chaos-zeebe-1.zell-chaos-zeebe.zell-chaos.svc:26501 timed out in PT15S</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Encountered an error during process instance creation. Error: rpc error: code = NotFound desc = Command 'CREATE_WITH_AWAITING_RESULT' rejected with code 'NOT_FOUND': Expected to find process definition with key '2251799813685249', but none found</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">panic: Expected to create process instance on partition 1, but timed out after 30s.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">goroutine 1 [running]:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">github.com/zeebe-io/zeebe-chaos/go-chaos/cmd.glob..func10(0x247f740?, {0x1758c60?, 0x7?, 0x7?})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	/home/zell/goPath/src/github.com/zeebe-io/zeebe-chaos/go-chaos/cmd/verify.go:97 +0x1c5</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">github.com/spf13/cobra.(*Command).execute(0x247f740, {0xc000426540, 0x7, 0x7})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	/home/zell/goPath/pkg/mod/github.com/spf13/cobra@v1.5.0/command.go:876 +0x67b</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">github.com/spf13/cobra.(*Command).ExecuteC(0x24808c0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	/home/zell/goPath/pkg/mod/github.com/spf13/cobra@v1.5.0/command.go:990 +0x3bd</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">github.com/spf13/cobra.(*Command).Execute(...)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	/home/zell/goPath/pkg/mod/github.com/spf13/cobra@v1.5.0/command.go:918</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">github.com/zeebe-io/zeebe-chaos/go-chaos/cmd.Execute()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	/home/zell/goPath/src/github.com/zeebe-io/zeebe-chaos/go-chaos/cmd/root.go:61 +0x25</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">main.main()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	/home/zell/goPath/src/github.com/zeebe-io/zeebe-chaos/go-chaos/main.go:8 +0x17</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>I retried it:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ ./zbchaos verify steady-state --awaitResult --partitionId 1 --processModelPath ../msg-catch.bpmn --variables '{"key":"2"}' -v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connecting to zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Successfully created port forwarding tunnel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Deploy file ../msg-catch.bpmn (size: 2980 bytes).</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Deployed process model ../msg-catch.bpmn successful with key 2251799813685249.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Create process instance with defition key 2251799813685249 [variables: '{"key":"2"}', awaitResult: true]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Encountered an error during process instance creation. Error: rpc error: code = DeadlineExceeded desc = Time out between gateway and broker: Request ProtocolRequest{id=509, subject=command-api-1, sender=10.0.20.4:26502, payload=byte[]{length=153, hash=1559826040}} to zell-chaos-zeebe-2.zell-chaos-zeebe.zell-chaos.svc:26501 timed out in PT15S</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Create process instance with defition key 2251799813685249 [variables: '{"key":"2"}', awaitResult: true]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Encountered an error during process instance creation. Error: rpc error: code = DeadlineExceeded desc = Time out between gateway and broker: Request ProtocolRequest{id=530, subject=command-api-2, sender=10.0.20.4:26502, payload=byte[]{length=153, hash=-1786651527}} to zell-chaos-zeebe-1.zell-chaos-zeebe.zell-chaos.svc:26501 timed out in PT14.999S</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Create process instance with defition key 2251799813685249 [variables: '{"key":"2"}', awaitResult: true]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Encountered an error during process instance creation. Error: rpc error: code = NotFound desc = Command 'CREATE_WITH_AWAITING_RESULT' rejected with code 'NOT_FOUND': Expected to find process definition with key '2251799813685249', but none found</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">panic: Expected to create process instance on partition 1, but timed out after 30s.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">goroutine 1 [running]:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">github.com/zeebe-io/zeebe-chaos/go-chaos/cmd.glob..func10(0x247f740?, {0x1758c60?, 0x8?, 0x8?})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	/home/zell/goPath/src/github.com/zeebe-io/zeebe-chaos/go-chaos/cmd/verify.go:97 +0x1c5</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">github.com/spf13/cobra.(*Command).execute(0x247f740, {0xc00007e500, 0x8, 0x8})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	/home/zell/goPath/pkg/mod/github.com/spf13/cobra@v1.5.0/command.go:876 +0x67b</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">github.com/spf13/cobra.(*Command).ExecuteC(0x24808c0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	/home/zell/goPath/pkg/mod/github.com/spf13/cobra@v1.5.0/command.go:990 +0x3bd</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">github.com/spf13/cobra.(*Command).Execute(...)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	/home/zell/goPath/pkg/mod/github.com/spf13/cobra@v1.5.0/command.go:918</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">github.com/zeebe-io/zeebe-chaos/go-chaos/cmd.Execute()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	/home/zell/goPath/src/github.com/zeebe-io/zeebe-chaos/go-chaos/cmd/root.go:61 +0x25</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">main.main()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	/home/zell/goPath/src/github.com/zeebe-io/zeebe-chaos/go-chaos/main.go:8 +0x17</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>And got a similar exception. Taking a look at Operate we can see that process instances are created. It is likely that the await timed out since the message hasn't been correlated but the returned error is a bit unclear. Interesting is that on partition two the message is also not correlated.</p>
<p><img loading="lazy" alt="operate" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/operate-efd0c9d98a1666f44bf235ba5bf4cdf2.png" width="1800" height="794" class="img_ev3q"></p>
<p>Removing the network partition:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ ./zbchaos connect brokers -v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connecting to zell-chaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Execute ["sh" "-c" "command -v ip"] on pod zell-chaos-zeebe-0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">/usr/sbin/ip</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Execute ["sh" "-c" "ip route | grep -m 1 unreachable"] on pod zell-chaos-zeebe-0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Execute ["sh" "-c" "ip route del unreachable 10.0.17.8"] on pod zell-chaos-zeebe-0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Connected zell-chaos-zeebe-0 again, removed unreachable routes.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Execute ["sh" "-c" "command -v ip"] on pod zell-chaos-zeebe-1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Error on connection Broker: zell-chaos-zeebe-1. Error: Execution exited with exit code 127 (Command not found). It is likely that the broker was not disconnected or restarted in between.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Execute ["sh" "-c" "command -v ip"] on pod zell-chaos-zeebe-2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Error on connection Broker: zell-chaos-zeebe-2. Error: Execution exited with exit code 127 (Command not found). It is likely that the broker was not disconnected or restarted in between.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>It looks like the Broker-2 was restarted in between, which is really the case if we check the <code>kubectl get pods</code></p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[zell go-chaos/ cluster: zeebe-cluster ns:zell-chaos]$ kgpo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                        READY   STATUS      RESTARTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">camunda-platform-curator-27698835-pwdjh     0/1     Completed   0          9m20s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-0                      1/1     Running     0          12m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-1                      1/1     Running     0          12m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticsearch-master-2                      1/1     Running     0          12m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-operate-64bbc6794d-vqtnc         1/1     Running     0          12m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-0                          1/1     Running     0          12m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-1                          1/1     Running     0          12m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-2                          1/1     Running     0          2m48s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-795f87fd64-c9mf4   1/1     Running     0          12m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-795f87fd64-h5d9c   1/1     Running     0          12m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zell-chaos-zeebe-gateway-795f87fd64-nlr5v   1/1     Running     0          12m</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The topology has also completely changed.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ ./zbchaos topology</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Node      |Partition 1         |Partition 2         |Partition 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">0         |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1         |LEADER (HEALTHY)    |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2         |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)    |FOLLOWER (HEALTHY)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>After connecting again the instances haven't been executed. My guess is that the TTL was already reached.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="rerun">Rerun<a href="https://zeebe-io.github.io/zeebe-chaos/2022/08/31/Message-Correlation-after-Network-Partition#rerun" class="hash-link" aria-label="Direct link to Rerun" title="Direct link to Rerun">​</a></h5>
<p>I will disconnect again partitions one and three and publish a message to partition three. Afterward I will connect them again and see whether the message is correlated.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">./zbchaos disconnect brokers --broker1PartitionId 3 --broker1Role LEADER --broker2PartitionId 1 --broker2Role LEADER -v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./zbchaos publish message -v --partitionId 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./zbchaos publish message -v --partitionId 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./zbchaos publish message -v --partitionId 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./zbchaos connect brokers -v</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Take a look at Operate again:</p>
<p><img loading="lazy" alt="operate2" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/operate2-c96a932956d4207bff7ce70f78cb7544.png" width="1851" height="738" class="img_ev3q"></p>
<p>We can see that the experiment was successful, and the message has been correlated even if they are published during a network partition. <!-- -->🎉</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="found-bugs">Found Bugs<a href="https://zeebe-io.github.io/zeebe-chaos/2022/08/31/Message-Correlation-after-Network-Partition#found-bugs" class="hash-link" aria-label="Direct link to Found Bugs" title="Direct link to Found Bugs">​</a></h2>
<ul>
<li>I learned that the go zeebe client, doesn't set a default TTL which was interesting to find out (and somehow unexpected).</li>
<li>The zbchaos uses always the same port for connecting to the kubernetes and zeebe cluster, which makes it impossible to run multiple commands. We should use random ports to make this possible.</li>
</ul>]]></content:encoded>
            <category>availability</category>
        </item>
        <item>
            <title><![CDATA[Bring Deployment distribution experiment back]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2022/08/02/deployment-distribution</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2022/08/02/deployment-distribution</guid>
            <pubDate>Tue, 02 Aug 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[We encountered recently a severe bug zeebe#9877 and I was wondering why we haven't spotted it earlier, since we have chaos experiments for it. I realized two things:]]></description>
            <content:encoded><![CDATA[<p>We encountered recently a severe bug <a href="https://github.com/camunda/zeebe/issues/9877" target="_blank" rel="noopener noreferrer">zeebe#9877</a> and I was wondering why we haven't spotted it earlier, since we have chaos experiments for it. I realized two things:</p>
<ol>
<li>The experiments only check for parts of it (BPMN resource only). The production code has changed, and a new feature has been added (DMN) but the experiments/tests haven't been adjusted.</li>
<li>More importantly we disabled the automated execution of the deployment distribution experiment because it was flaky due to a missing standalone gateway in Camunda Cloud SaaS <a href="https://github.com/zeebe-io/zeebe-chaos/issues/61" target="_blank" rel="noopener noreferrer">zeebe-io/zeebe-chaos#61</a>. This is no longer the case, see <a href="https://zeebe-io.github.io/zeebe-chaos/2022/02/15/Standalone-Gateway-in-CCSaaS">Standalone Gateway in CCSaaS</a></li>
</ol>
<p>On this chaos day I want to bring the automation of this chaos experiment back to life. If I have still time I want to enhance the experiment.</p>
<p><strong>TL;DR;</strong> The experiment still worked, and our deployment distribution is still resilient against network partitions. It also works with DMN resources. I can enable the experiment again, and we can close <a href="https://github.com/zeebe-io/zeebe-chaos/issues/61" target="_blank" rel="noopener noreferrer">zeebe-io/zeebe-chaos#61</a>. Unfortunately, we were not able to reproduce <a href="https://github.com/camunda/zeebe/issues/9877" target="_blank" rel="noopener noreferrer">zeebe#9877</a> but we did some good preparation work for it.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2022/08/02/deployment-distribution#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">​</a></h2>
<p>To recap, when a deployment is created by a client it is sent to the partition one leader. Partition one is in charge of distributing the deployment to the other partitions. That means it will send the deployment to the other partition leaders, this is retried as long no ACK was received from the corresponding partition leader.</p>
<p><img loading="lazy" alt="deploymentDistribution" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/deploymentDistribution-d300fff30d9d6cab27d9fe01c6504cd4.png" width="871" height="491" class="img_ev3q"></p>
<p>We already have covered that in more detail in another chaos day you can read <a href="https://zeebe-io.github.io/zeebe-chaos/2021/01/26/deployments">here</a>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2022/08/02/deployment-distribution#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/deploymentDistributionExperiment-8f120f1fafbca4d31ecf2fb0f8e909ba.png" width="933" height="515" class="img_ev3q"></p>
<p>As you can see in the image we will create an asymmetric network partition and disconnect the partition one leader from partition three. That means the sending to partition three will not be possible. We use here an asymmetric network partition, in order to reduce the probability to cause a leader change. The partition one leader is a follower of partition three and will still receive heartbeats.</p>
<p>After disconnecting the leaders we deploy multiple process versions and after connecting the leaders again we expect that the deployments are distributed. It is expected that we can create instances of the last version on all partitions.</p>
<p>We will run the existing experiment against the latest minor version, to verify whether the experiment still works. When we enable the experiment again for automation it will be executed against SNAPSHOT automatically.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2022/08/02/deployment-distribution#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="setup">Setup<a href="https://zeebe-io.github.io/zeebe-chaos/2022/08/02/deployment-distribution#setup" class="hash-link" aria-label="Direct link to Setup" title="Direct link to Setup">​</a></h4>
<p>As a first step, we created a new Production-S cluster, which has three partitions, three nodes (brokers), and two standalone gateways. The Zeebe version was set to 8.0.4 (latest minor).</p>
<p>It was a while since I used the <a href="https://chaostoolkit.org/" target="_blank" rel="noopener noreferrer">chaostoolkit</a> which is the reason I had to reinstall it again, which is quite a simple see <a href="https://chaostoolkit.org/reference/usage/install/" target="_blank" rel="noopener noreferrer">here</a>.</p>
<p>TL;DR:</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">python3 -m venv ~/.venvs/chaostk</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">source  ~/.venvs/chaostk/bin/activate</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip install -U chaostoolkit</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chaos --version</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="executing-chaos-toolkit">Executing chaos toolkit<a href="https://zeebe-io.github.io/zeebe-chaos/2022/08/02/deployment-distribution#executing-chaos-toolkit" class="hash-link" aria-label="Direct link to Executing chaos toolkit" title="Direct link to Executing chaos toolkit">​</a></h4>
<p>As mentioned, the deployment distribution was not enabled for Production-S clusters, which is currently the only configuration we test via <a href="https://github.com/zeebe-io/zeebe-cluster-testbench" target="_blank" rel="noopener noreferrer">Zeebe Testbench</a>. We have to use the experiment that is defined under <a href="https://github.com/zeebe-io/zeebe-chaos/tree/master/chaos-workers/chaos-experiments/camunda-cloud/production-l/deployment-distribution" target="_blank" rel="noopener noreferrer">production-l/deployment-distribution</a>, which is the same*.</p>
<sub>* That is not 100% true. During running the Production-l experiment I realized that it made some assumptions regarding the <a href="https://github.com/zeebe-io/zeebe-chaos/blob/master/chaos-workers/chaos-experiments/scripts/disconnect-leaders-one-way.sh#L19">partition count</a> which needs to be adjusted for the Production-S setup.</sub>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"> chaos run production-l/deployment-distribution/experiment.json </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:35:25 INFO] Validating the experiment's syntax</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:35:25 INFO] Experiment looks valid</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:35:25 INFO] Running experiment: Zeebe deployment distribution</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:35:25 INFO] Steady-state strategy: default</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:35:25 INFO] Rollbacks strategy: default</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:35:25 INFO] Steady state hypothesis: Zeebe is alive</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:35:25 INFO] Probe: All pods should be ready</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:35:25 INFO] Steady state hypothesis is met!</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:35:25 INFO] Playing your experiment's method now...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:35:25 INFO] Action: Enable net_admin capabilities</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:35:26 WARNING] This process returned a non-zero exit code. This may indicate some error and not what you expected. Please have a look at the logs.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:35:26 INFO] Pausing after activity for 180s...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:38:26 INFO] Probe: All pods should be ready</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:38:33 INFO] Action: Create network partition between leaders</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:38:34 WARNING] This process returned a non-zero exit code. This may indicate some error and not what you expected. Please have a look at the logs.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:38:34 INFO] Action: Deploy different deployment versions.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:38:40 INFO] Action: Delete network partition</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:38:42 INFO] Probe: Create process instance of latest version on partition one</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:38:43 INFO] Probe: Create process instance of latest version on partition two</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:38:44 INFO] Probe: Create process instance of latest version on partition three</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:38:44 INFO] Steady state hypothesis: Zeebe is alive</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:38:44 INFO] Probe: All pods should be ready</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:38:45 INFO] Steady state hypothesis is met!</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:38:45 INFO] Let's rollback...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:38:45 INFO] No declared rollbacks, let's move on.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 09:38:45 INFO] Experiment ended with status: completed</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Based on the tool output it looks like it succeed, to make sure it really worked, we will take a look at the logs in stackdriver.</p>
<p>In the following logs we can see that deployment distribution is failing for partition 3 and is retried, which is expected and what we wanted.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:53.114 CEST zeebe Failed to receive deployment response for partition 3 (on topic 'deployment-response-2251799813685347-3'). Retrying</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:53.115 CEST zeebe Deployment DISTRIBUTE command for deployment 2251799813685347 was written on partition 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:53.157 CEST zeebe Received new exporter state {elasticsearch=228, MetricsExporter=228} </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:53.157 CEST zeebe Received new exporter state {elasticsearch=228, MetricsExporter=228}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:53.241 CEST zeebe Received new exporter state {elasticsearch=232, MetricsExporter=232}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:53.241 CEST zeebe Received new exporter state {elasticsearch=232, MetricsExporter=232}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:53.464 CEST zeebe Failed to receive deployment response for partition 3 (on topic 'deployment-response-2251799813685351-3'). Retrying</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:53.466 CEST zeebe Deployment DISTRIBUTE command for deployment 2251799813685351 was written on partition 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:54.216 CEST zeebe Failed to receive deployment response for partition 3 (on topic 'deployment-response-2251799813685353-3'). Retrying</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:54.218 CEST zeebe Deployment DISTRIBUTE command for deployment 2251799813685353 was written on partition 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:54.224 CEST zeebe Failed to receive deployment response for partition 3 (on topic 'deployment-response-2251799813685355-3'). Retrying</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:54.225 CEST zeebe Deployment DISTRIBUTE command for deployment 2251799813685355 was written on partition 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:55.055 CEST zeebe Failed to receive deployment response for partition 3 (on topic 'deployment-response-2251799813685359-3'). Retrying</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:55.057 CEST zeebe Deployment DISTRIBUTE command for deployment 2251799813685359 was written on partition 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:55.689 CEST zeebe Received new exporter state {elasticsearch=299, MetricsExporter=299}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:55.690 CEST zeebe Received new exporter state {elasticsearch=299, MetricsExporter=299}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:56.089 CEST zeebe Failed to receive deployment response for partition 3 (on topic 'deployment-response-2251799813685357-3'). Retrying</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:56.090 CEST zeebe Deployment DISTRIBUTE command for deployment 2251799813685357 was written on partition 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:56.272 CEST zeebe Failed to receive deployment response for partition 3 (on topic 'deployment-response-2251799813685363-3'). Retrying</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:56.273 CEST zeebe Deployment DISTRIBUTE command for deployment 2251799813685363 was written on partition 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:56.920 CEST zeebe Failed to receive deployment response for partition 3 (on topic 'deployment-response-2251799813685361-3'). Retrying</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:38:56.922 CEST zeebe Deployment DISTRIBUTE command for deployment 2251799813685361 was written on partition 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2022-08-02 09:39:08.369 CEST zeebe Received new exporter state {elasticsearch=252, MetricsExporter=252}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>At some point, the retry stopped, and we can see in the experiment output that we were able to start process instances on all partitions. This is great because it means the experiment was successfully executed and our deployment distribution is failure tolerant.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="enhancement">Enhancement<a href="https://zeebe-io.github.io/zeebe-chaos/2022/08/02/deployment-distribution#enhancement" class="hash-link" aria-label="Direct link to Enhancement" title="Direct link to Enhancement">​</a></h4>
<p>As described earlier the current experiment deploys a BPMN process model only. It looks like this:</p>
<p><img loading="lazy" alt="v1" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/multiVersionModel-bae5089e350bb8e3ef1f11b3e01be25c.png" width="999" height="276" class="img_ev3q"></p>
<p>In order to make DMN part of the experiment, we change the service task to a <a href="https://docs.camunda.io/docs/components/modeler/bpmn/business-rule-tasks/" target="_blank" rel="noopener noreferrer">Business Rule task</a>.</p>
<p><img loading="lazy" alt="v2" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/multiVersionModelv2-7fa903fb40c6a640222206e5922de001.png" width="999" height="276" class="img_ev3q"></p>
<p>The decision is really simple and just defines a static input and returns that as output.</p>
<p><img loading="lazy" alt="decision" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/decision-3e1b9db140fbc19b0250ee1fd804a33d.png" width="1213" height="471" class="img_ev3q"></p>
<p>When we run our experiment and create process instances on all partitions the DMN needs to be available otherwise the execution would fail. Currently, we can't specify a specific version of the DMN in the Business Rule Task (always the latest will be executed). Because of that, we will not deploy different DMN model versions, since it is currently not that easy to verify whether the right version was chosen.</p>
<p>After adjusting the model and adjusting the script, we run the experiment again.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ chaos run production-l/deployment-distribution/experiment.json </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:05:12 INFO] Validating the experiment's syntax</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:05:12 INFO] Experiment looks valid</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:05:12 INFO] Running experiment: Zeebe deployment distribution</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:05:12 INFO] Steady-state strategy: default</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:05:12 INFO] Rollbacks strategy: default</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:05:12 INFO] Steady state hypothesis: Zeebe is alive</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:05:12 INFO] Probe: All pods should be ready</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:05:13 INFO] Steady state hypothesis is met!</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:05:13 INFO] Playing your experiment's method now...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:05:13 INFO] Action: Enable net_admin capabilities</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:05:13 WARNING] This process returned a non-zero exit code. This may indicate some error and not what you expected. Please have a look at the logs.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:05:13 INFO] Pausing after activity for 180s...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:08:14 INFO] Probe: All pods should be ready</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:08:14 INFO] Action: Create network partition between leaders</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:08:16 WARNING] This process returned a non-zero exit code. This may indicate some error and not what you expected. Please have a look at the logs.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:08:16 INFO] Action: Deploy different deployment versions.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:08:25 INFO] Action: Delete network partition</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:08:27 INFO] Probe: Create process instance of latest version on partition one</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:08:27 INFO] Probe: Create process instance of latest version on partition two</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:08:28 INFO] Probe: Create process instance of latest version on partition three</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:08:29 INFO] Steady state hypothesis: Zeebe is alive</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:08:29 INFO] Probe: All pods should be ready</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:08:29 INFO] Steady state hypothesis is met!</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:08:29 INFO] Let's rollback...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:08:29 INFO] No declared rollbacks, let's move on.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[2022-08-02 11:08:29 INFO] Experiment ended with status: completed</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>It succeeded as well.</p>
<p>Taking a look at Operate we can see some incidents.</p>
<p><img loading="lazy" alt="dmn-error" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/dmn-error-422b88cf3273e715c442c76ecce338d9.png" width="1000" height="175" class="img_ev3q"></p>
<p>It seems the process instance execution runs into the Business Rule Task, but the DMN resource was not available on the partition.</p>
<p><img loading="lazy" alt="dmn-retry" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/dmn-retry-665320690997b2566a40ac99505a2f84.png" width="2528" height="698" class="img_ev3q"></p>
<p>After retrying in Operate the incident was resolved, which means the DMN resource was distributed at that time.</p>
<p>We can adjust the experiment further to await the result of the process execution, but I will stop here and leave that for a later point.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="reproduce-our-bug">Reproduce our bug<a href="https://zeebe-io.github.io/zeebe-chaos/2022/08/02/deployment-distribution#reproduce-our-bug" class="hash-link" aria-label="Direct link to Reproduce our bug" title="Direct link to Reproduce our bug">​</a></h4>
<p>The current experiment didn't reproduce the bug in <a href="https://github.com/camunda/zeebe/issues/9877" target="_blank" rel="noopener noreferrer">zeebe#9877</a>, since the DMN resource has to be distributed multiple times. Currently, we create a network partition such that the distribution doesn't work at all.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/deploymentDistributionExperimentV2-271448cf9bf1690fc24acdd0f89581d9.png" width="933" height="515" class="img_ev3q"></p>
<p>In order to reproduce our scenario, we can set the network partition in the other direction, such that the acknowledgment is not received by the leader one.</p>
<p>Adjusting the experiment (script) like this:</p>
<div class="language-diff codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-diff codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">-retryUntilSuccess disconnect "$leader" "$leaderTwoIp"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+retryUntilSuccess disconnect "$leaderTwo" "$leaderIp"</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Should do the trick, but I was not yet able to reproduce the issue with 8.0.4. It seems we need to spend some more time reproducing the bug. But I think with today's changes we already did a good step in the right direction, and we can improve based on that. I will create a follow-up issue to improve our experiment.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="further-work">Further Work<a href="https://zeebe-io.github.io/zeebe-chaos/2022/08/02/deployment-distribution#further-work" class="hash-link" aria-label="Direct link to Further Work" title="Direct link to Further Work">​</a></h2>
<p>Based on today's outcome we can enable again the Deployment Distribution experiment for Production-S, such that is executed by Zeebe Testbench (our automation tooling). We can close <a href="https://github.com/zeebe-io/zeebe-chaos/issues/61" target="_blank" rel="noopener noreferrer">zeebe-io/zeebe-chaos#61</a></p>
<p>We should adjust our Chaos Worker implementation such that we also deploy DMN resources as we did in today's Chaos Day, since the scripts we changed aren't used in the automation.</p>
<p>I will create a follow-up issue to improve our experiment, so we can reproduce the critical bug.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="found-bugs">Found Bugs<a href="https://zeebe-io.github.io/zeebe-chaos/2022/08/02/deployment-distribution#found-bugs" class="hash-link" aria-label="Direct link to Found Bugs" title="Direct link to Found Bugs">​</a></h2>
<p><em>none</em></p>]]></content:encoded>
            <category>availability</category>
        </item>
        <item>
            <title><![CDATA[Standalone Gateway in CCSaaS]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2022/02/15/Standalone-Gateway-in-CCSaaS</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2022/02/15/Standalone-Gateway-in-CCSaaS</guid>
            <pubDate>Tue, 15 Feb 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[We recently introduced the Zeebe Standalone Gateway in CCSaaS. Today I wanted to do a first simple]]></description>
            <content:encoded><![CDATA[<p>We recently introduced the Zeebe Standalone Gateway in CCSaaS. Today I wanted to do a first simple
chaos experiment with the gateway, where we just restart one gateway.</p>
<p>Ideally in the future we could enable some gateway chaos experiments again, which we currently only support for <a href="https://github.com/zeebe-io/zeebe-chaos/tree/master/chaos-workers/chaos-experiments/helm" target="_blank" rel="noopener noreferrer">helm</a>.</p>
<p><strong>TL;DR;</strong> Our Camunda Cloud clusters can handle gateway restarts without issues.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2022/02/15/Standalone-Gateway-in-CCSaaS#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">​</a></h2>
<p>This experiment is a simple restart / kill pod experiment. We want to verify that our cluster
can still make progress even if a gateway is restarted / killed in between. Currently, we are running two gateway replicas in the CCSaaS.</p>
<p>In order to start with our experiment we created a new CCSaaS cluster with a <code>Production - S</code> plan, and the latest version (1.3.4).
To run some load on the cluster we used the cloud benchmark deployments, which you can find <a href="https://github.com/camunda-cloud/zeebe/tree/main/benchmarks/setup/cloud-default" target="_blank" rel="noopener noreferrer">here</a>.
The load was rather low with ~ 100 PI/s.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2022/02/15/Standalone-Gateway-in-CCSaaS#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p><em>Hypothesis: When restarting / killing a zeebe standalone gateway we expect only a small
impact on current requests, new requests should be routed to the right gateway and the cluster can
make progress.</em></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2022/02/15/Standalone-Gateway-in-CCSaaS#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<p>After creating the cluster and starting the benchmark we checked the current resource usage, to find a cluster which does most of the work. It looks like that the requests are well distributed.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[zell zell-chaos/ cluster: ultrachaos ns:448f5091-8d15-4c01-a0ee-202437c09d83-zeebe]$ k top pod</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                                     CPU(cores)   MEMORY(bytes)   </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...      </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zeebe-gateway-6c9f95b557-f2zbf                           294m         407Mi           </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zeebe-gateway-6c9f95b557-gk57z                           202m         396Mi</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We deleted the first pod <code>zeebe-gateway-6c9f95b557-f2zbf</code> and observed the metrics.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[zell zell-chaos/ cluster: ultrachaos ns:448f5091-8d15-4c01-a0ee-202437c09d83-zeebe]$ k delete pod zeebe-gateway-6c9f95b557-f2zbf</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zeebe-gateway-6c9f95b557-f2zbf" deleted</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We can see that a new gateway pod is created quite fast.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[zell zell-chaos/ cluster: ultrachaos ns:448f5091-8d15-4c01-a0ee-202437c09d83-zeebe]$ kgpo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                                     READY   STATUS             RESTARTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zeebe-gateway-6c9f95b557-flgz6                           0/1     Running            0          16s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">zeebe-gateway-6c9f95b557-gk57z                           1/1     Running            0          156m</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>As expected we see no high impact due to the restart.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/restart-5fbac0a50fb69d699a0721209d956d9d.png" width="1834" height="682" class="img_ev3q"></p>
<p>Just out of interest I deleted all gateway pods:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ k delete pod -l app.kubernetes.io/component=standalone-gateway</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zeebe-gateway-6c9f95b557-flgz6" deleted</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod "zeebe-gateway-6c9f95b557-gk57z" deleted</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We can see that the throughput goes almost directly down, but recovers again. It took ~4 min until we
reached the normal state (normal throughput of 100 PI/s) again. But we can also see that it is only a short period
of time, where nothing happens.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/restart2-a5fd3b37472ebf79e5edac7f1ed513e5.png" width="1828" height="685" class="img_ev3q"></p>
<p>Ideally we would define some anti-affinity on the gateway pods, to reduce the risk of losing all gateways at once.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2022/02/15/Standalone-Gateway-in-CCSaaS#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">​</a></h2>
<p>We were able to verify and proof our hypothesis.</p>
<blockquote>
<p><em>Hypothesis: When restarting / killing a zeebe standalone gateway we expect only a small
impact on current requests, new requests should be routed to the right gateway and the cluster can
make progress.</em></p>
</blockquote>
<p>As we saw above the resources were almost equally used, which is in our normal zeebe benchmarks not the case.
In the benchmarks we use the helm charts and there is no ingress controller enabled,
so we have no good load balancing of the incoming requests.</p>
<p>The benefit of the standalone gateway now stands out: losing one is not too problematic than one broker with an embedded gateway,
since a broker takes longer to restart and is likely to be an leader for a partition, which will then also cause a leader change.
Furthermore, we can scale the gateways independently.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="found-issues">Found Issues<a href="https://zeebe-io.github.io/zeebe-chaos/2022/02/15/Standalone-Gateway-in-CCSaaS#found-issues" class="hash-link" aria-label="Direct link to Found Issues" title="Direct link to Found Issues">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="optimize-resources">Optimize resources<a href="https://zeebe-io.github.io/zeebe-chaos/2022/02/15/Standalone-Gateway-in-CCSaaS#optimize-resources" class="hash-link" aria-label="Direct link to Optimize resources" title="Direct link to Optimize resources">​</a></h3>
<p>During experiment with the CCSaaS cluster I observed that the Optimize importer was crashlooping due to this load (PI 100/s).</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[zell zell-chaos/ cluster: ultrachaos ns:448f5091-8d15-4c01-a0ee-202437c09d83-zeebe]$ kgpo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                                     READY   STATUS             RESTARTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">optimize-deployment-importer-archiver-65679b6449-pb7kz   0/1     CrashLoopBackOff   5          128m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Checking the pod shows:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">    State:          Waiting</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      Reason:       CrashLoopBackOff</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Last State:     Terminated</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      Reason:       Error</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      Exit Code:    3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      Started:      Tue, 15 Feb 2022 14:25:36 +0100</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      Finished:     Tue, 15 Feb 2022 14:26:33 +0100</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Ready:          False</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Checking the logs we can see that it runs continuously out of memory.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Zell￼  13 minutes ago</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">13:32:48.493 [ZeebeImportScheduler-1] WARN  org.elasticsearch.client.RestClient - request [POST http://elasticsearch:9200/zeebe-record-process-instance/_search?routing=2&amp;typed_keys=true&amp;max_concurrent_shard_requests=5&amp;ignore_unavailable=false&amp;expand_wildcards=open&amp;allow_no_indices=true&amp;ignore_throttled=true&amp;request_cache=false&amp;search_type=query_then_fetch&amp;batched_reduce_size=512&amp;ccs_minimize_roundtrips=true] returned 1 warnings: [299 Elasticsearch-7.16.2-2b937c44140b6559905130a8650c64dbd0879cfb "[ignore_throttled] parameter is deprecated because frozen indices have been deprecated. Consider cold or frozen tiers in place of frozen indices."]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">13:32:49.104 [ImportJobExecutor-pool-ZeebeProcessInstanceImportService-0] WARN  org.elasticsearch.client.RestClient - request [HEAD http://elasticsearch:9200/optimize-process-instance-benchmark?ignore_throttled=false&amp;ignore_unavailable=false&amp;expand_wildcards=open%2Cclosed&amp;allow_no_indices=false] returned 1 warnings: [299 Elasticsearch-7.16.2-2b937c44140b6559905130a8650c64dbd0879cfb "[ignore_throttled] parameter is deprecated because frozen indices have been deprecated. Consider cold or frozen tiers in place of frozen indices."]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">java.lang.OutOfMemoryError: Java heap space</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Dumping heap to java_pid8.hprof ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Heap dump file created [611503401 bytes in 1.070 secs]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Terminating due to java.lang.OutOfMemoryError: Java heap space</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="gateway-metrics">Gateway metrics<a href="https://zeebe-io.github.io/zeebe-chaos/2022/02/15/Standalone-Gateway-in-CCSaaS#gateway-metrics" class="hash-link" aria-label="Direct link to Gateway metrics" title="Direct link to Gateway metrics">​</a></h3>
<p>It looks like that in our latest ccsm helm charts, we no longer export the gateway metrics which we should fix.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="gateway-anti-affinity">Gateway Anti-affinity<a href="https://zeebe-io.github.io/zeebe-chaos/2022/02/15/Standalone-Gateway-in-CCSaaS#gateway-anti-affinity" class="hash-link" aria-label="Direct link to Gateway Anti-affinity" title="Direct link to Gateway Anti-affinity">​</a></h3>
<p>Currently, we have no anti-affinity defined for the gateway, which could cause on preemption to take down all gateways.</p>]]></content:encoded>
            <category>availability</category>
        </item>
        <item>
            <title><![CDATA[High Snapshot Frequency]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2022/02/01/High-Snapshot-Frequency</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2022/02/01/High-Snapshot-Frequency</guid>
            <pubDate>Tue, 01 Feb 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[Today we wanted to experiment with the snapshot interval and verify that a high snapshot frequency will not impact our availability (#21).]]></description>
            <content:encoded><![CDATA[<p>Today we wanted to experiment with the snapshot interval and verify that a high snapshot frequency will not impact our availability (<a href="https://github.com/zeebe-io/zeebe-chaos/issues/21" target="_blank" rel="noopener noreferrer">#21</a>).</p>
<p><strong>TL;DR;</strong> The chaos experiment succeeded <!-- -->💪<!-- --> We were able to prove our hypothesis.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2022/02/01/High-Snapshot-Frequency#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="snapshot-interval">Snapshot Interval<a href="https://zeebe-io.github.io/zeebe-chaos/2022/02/01/High-Snapshot-Frequency#snapshot-interval" class="hash-link" aria-label="Direct link to Snapshot Interval" title="Direct link to Snapshot Interval">​</a></h3>
<p>As we can see in the <a href="https://docs.camunda.io/docs/self-managed/zeebe-deployment/operations/resource-planning/#snapshots" target="_blank" rel="noopener noreferrer">docs</a> a snapshot is defined as:</p>
<blockquote>
<p>A snapshot is a projection of all events that represent the current running state of the processes running on the partition. It contains all active data, for example, deployed processes, active process instances, and not yet completed jobs.</p>
</blockquote>
<p>Per default snapshots are taken every 5 minutes, by leaders and followers. If a follower is lagging behind (with replication) the leader will, after reaching a certain threshold, prefer to send the follower a snapshot instead of replicating X amount of records. We recently observed that this currently happens quite often, see <a href="https://github.com/camunda-cloud/zeebe/issues/8565" target="_blank" rel="noopener noreferrer">#8565</a>.</p>
<p>The snapshot interval can be changed via an environment variable: <code>ZEEBE_BROKER_DATA_SNAPSHOTPERIOD</code></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2022/02/01/High-Snapshot-Frequency#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>We expect that even if the snapshot interval is low (so the frequency of taking snapshot is high) we not run into any availability issues and the cluster should still be healthy. Lower snapshot interval might impact the performance, since taking a snapshot can take some time but other than that it shouldn't have any effect.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2022/02/01/High-Snapshot-Frequency#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<p>As usual, we run again two benchmarks to compare them. One base which has the <a href="https://github.com/camunda-cloud/zeebe/tree/develop/benchmarks/setup/default" target="_blank" rel="noopener noreferrer">default benchmark configuration</a> and one with a changed snapshot interval.</p>
<p>For the second benchmark we set the snapshot interval to one minute. Like this:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">env:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    - name: ZEEBE_BROKER_DATA_SNAPSHOTPERIOD</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    value: "1m"</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Throughput wise we can see a small difference, but this might be more related that on the base benchmark one node is leader for all partitions.</p>
<table><thead><tr><th>Base</th><th>Chaos</th></tr></thead><tbody><tr><td><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/chaos-base-general-93cd02e76e4ef0ed2125c457d5137ac0.png" width="1842" height="992" class="img_ev3q"></td><td><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/chaos-general-5d09330d3230f0843593e5384da1563f.png" width="1834" height="994" class="img_ev3q"></td></tr></tbody></table>
<p>In general the cluster with the small snapshot interval shows no negative effect. What we can see is that the install request rate increased. It seems to be currently have no affect, but it is likely that if more partitions are added it might become an issue.</p>
<table><thead><tr><th>Base</th><th>Chaos</th></tr></thead><tbody><tr><td><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/chaos-base-install-freq-8110ca25fd510d004d558c30a6a75ad6.png" width="1832" height="539" class="img_ev3q"></td><td><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/chaos-install-freq-aea78deeffe000efe95cf1c111dade6f.png" width="1831" height="538" class="img_ev3q"></td></tr></tbody></table>
<p>Further investigation needs to be done as part of <a href="https://github.com/camunda-cloud/zeebe/issues/8565" target="_blank" rel="noopener noreferrer">#8565</a>.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="smaller-intervals">Smaller intervals<a href="https://zeebe-io.github.io/zeebe-chaos/2022/02/01/High-Snapshot-Frequency#smaller-intervals" class="hash-link" aria-label="Direct link to Smaller intervals" title="Direct link to Smaller intervals">​</a></h4>
<p>The smallest interval which Zeebe supports is <code>1m == 1 minute</code>. If we configure for example <code>1s</code></p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">env:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    - name: ZEEBE_BROKER_DATA_SNAPSHOTPERIOD</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    value: "1s"</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We see the following exception in the log and the broker fails to start.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">java.lang.IllegalArgumentException: Snapshot period PT1S needs to be larger then or equals to one minute.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bigger-intervals">Bigger intervals<a href="https://zeebe-io.github.io/zeebe-chaos/2022/02/01/High-Snapshot-Frequency#bigger-intervals" class="hash-link" aria-label="Direct link to Bigger intervals" title="Direct link to Bigger intervals">​</a></h4>
<p>In order to verify how Zeebe reacts on a bigger snapshot interval we have set the interval to 30 minutes.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">env:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    - name: ZEEBE_BROKER_DATA_SNAPSHOTPERIOD</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    value: "30m"</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>In general, it looked good. What we can see is that one node was restarted in between and took a while to come back.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/big-general-799179b5b7dc76032320f1a31488778f.png" width="1840" height="986" class="img_ev3q"></p>
<p>This is expected due to the high snapshot interval, but interesting to observe. The leader had no snapshot yet produced, which means it had to replicate all events to the restarted follower. Only if the follower catches up on all partitions its bootstrap process is complete, and it can mark itself as ready. As we see it can take a while if there is no snapshot available, since new records are incoming all the time.</p>
<p>After the leader of partition two took a snapshot and the leader sent this snapshot to the follower, the follower were able to become ready.</p>
<p>Even with a big snapshot interval we can see that as soon as a new snapshot is taken it is sent to the followers, which is suboptimal.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/big-install-freq-ec4ff83707c476e44d9469cc1969b106.png" width="2472" height="274" class="img_ev3q"></p>
<p>An important thing to keep in mind when playing around with snapshots is the logstream/journal size. The journal is only compacted after taking a snapshot, if we take snapshot less frequent this means we clean up less frequent. The log can grow much bigger with big snapshot intervals.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/big-interval-log-84637b403e2e447d914fbf9fc386e164.png" width="1219" height="295" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2022/02/01/High-Snapshot-Frequency#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">​</a></h3>
<p>The chaos experiment succeeded <!-- -->🎉<!-- --> We verified that a smaller snapshot interval has no negative impact on the cluster availability, at least for a small amount of partitions.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="found-bugs">Found Bugs<a href="https://zeebe-io.github.io/zeebe-chaos/2022/02/01/High-Snapshot-Frequency#found-bugs" class="hash-link" aria-label="Direct link to Found Bugs" title="Direct link to Found Bugs">​</a></h2>
<ul>
<li>Existing issue regarding the install requests <a href="https://github.com/camunda-cloud/zeebe/issues/8565" target="_blank" rel="noopener noreferrer">#8565</a></li>
</ul>]]></content:encoded>
            <category>availability</category>
        </item>
        <item>
            <title><![CDATA[Handling of Big Variables]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2022/01/19/big-variables</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2022/01/19/big-variables</guid>
            <pubDate>Wed, 19 Jan 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[New Year;New Chaos]]></description>
            <content:encoded><![CDATA[<p>New Year;:tada<!-- -->:New<!-- --> Chaos<!-- -->🐒</p>
<p>This time I wanted to experiment with "big" variables. Zeebe supports a <code>maxMessageSize</code> of 4 MB, which is quite big. In general, it should be clear that using big variables will cause performance issues, but today I also want to find out whether the system can handle big variables (~1 MB) at all.</p>
<p><strong>TL;DR;</strong> Our Chaos experiment failed! Zeebe and Camunda Cloud is not able to handle (per default) big variables (~1 MB) without issues.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2022/01/19/big-variables#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">​</a></h2>
<p>Normally we run our benchmarks with ~32 KB payload size. This time we want to try out a payload size of ~1 MB and verify whether the system can handle such payload sizes. The payload we use can be found <a href="https://zeebe-io.github.io/zeebe-chaos/2022/01/19/big_payload.json" target="_blank" rel="noopener noreferrer">here</a>.</p>
<p>The benchmark setup, is similar to default Zeebe benchmarks you can find <a href="https://github.com/camunda-cloud/zeebe/tree/develop/benchmarks/setup/default" target="_blank" rel="noopener noreferrer">here</a>. To make it work and fair we updated the starter and worker resources for both, base and the chaos cluster.</p>
<div class="language-diff codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-diff codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">diff --git a/benchmarks/setup/default/starter.yaml b/benchmarks/setup/default/starter.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">index 78c6e81dbb..d0404d4d3e 100644</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--- a/benchmarks/setup/default/starter.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+++ b/benchmarks/setup/default/starter.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@@ -30,11 +30,11 @@ spec:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">             value: "warn"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         resources:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">           limits:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-            cpu: 250m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-            memory: 256Mi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+            cpu: 1G</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+            memory: 2Gi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">           requests:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-            cpu: 250m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-            memory: 256Mi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+            cpu: 1G</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+            memory: 2Gi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> ---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> apiVersion: v1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> kind: Service</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">diff --git a/benchmarks/setup/default/worker.yaml b/benchmarks/setup/default/worker.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">index cd6f5ffeb6..05b195291f 100644</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--- a/benchmarks/setup/default/worker.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+++ b/benchmarks/setup/default/worker.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@@ -31,11 +31,11 @@ spec:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">             value: "warn"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         resources:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">           limits:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-            cpu: 500m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-            memory: 256Mi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+            cpu: 1G</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+            memory: 1Gi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">           requests:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-            cpu: 500m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-            memory: 256Mi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+            cpu: 1G</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+            memory: 1Gi</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2022/01/19/big-variables#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>It is expected that the performance will drop, we formulate the following hypothesis.</p>
<p><strong>Hypothesis: With a bigger payload size of e.g. 1 MB, Zeebe should be still able to handle process instances, maybe under a degraded performance, but in general the availability must not suffer from such a payload size.</strong></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2022/01/19/big-variables#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="base">Base<a href="https://zeebe-io.github.io/zeebe-chaos/2022/01/19/big-variables#base" class="hash-link" aria-label="Direct link to Base" title="Direct link to Base">​</a></h4>
<p>We started a base benchmark with ~32 KB to verify how it looks like normally.</p>
<p><img loading="lazy" alt="base" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/base-general-6f2d98f4e1437e7d6ccaeb9106e1ad4e.png" width="1838" height="912" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="small-payload">Small Payload<a href="https://zeebe-io.github.io/zeebe-chaos/2022/01/19/big-variables#small-payload" class="hash-link" aria-label="Direct link to Small Payload" title="Direct link to Small Payload">​</a></h4>
<p>In order to verify how Zeebe handles different payload, we first started with a small payload ~130 bytes, which is part of the Starter application (called <code>small_payload.json</code>).</p>
<p><img loading="lazy" alt="small-payload" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/small-payload-7275166d05a6c32e2a0e7d86125f3c44.png" width="1835" height="910" class="img_ev3q"></p>
<p>We can see that the system handles such payload without any issues, and we can reach ~190 process instances per second (PI/s).</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="big-payload">Big Payload<a href="https://zeebe-io.github.io/zeebe-chaos/2022/01/19/big-variables#big-payload" class="hash-link" aria-label="Direct link to Big Payload" title="Direct link to Big Payload">​</a></h4>
<p>After running with a small payload, we changed the payload to a size of ~1 MB. This immediately broke the standalone gateways.</p>
<p><img loading="lazy" alt="big-payload" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/big-payload-starter-gw-restarts-18e517c14c161d58190bd23b618b87cf.png" width="1835" height="904" class="img_ev3q"></p>
<p>The gateways went out of memory (OOM) in a loop. No processing was made in this time.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="increasing-resources">Increasing Resources<a href="https://zeebe-io.github.io/zeebe-chaos/2022/01/19/big-variables#increasing-resources" class="hash-link" aria-label="Direct link to Increasing Resources" title="Direct link to Increasing Resources">​</a></h5>
<p>In order to continue the experiment and to verify how Zeebe itself can handle it, we increased the gateway resources.</p>
<div class="language-diff codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-diff codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">diff --git a/benchmarks/setup/default/zeebe-values.yaml b/benchmarks/setup/default/zeebe-values.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">index 371ba538dc..7a11c10366 100644</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--- a/benchmarks/setup/default/zeebe-values.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+++ b/benchmarks/setup/default/zeebe-values.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@@ -38,10 +38,10 @@ gateway:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   resources:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     limits:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       cpu: 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-      memory: 512Mi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+      memory: 4Gi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     requests:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       cpu: 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-      memory: 512Mi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+      memory: 4Gi</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>But this doesn't help. The gateway went no longer OOM, but it was still not able to handle the payload.</p>
<p><img loading="lazy" alt="increase-res" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/big-payload-increase-res-ccf66088a1363c2c7bbf3d10cd430c9e.png" width="1834" height="912" class="img_ev3q"></p>
<p>We can see that in a short period of time some events have been processed (small spike in the "Current Events" panel), but this stopped quite fast again. In the gateway logs there are endless warnings:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Warning 2022-01-20 10:09:32.644 CET zeebe-cluster-helm "Stream Error"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Warning 2022-01-20 10:09:56.847 CET zeebe-cluster-helm "Stream Error"</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>With an underlying exception: <code>io.netty.handler.codec.http2.Http2Exception$StreamException: Stream closed before write could take place</code></p>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Stacktrace</summary><div><div class="collapsibleContent_i85q"><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">io.netty.handler.codec.http2.Http2Exception$StreamException: Stream closed before write could take place</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.handler.codec.http2.Http2Exception.streamError(Http2Exception.java:172) ~[netty-codec-http2-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.handler.codec.http2.DefaultHttp2RemoteFlowController$FlowState.cancel(DefaultHttp2RemoteFlowController.java:481) [netty-codec-http2-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.handler.codec.http2.DefaultHttp2RemoteFlowController$1.onStreamClosed(DefaultHttp2RemoteFlowController.java:105) [netty-codec-http2-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.handler.codec.http2.DefaultHttp2Connection.notifyClosed(DefaultHttp2Connection.java:357) [netty-codec-http2-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.handler.codec.http2.DefaultHttp2Connection$ActiveStreams.removeFromActiveStreams(DefaultHttp2Connection.java:1007) [netty-codec-http2-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.handler.codec.http2.DefaultHttp2Connection$ActiveStreams.deactivate(DefaultHttp2Connection.java:963) [netty-codec-http2-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.handler.codec.http2.DefaultHttp2Connection$DefaultStream.close(DefaultHttp2Connection.java:515) [netty-codec-http2-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.handler.codec.http2.DefaultHttp2Connection$DefaultStream.close(DefaultHttp2Connection.java:521) [netty-codec-http2-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.handler.codec.http2.Http2ConnectionHandler.closeStream(Http2ConnectionHandler.java:613) [netty-codec-http2-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder$FrameReadListener.onRstStreamRead(DefaultHttp2ConnectionDecoder.java:444) [netty-codec-http2-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.handler.codec.http2.Http2InboundFrameLogger$1.onRstStreamRead(Http2InboundFrameLogger.java:80) [netty-codec-http2-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.handler.codec.http2.DefaultHttp2FrameReader.readRstStreamFrame(DefaultHttp2FrameReader.java:509) [netty-codec-http2-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.handler.codec.http2.DefaultHttp2FrameReader.processPayloadState(DefaultHttp2FrameReader.java:259) [netty-codec-http2-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.handler.codec.http2.DefaultHttp2FrameReader.readFrame(DefaultHttp2FrameReader.java:159) [netty-codec-http2-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.handler.codec.http2.Http2InboundFrameLogger.readFrame(Http2InboundFrameLogger.java:41) [netty-codec-http2-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder.decodeFrame(DefaultHttp2ConnectionDecoder.java:173) [netty-codec-http2-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.handler.codec.http2.Http2ConnectionHandler$FrameDecoder.decode(Http2ConnectionHandler.java:378) [netty-codec-http2-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.handler.codec.http2.Http2ConnectionHandler.decode(Http2ConnectionHandler.java:438) [netty-codec-http2-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:510) [netty-codec-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:449) [netty-codec-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:279) [netty-codec-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) [netty-transport-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) [netty-transport-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:795) [netty-transport-classes-epoll-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:480) [netty-transport-classes-epoll-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378) [netty-transport-classes-epoll-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986) [netty-common-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [netty-common-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.73.Final.jar:4.1.73.Final]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	at java.lang.Thread.run(Unknown Source)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></details>
<p>On the client side we can see that the Zeebe cluster seems to be unavailable.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="camunda-cloud">Camunda Cloud<a href="https://zeebe-io.github.io/zeebe-chaos/2022/01/19/big-variables#camunda-cloud" class="hash-link" aria-label="Direct link to Camunda Cloud" title="Direct link to Camunda Cloud">​</a></h3>
<p>We wanted to verify how Camunda Cloud and our standard Cluster plan (GA Hardware Plan) handles such a payload. But the result was the same.</p>
<p><img loading="lazy" alt="cc-general" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/cc-general-bd2b9235be276f75cd8c485229bf9b44.png" width="1835" height="882" class="img_ev3q"></p>
<p>The processing stopped quite fast due to OOM of the gateway. We can see that operate is also not able to handle such load.</p>
<p><img loading="lazy" alt="failed-op" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/failed-operate-6cc764529ec07f8c422fb62e53289a02.png" width="1866" height="713" class="img_ev3q"></p>
<p>In our console overview we see that all services (exception Zeebe) went unhealthy</p>
<p><img loading="lazy" alt="console-healthy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/console-healthy-23ed317bbe9dc53934403731fb72b55c.png" width="739" height="733" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2022/01/19/big-variables#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">​</a></h3>
<blockquote>
<p><em>Hypothesis: With a bigger payload size of e.g. 1 MB Zeebe, should be still able to handle process instances, maybe under a degraded performance but in general the availability must not suffer from such a payload size.</em></p>
</blockquote>
<p><strong>We were not able to validate our hypothesis, which means our chaos experiment failed!</strong> <!-- -->💥</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="found-bugs">Found Bugs<a href="https://zeebe-io.github.io/zeebe-chaos/2022/01/19/big-variables#found-bugs" class="hash-link" aria-label="Direct link to Found Bugs" title="Direct link to Found Bugs">​</a></h3>
<p>We opened the following bug issues:</p>
<ul>
<li>Gateway can't handle bigger payload sizes <a href="https://github.com/camunda-cloud/zeebe/issues/8621" target="_blank" rel="noopener noreferrer">#8621</a></li>
</ul>
<h1>Outtakes</h1>
<p>Interesting issues I run into when doing the chaos experiment, could be count as TIL events and mentioning them might help others.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="message-pack-is-not-valid">Message pack is not valid<a href="https://zeebe-io.github.io/zeebe-chaos/2022/01/19/big-variables#message-pack-is-not-valid" class="hash-link" aria-label="Direct link to Message pack is not valid" title="Direct link to Message pack is not valid">​</a></h2>
<p>When I first generated the JSON payload, it was an array on root level, which is not supported by Zeebe.</p>
<p>I spent sometime to understand why I see no progress in processing. Taking a look at the gateway logs we can see:</p>
<p><code>"Expected to handle gRPC request, but messagepack property was invalid: io.camunda.zeebe.msgpack.MsgpackPropertyException: Property 'variables' is invalid: Expected document to be a root level object, but was 'ARRAY'"</code></p>
<p>On the client side (if the logging is turned on, starter needs info logging) we see:</p>
<p><code>INVALID_ARGUMENT: Property 'variables' is invalid: Expected document to be a root level object, but was 'ARRAY'</code></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="configure-the-starter-payload">Configure the Starter payload<a href="https://zeebe-io.github.io/zeebe-chaos/2022/01/19/big-variables#configure-the-starter-payload" class="hash-link" aria-label="Direct link to Configure the Starter payload" title="Direct link to Configure the Starter payload">​</a></h2>
<p>In order to use different JSON payload for the starter we support a configuration on the starter application (<code>-Dapp.starter.payloadPath</code>). I had a lot of <em>"fun"</em> to find out the right syntax:</p>
<ul>
<li>-Dapp.starter.payloadPath="bpmn/small_payload.json" - <em>DOESN'T WORK</em></li>
<li>-Dapp.starter.payloadPath="/bpmn/small_payload.json" - <em>DOESN'T WORK</em></li>
<li>-Dapp.starter.payloadPath=/bpmn/small_payload.json - <em>DOESN'T WORK</em></li>
<li>-Dapp.starter.payloadPath=bpmn/big_payload.json - <em>WORKS</em></li>
</ul>
<p>So be aware don't use <code>"</code> and no <code>/</code> in front, otherwise you might get a <code>java.io.FileNotFoundException: "bpmn/small_payload.json" (No such file or directory)</code> in your starter deployment and wonder why you see no progress.</p>]]></content:encoded>
            <category>availability</category>
        </item>
        <item>
            <title><![CDATA[Worker count should not impact performance]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance</guid>
            <pubDate>Wed, 24 Nov 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[In this chaos day we experimented with the worker count, since we saw recently that it might affect the performance (throughput) negatively if there are more workers deployed. This is related to #7955 and #8244.]]></description>
            <content:encoded><![CDATA[<p>In this chaos day we experimented with the worker count, since we saw recently that it might affect the performance (throughput) negatively if there are more workers deployed. This is related to <a href="https://github.com/camunda-cloud/zeebe/issues/7955" target="_blank" rel="noopener noreferrer">#7955</a> and <a href="https://github.com/camunda-cloud/zeebe/issues/8244" target="_blank" rel="noopener noreferrer">#8244</a>.</p>
<p>We wanted to prove, that even if we have more workers deployed the throughput of the process instance execution should not have an negative impact.</p>
<p><strong>TL;DR;</strong> We were not able to prove our hypothesis. Scaling of workers can have a negative impact on performance. Check out the <a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#third-chaos-experiment">third chaos experiment</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="first-chaos-experiment">First Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#first-chaos-experiment" class="hash-link" aria-label="Direct link to First Chaos Experiment" title="Direct link to First Chaos Experiment">​</a></h2>
<p>We run the first experiment with one partition, three brokers, one standalone gateway and one starter which creates 100 PI/s. In this experiment we deployed different zeebe <a href="https://github.com/camunda-cloud/zeebe/tree/develop/benchmarks" target="_blank" rel="noopener noreferrer">benchmarks</a> with 4, 8 and 16 workers.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>The workers should be able to complete all created instances and if the workers are scaled the throughput should remain.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="4-worker">4 Worker<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#4-worker" class="hash-link" aria-label="Direct link to 4 Worker" title="Direct link to 4 Worker">​</a></h4>
<p><img loading="lazy" alt="worker-4-p1-general.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/worker-4-p1-general-62ffbfc05a0d98a217d628ea1c11dfe0.png" width="1828" height="902" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="8-worker">8 Worker<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#8-worker" class="hash-link" aria-label="Direct link to 8 Worker" title="Direct link to 8 Worker">​</a></h4>
<p><img loading="lazy" alt="worker-8-p1-general.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/worker-8-p1-general-d9a0c1f55aeb25f8a41b43f0caf44f47.png" width="1833" height="901" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="16-worker">16 Worker<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#16-worker" class="hash-link" aria-label="Direct link to 16 Worker" title="Direct link to 16 Worker">​</a></h4>
<p><img loading="lazy" alt="worker-16-p1-general.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/worker-16-p1-general-6af6d38ff8109ecc304b34fb149d24dc.png" width="1826" height="897" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">​</a></h5>
<p>What we can see is that if we increase the worker number it will decrease the throughput, this might be explained with the case that we sent more activation requests / commands which need to be handled by the Brokers. We can see that the back pressure is higher with 16 workers.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="second-chaos-experiment">Second Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#second-chaos-experiment" class="hash-link" aria-label="Direct link to Second Chaos Experiment" title="Direct link to Second Chaos Experiment">​</a></h2>
<p>We will repeat first experiment with some changes, to the partition count. We will now use three partitions.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-1">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#expected-1" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>The workers should be able to complete all created instances and if the workers are scaled the throughput should remain or be better.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-1">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#actual-1" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="4-worker-1">4 Worker<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#4-worker-1" class="hash-link" aria-label="Direct link to 4 Worker" title="Direct link to 4 Worker">​</a></h4>
<p><img loading="lazy" alt="worker-4-p3-general.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/worker-4-p3-general-3e773f9f2734c854f579cf560474f558.png" width="1840" height="898" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="8-worker-1">8 Worker<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#8-worker-1" class="hash-link" aria-label="Direct link to 8 Worker" title="Direct link to 8 Worker">​</a></h4>
<p><img loading="lazy" alt="worker-8-p3-general.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/worker-8-p3-general-25f411adf3701877e4ab7a040b401434.png" width="1836" height="903" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="16-worker-1">16 Worker<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#16-worker-1" class="hash-link" aria-label="Direct link to 16 Worker" title="Direct link to 16 Worker">​</a></h4>
<p><img loading="lazy" alt="worker-16-p3-general.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/worker-16-p3-general-9e04e4d183f59d59573917fc264a04e0.png" width="1832" height="906" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="result-1">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#result-1" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">​</a></h5>
<p>In this experiment we can see that all benchmarks reach almost the same throughput, since we not really stressing the system and have enough resources to work with. There is no backpressure at all. In the next experiment we will increase the load.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="third-chaos-experiment">Third Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#third-chaos-experiment" class="hash-link" aria-label="Direct link to Third Chaos Experiment" title="Direct link to Third Chaos Experiment">​</a></h2>
<p>We will repeat second experiment with some changes to the instance creation count. We will now start 300 process instances per second, with one starter.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-2">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#expected-2" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>The workers should be able to complete most of the instances, we would expect that with more workers we would be able to complete more instances and have no negative impact on the system.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-2">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#actual-2" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="4-worker-2">4 Worker<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#4-worker-2" class="hash-link" aria-label="Direct link to 4 Worker" title="Direct link to 4 Worker">​</a></h4>
<p><img loading="lazy" alt="worker-4-p3-300-general.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/worker-4-p3-300-general-632f8cc19401a161b90ab68bef7978ed.png" width="1825" height="903" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="8-worker-2">8 Worker<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#8-worker-2" class="hash-link" aria-label="Direct link to 8 Worker" title="Direct link to 8 Worker">​</a></h4>
<p><img loading="lazy" alt="worker-8-p3-general.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/worker-8-p3-300-general-32b3a55b2d73fc15983195071742b18c.png" width="1832" height="911" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="16-worker-2">16 Worker<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#16-worker-2" class="hash-link" aria-label="Direct link to 16 Worker" title="Direct link to 16 Worker">​</a></h4>
<p><img loading="lazy" alt="worker-16-p3-general.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/worker-16-p3-300-general-edb0fc05b8ef76f9991a26e215232366.png" width="1837" height="915" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="result-2">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#result-2" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">​</a></h5>
<p>Between eight and four workers we see the expected difference, that more workers increases the throughput and we are able to complete more instances in a second. The result of 16 workers is completely unexpected. We observed that after short time frame the completion throughput completely droped, and only process instances are created.</p>
<p>We were able to reproduce this behavior, which shows the weakness again.</p>
<p><img loading="lazy" alt="worker-16-p3-general-reproduce.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/worker-16-p3-300-general-reproduce-23ede1412500950de080d9b90f080400.png" width="1827" height="886" class="img_ev3q"></p>
<p>We were not able to prove our hypothesis, that scaling of workers has no negative impact on performance.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="further-analysis">Further Analysis<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/24/Worker-count-should-not-impact-performance#further-analysis" class="hash-link" aria-label="Direct link to Further Analysis" title="Direct link to Further Analysis">​</a></h2>
<p>We created a bug issue to analyze and fix this weakness <a href="https://github.com/camunda-cloud/zeebe/issues/8267" target="_blank" rel="noopener noreferrer">#8267</a>.</p>]]></content:encoded>
            <category>performance</category>
        </item>
        <item>
            <title><![CDATA[Not produce duplicate Keys]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2021/11/11/Not-produce-duplicate-Keys</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2021/11/11/Not-produce-duplicate-Keys</guid>
            <pubDate>Thu, 11 Nov 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Due to some incidents and critical bugs we observed in the last weeks, I wanted to spent some time to understand the issues better and experiment how we could detect them. One of the issue we have observed was that keys were generated more than once, so they were no longer unique (#8129). I will describe this property in the next section more in depth.]]></description>
            <content:encoded><![CDATA[<p>Due to some incidents and critical bugs we observed in the last weeks, I wanted to spent some time to understand the issues better and experiment how we could detect them. One of the issue we have observed was that keys were generated more than once, so they were no longer unique (<a href="https://github.com/camunda-cloud/zeebe/issues/8129" target="_blank" rel="noopener noreferrer">#8129</a>). I will describe this property in the next section more in depth.</p>
<p><strong>TL;DR;</strong> We were able to design an experiment which helps us to detect duplicated keys in the log. Further work should be done to automate such experiment and run it agains newer versions.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="unique-keys">Unique Keys<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/11/Not-produce-duplicate-Keys#unique-keys" class="hash-link" aria-label="Direct link to Unique Keys" title="Direct link to Unique Keys">​</a></h2>
<p>In Zeebe each element must have an cluster wide unique key. This is a property we expect in several areas inside, but also outside of Zeebe (external services). We can call it an invariant we have to guarantee.</p>
<p>In order to have cluster wide unique key's we encode the partition id in the key's. You can check this <a href="https://github.com/camunda-cloud/zeebe/blob/develop/protocol/src/main/java/io/camunda/zeebe/protocol/Protocol.java#L71-L73" target="_blank" rel="noopener noreferrer">code</a> for more details. Furthermore only the Leader (of a partition) are in charge and allowed to generate new keys. If a fail-over happens the new leader need to continue with generating new keys, he has to resume where the other Leader have left-of.</p>
<p>The last part was exactly the issue we had, see <a href="https://github.com/camunda-cloud/zeebe/issues/8129" target="_blank" rel="noopener noreferrer">#8129</a>. The new leader generated key's, which have been already generated by the previous leader. This caused inconsistency in our internal state, but also in external services like Operate.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/11/Not-produce-duplicate-Keys#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">​</a></h2>
<p>This time it is a bit different approach, since we know it will <em>fail</em> and we want to examine how we can detect the weakness.
In order to understand how we can detect and prevent/verify that this will not happen again, I want to run an experiment against 1.2.0. Later we should try to automate this experiment and run it against newer versions.</p>
<p>As described <a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/11/Not-produce-duplicate-Keys#unique-keys">above</a> the issue was caused due to a fail-over, to be more specific, the Follower has already reached the end of the log (replayed all events) and on fail-over he had nothing to replay. In order to reproduce this situation we will do the following experiment:</p>
<ol>
<li>Deploy an simple process model, with start and end event.</li>
<li>Start an instance and await the result <code>zbctl create instance "simpleProcess" --withResult --insecure</code></li>
<li>Wait a short period of time</li>
<li>Restart the current Leader <code>k delete pod zell-chaos-zeebe-2</code></li>
<li>Wait until a new Leader is choosen</li>
<li>Start an instance and await the result <code>zbctl create instance "simpleProcess" --withResult --insecure</code></li>
</ol>
<p>After doing this we should copy the data from the new Leader and exermine the log (with <a href="https://github.com/Zelldon/zdb" target="_blank" rel="noopener noreferrer">zdb</a>). Alternatively, we could also verify the exporter log in elastic.</p>
<p>In general it should be clear that if we take a look at the log the key can appear multiple times, but they should only reference one single entity/element.</p>
<p>A key is normally generated when processing a command and written as follow up event the first time to the log. For example when we process the <code>ACTIVATE_ELEMENT</code> command we write the key of the new entity on <code>ELEMENT_ACTIVATED</code> to the log.
Keys are assigned for other types of entities as well, like process instance creations, deployments etc. Here it works similar.</p>
<p>If the follow-up event contains a key which doesn't occurre the first time, then we have a problem, and this is how we want to detect it.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/11/Not-produce-duplicate-Keys#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>To follow the chaos engineering approach we will define here a hypothesis, even if we know it might not true for 1.2.0. But later we can reuse it for newer version, because here it should apply.</p>
<p><em>We expect even if we processed all records and have a fail-over that the new leader should not generate the same keys again.</em></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2021/11/11/Not-produce-duplicate-Keys#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<p>We started a benchmark with version 1.2.0, three brokers and one partition to reduce the scope and followed the described experiment above.</p>
<p>The second process instance creation returned a key (<code>2251799813685258</code>) which was incremented by one, compared to the other process instance (<code>2251799813685257</code>). Here we already knew that our experiment caused the issue. Because, multiple new entities are generated during processing of a process instance and we awaited the result, at the first process instance creation. This means we have generated already more than one key (on the old leader), which hasn't been picked up by the new leader.</p>
<p>We copyed the data from the new Leader and exermined the log via <code>zdb</code>. First we printed the complete log into a separate file as json:</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">  zdb log print -p raft-partition/partitions/1 | jq &gt; data.json</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This makes it human readable and also processable by other tools, like <code>jq</code>. After checking the file we already found one duplicate.</p>
<p>The first key was part of index 12 in term one and the duplicate was part of index 20 in term 2 (new leader term)</p>
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"> {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "index": 12,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "term": 1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "entries": [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "partitionId": 1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "value": {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "version": 1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "processDefinitionKey": 2251799813685249,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "bpmnProcessId": "simpleProcess",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "processInstanceKey": 2251799813685256,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "parentElementInstanceKey": -1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "flowScopeKey": -1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "parentProcessInstanceKey": -1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "elementId": "simpleProcess",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "bpmnElementType": "PROCESS"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "timestamp": 1636627776427,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "position": 26,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "valueType": "PROCESS_INSTANCE",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "intent": "ACTIVATE_ELEMENT",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "recordType": "COMMAND",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "rejectionType": "NULL_VAL",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "rejectionReason": "",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "brokerVersion": "1.2.0",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "sourceRecordPosition": 25,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "key": 2251799813685256</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "partitionId": 1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "value": {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "version": 1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "processDefinitionKey": 2251799813685249,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "bpmnProcessId": "simpleProcess",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "processInstanceKey": 2251799813685256,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "variables": {}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "timestamp": 1636627776427,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "position": 27,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "valueType": "PROCESS_INSTANCE_CREATION",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "intent": "CREATED",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "recordType": "EVENT",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "rejectionType": "NULL_VAL",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "rejectionReason": "",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "brokerVersion": "1.2.0",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "sourceRecordPosition": 25,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "key": 2251799813685257</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    },</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"> {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "index": 20,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "term": 2,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      "entries": [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "partitionId": 1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "value": {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "version": 1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "processDefinitionKey": 2251799813685249,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "bpmnProcessId": "simpleProcess",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "processInstanceKey": 2251799813685257,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "parentElementInstanceKey": -1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "flowScopeKey": -1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "parentProcessInstanceKey": -1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "elementId": "simpleProcess",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "bpmnElementType": "PROCESS"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "timestamp": 1636627887305,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "position": 46,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "valueType": "PROCESS_INSTANCE",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "intent": "ACTIVATE_ELEMENT",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "recordType": "COMMAND",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "rejectionType": "NULL_VAL",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "rejectionReason": "",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "brokerVersion": "1.2.0",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "sourceRecordPosition": 45,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "key": 2251799813685257</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "partitionId": 1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "value": {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "version": 1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "processDefinitionKey": 2251799813685249,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "bpmnProcessId": "simpleProcess",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "processInstanceKey": 2251799813685257,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            "variables": {}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "timestamp": 1636627887305,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "position": 47,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "valueType": "PROCESS_INSTANCE_CREATION",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "intent": "CREATED",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "recordType": "EVENT",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "rejectionType": "NULL_VAL",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "rejectionReason": "",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "brokerVersion": "1.2.0",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "sourceRecordPosition": 45,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          "key": 2251799813685258</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Since reading and checking the complete file is a bit hard and error prone, we tried to exermine the data with <code>jq</code>. This worked quite well, we were able to detect the duplicates with an <code>jq</code> expression.</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cat data.json | jq -r '.records[] | select(.entries  != null) |  .entries[] | select (.intent == "ELEMENT_ACTIVATED" or .intent == "CREATED") | .key' data.json | sort | uniq -c -d | awk '{print $2}'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2251799813685257</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2251799813685258</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2251799813685263</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2251799813685264</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This expression we can use for further experiments and for automating such.</p>]]></content:encoded>
            <category>data</category>
        </item>
        <item>
            <title><![CDATA[Throughput on big state]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2021/10/29/Throughput-on-big-state</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2021/10/29/Throughput-on-big-state</guid>
            <pubDate>Fri, 29 Oct 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[In this chaos day we wanted to prove the hypothesis that the throughput should not significantly change even if we have bigger state, see zeebe-chaos#64]]></description>
            <content:encoded><![CDATA[<p>In this chaos day we wanted to prove the hypothesis that the throughput should not significantly change even if we have bigger state, see <a href="https://github.com/zeebe-io/zeebe-chaos/issues/64" target="_blank" rel="noopener noreferrer">zeebe-chaos#64</a></p>
<p>This came up due observations from the <a href="https://zeebe-io.github.io/zeebe-chaos/2021/10/05/recovery-time">last chaos day</a>. We already had a bigger investigation here <a href="https://github.com/camunda-cloud/zeebe/issues/7955" target="_blank" rel="noopener noreferrer">zeebe#7955</a>.</p>
<p><strong>TL;DR;</strong> We were not able to prove the hypothesis. Bigger state, more than 100k+ process instances in the state, seems to have an big impact on the processing throughput.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2021/10/29/Throughput-on-big-state#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">​</a></h2>
<p>Similar to the <a href="https://zeebe-io.github.io/zeebe-chaos/2021/10/05/recovery-time">last chaos day</a> we set up three brokers, with one partition and replication factor three.</p>
<p>As first part of the experiment we start some amount of instances, afterwards we want to complete them with our workers. Based on the <a href="https://zeebe-io.github.io/zeebe-chaos/2021/10/05/recovery-time">last chaos day</a> we know what we can complete ~100 process instances with one worker and a capacity of <code>12</code>. An example worker configuration can be found <a href="https://github.com/camunda-cloud/zeebe/blob/develop/benchmarks/setup/default/worker.yaml" target="_blank" rel="noopener noreferrer">here</a></p>
<p>We changed the following:</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ diff default/worker.yaml zell-chaos/worker.yaml </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">11c11</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;   replicas: 12</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;   replicas: 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">26c26</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;               -Dapp.worker.capacity=120</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;               -Dapp.worker.capacity=12</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="experiment-one">Experiment One<a href="https://zeebe-io.github.io/zeebe-chaos/2021/10/29/Throughput-on-big-state#experiment-one" class="hash-link" aria-label="Direct link to Experiment One" title="Direct link to Experiment One">​</a></h3>
<p>As first experiment we start with creating <code>100.000</code> instances, afterwards we start the worker.</p>
<p>In order to do that easily we can configure the <a href="https://github.com/camunda-cloud/zeebe/blob/develop/benchmarks/setup/default/starter.yaml" target="_blank" rel="noopener noreferrer">starter</a> and reduce the rate to <code>100</code> and set the duration limit to <code>1000</code>. This means it will run for <code>1000</code> second and start each second <code>100</code> instances (which makes <code>100.000</code>).</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ diff default/starter.yaml zell-chaos/starter.yaml </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">24,26c24,26</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;               -Dapp.starter.rate=200</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;               -Dapp.starter.durationLimit=0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;               -Dapp.starter.rate=100</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;               -Dapp.starter.durationLimit=1000</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2021/10/29/Throughput-on-big-state#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h4>
<p>We expected that we can create <code>100.000</code> instances and can complete them with a rate of <code>~100</code>, as we have seen in other experiments.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2021/10/29/Throughput-on-big-state#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h4>
<p>We were able to create all instances without any issues.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp1-100k-instances-ed40fdd974ae9c8814edac7067da9732.png" width="1824" height="654" class="img_ev3q"></p>
<p>We were able to complete all instances without any issues and the throughput was ~100 completion per second.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp1-completion-abed9e37390c8651d43576a0a0d040d7.png" width="1832" height="637" class="img_ev3q"></p>
<p>We can see that the snapshot was at some point ~650 MB big.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp1-state-abdb40eedb529ef2dcb2a34d841b3327.png" width="1833" height="918" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="experiment-two">Experiment Two<a href="https://zeebe-io.github.io/zeebe-chaos/2021/10/29/Throughput-on-big-state#experiment-two" class="hash-link" aria-label="Direct link to Experiment Two" title="Direct link to Experiment Two">​</a></h3>
<p>As second experiment we wanted to increase the state by factor <code>10</code>, which means <code>1.000.000</code> instances in the state and then start the worker.</p>
<p>In order to do that we changed the following in the starter configuration:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ diff default/starter.yaml zell-chaos/starter.yaml </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">24,26c24,26</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;               -Dapp.starter.rate=200</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;               -Dapp.starter.durationLimit=0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;               -Dapp.starter.rate=100</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&gt;               -Dapp.starter.durationLimit=10000</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="expected-1">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2021/10/29/Throughput-on-big-state#expected-1" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h4>
<p>We expect that we can create <code>1.000.000</code> instances and can complete them with a rate of <code>~100</code>, as we have seen in other experiments.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="actual-1">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2021/10/29/Throughput-on-big-state#actual-1" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h4>
<p>We were <strong>not</strong> able to create all instances without issues.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp2-starting-general-90285fc89bbadf62e2171be8ded4684f.png" width="1825" height="643" class="img_ev3q"></p>
<p>We see that at some point the throughput drops and backpressure seem to kick in. When this happens the state is only a bit bigger than in the previous experiment</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp2-state-4b557cf5a0c465d33ea8a378c5b93414.png" width="1838" height="878" class="img_ev3q"></p>
<p>The running instances seem to be around ~170K at this time.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp2-running-17d829e56e06a32e935cae47c68aeae6.png" width="1828" height="653" class="img_ev3q"></p>
<p>We can see that the processing queue increased at the same time and reached a critical point (over 150 records in the backlog).</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp2-queue-080a6c7f13f9b67e38f6c322f9d5f6fa.png" width="1827" height="300" class="img_ev3q"></p>
<p>The overall latency seems to increase after this time (which makes sense)</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp2-latency-5d21d638de8b582d99853871ddf73f9f.png" width="1828" height="786" class="img_ev3q"></p>
<p>We haven't started the workers for this experiment, since the throughput already break before.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="experiment-three">Experiment Three<a href="https://zeebe-io.github.io/zeebe-chaos/2021/10/29/Throughput-on-big-state#experiment-three" class="hash-link" aria-label="Direct link to Experiment Three" title="Direct link to Experiment Three">​</a></h3>
<p>In order to make sure that this is related to the state we run an experiment with the <a href="https://github.com/camunda-cloud/zeebe/blob/develop/benchmarks/setup/default/simpleStarter.yaml" target="_blank" rel="noopener noreferrer">simpleStarter</a>. This starter starts a process, which contains only a start and end event.</p>
<p>We let this starter run for more than one day and haven't experienced any issues on this one.</p>
<p><img loading="lazy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/exp3-general-1000c96b073da25d9e76e2611d28b747.png" width="1830" height="914" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2021/10/29/Throughput-on-big-state#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">​</a></h2>
<p>As written above the throughput seem to break, after we reach a certain state size.</p>
<p>It might be just a trigger to get the system into stumblling, which means: after one thing takes a bit longer the processing queue gets longer and the processor is not able to catch up any more. This causes then backpressure to kick in etc.</p>
<p>I think we need to further investigate this.</p>]]></content:encoded>
            <category>performance</category>
        </item>
        <item>
            <title><![CDATA[Recovery (Fail Over) time]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2021/10/05/recovery-time</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2021/10/05/recovery-time</guid>
            <pubDate>Tue, 05 Oct 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[In the last quarter we worked on a new "feature" which is called "building state on followers". In short,]]></description>
            <content:encoded><![CDATA[<p>In the last quarter we worked on a new "feature" which is called "building state on followers". In short,
it means that the followers apply the events to build there state, which makes regular snapshot
replication unnecessary and allows faster role transition between Follower-to-Leader. In this chaos
day I wanted to experiment a bit with this property, we already did some benchmarks <a href="https://github.com/camunda-cloud/zeebe/issues/7515" target="_blank" rel="noopener noreferrer">here</a>.
Today, I want to see how it behaves with larger state (bigger snapshots), since this needed to be
copied in previous versions of Zeebe, and the broker had to replay more than with the newest version.</p>
<p>If you want to now more about build state on followers check out the <a href="https://github.com/zeebe-io/enhancements/blob/master/ZEP007-build-state-on-followers.md" target="_blank" rel="noopener noreferrer">ZEP</a></p>
<p><strong>TL;DR;</strong> In our experiment we had almost no downtime, with version 1.2, the new leader was very fast able to pick up the next work (accept new commands).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="first-chaos-experiment">First Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2021/10/05/recovery-time#first-chaos-experiment" class="hash-link" aria-label="Direct link to First Chaos Experiment" title="Direct link to First Chaos Experiment">​</a></h2>
<p>We will run two benchmarks one with 1.1 version and one with 1.2, to compare the differences between
the versions. We will run three brokers, with one partition and replication factor three.</p>
<p>In order to build up state we run the <code>starter</code> with a <code>durationLimit</code>, example cfg:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">            value: &gt;-</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">              -Dapp.brokerUrl=zell-chaos-12-zeebe-gateway:26500</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">              -Dapp.starter.rate=100</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">              -Dapp.starter.durationLimit=1000</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">              -Dzeebe.client.requestTimeout=62000</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">              -XX:+HeapDumpOnOutOfMemoryError</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This means that we run a rate of 100 PI/s creations over 1000 seconds. We expect at the end around
100.000 PI, which should be enough to simulate a "big state".</p>
<p>After executing the starters we can see in the metrics the running instances:</p>
<p><img loading="lazy" alt="instances" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/instances-8b991c2d040baa3627ded5a001ef43d1.png" width="1187" height="191" class="img_ev3q"></p>
<p>And that the snapshot is around 600 to 700 MB.</p>
<p><img loading="lazy" alt="snapshot" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/snapshot-73e2affb2bb52e3c38343994b6b7bf7f.png" width="591" height="304" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2021/10/05/recovery-time#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>We expect that if we restart the current leader that a new leader is fast (under seconds) able to
take over and continues the work. The version 1.2 should perform here much better than 1.1.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2021/10/05/recovery-time#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<p>Just normal bootstrap takes some time, on version 1.1:</p>
<p><img loading="lazy" alt="base-start-up" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/base-start-up-990e2a69500f27068362d59e86bedbdc.png" width="2468" height="501" class="img_ev3q"></p>
<p>For version 1.2:</p>
<p><img loading="lazy" alt="12-start-up" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/12-start-up-04e2050bd718b765993f07dc097b7678.png" width="2477" height="494" class="img_ev3q"></p>
<p>After running the starters for a certain duration and restarting the leader we can see that
the processor recovery takes by <em>factor 10</em> longer on version 1.1. Unfortunately, we have not the
leader transition metric in that version to compare against.</p>
<table><thead><tr><th><strong>Version</strong></th><th><strong>1.1</strong></th><th><strong>1.2</strong></th></tr></thead><tbody><tr><td>Recovery</td><td><a target="_blank" href="https://zeebe-io.github.io/zeebe-chaos/assets/files/base-recovery-bee7a028446f8d3ee578efdcfb0ce458.png"><img loading="lazy" alt="base-recovery" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/base-recovery-bee7a028446f8d3ee578efdcfb0ce458.png" width="1198" height="490" class="img_ev3q"></a></td><td><a target="_blank" href="https://zeebe-io.github.io/zeebe-chaos/assets/files/12-recovery-fadf67de59709ef23de1048730aa1fa6.png"><img loading="lazy" alt="12-recovery" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/12-recovery-fadf67de59709ef23de1048730aa1fa6.png" width="1191" height="495" class="img_ev3q"></a></td></tr><tr><td>General</td><td><a target="_blank" href="https://zeebe-io.github.io/zeebe-chaos/assets/files/base-recovery-general-71b7de7df76b17ee89efd539b6a3b5b3.png"><img loading="lazy" alt="base-recovery-general" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/base-recovery-general-71b7de7df76b17ee89efd539b6a3b5b3.png" width="1188" height="957" class="img_ev3q"></a></td><td><a target="_blank" href="https://zeebe-io.github.io/zeebe-chaos/assets/files/12-recovery-general-fa5b6920c1d994b36be40ee7130c86b0.png"><img loading="lazy" alt="12-recovery-general" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/12-recovery-general-fa5b6920c1d994b36be40ee7130c86b0.png" width="1191" height="948" class="img_ev3q"></a></td></tr></tbody></table>
<p><em>Sorry for the small pictures</em></p>
<p>In general what we have seen is that it is not so easy to compare if there is no longer load on the
system, which is the reason I did a second experiment with: A) "big state" and B) steady load.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="second-chaos-experiment">Second Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2021/10/05/recovery-time#second-chaos-experiment" class="hash-link" aria-label="Direct link to Second Chaos Experiment" title="Direct link to Second Chaos Experiment">​</a></h2>
<p>Similar setup to the first experiment, but additionally after the "big state" is reached a steady
load is put on the system. One starter with a rate of 100 PI/s and one worker completing some jobs.</p>
<p>With that setup we want to verify how it affects the system if now a leader change happens.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected-1">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2021/10/05/recovery-time#expected-1" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>Similar to above expect that if we restart the current leader that a new leader is fast
(under seconds) able to take over and continues the work. The version 1.2 should perform here much
better than 1.1.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual-1">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2021/10/05/recovery-time#actual-1" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<table><thead><tr><th><strong>Version</strong></th><th><strong>1.1</strong></th><th><strong>1.2</strong></th></tr></thead><tbody><tr><td>Recovery</td><td><a target="_blank" href="https://zeebe-io.github.io/zeebe-chaos/assets/files/base-general-state-and-throughput-recover-time-b9c20296a6c02ab22b64a90c8e5b0f3a.png"><img loading="lazy" alt="base-general-state-and-throughput-recover-time.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/base-general-state-and-throughput-recover-time-b9c20296a6c02ab22b64a90c8e5b0f3a.png" width="1192" height="489" class="img_ev3q"></a></td><td><a target="_blank" href="https://zeebe-io.github.io/zeebe-chaos/assets/files/12-general-state-and-throughput-recovery-time-25934f696f3d76a60017fd5c85dda9ea.png"><img loading="lazy" alt="12-general-state-and-throughput-recover-time.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/12-general-state-and-throughput-recovery-time-25934f696f3d76a60017fd5c85dda9ea.png" width="1195" height="487" class="img_ev3q"></a></td></tr><tr><td>General</td><td><a target="_blank" href="https://zeebe-io.github.io/zeebe-chaos/assets/files/base-general-state-and-throughput-recover-general-494ebfac74f239ed6ab1e40c424e6719.png"><img loading="lazy" alt="base-general-state-and-throughput-recover-general.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/base-general-state-and-throughput-recover-general-494ebfac74f239ed6ab1e40c424e6719.png" width="1187" height="953" class="img_ev3q"></a></td><td><a target="_blank" href="https://zeebe-io.github.io/zeebe-chaos/assets/files/12-general-state-and-throughput-recovery-general-803fd268a252c919fb75fd5a0368a6a7.png"><img loading="lazy" alt="12-general-state-and-throughput-recover-general.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/12-general-state-and-throughput-recovery-general-803fd268a252c919fb75fd5a0368a6a7.png" width="1194" height="970" class="img_ev3q"></a></td></tr></tbody></table>
<p>After running the experiment again, this time with load, we can see that the version 1.1 took almost
2 minutes! The newest Zeebe version (1.2), with building state on followers, took ~80 milliseconds!</p>
<p>We can see this much better also in the processing and throughput metrics on version 1.1 we have ~2
minutes gap.</p>
<p><img loading="lazy" alt="base-general-state-and-throughput-recover-general-zoom.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/base-general-state-and-throughput-recover-general-zoom-346e51e9a7d1c8fd37a995dcf13ec030.png" width="1185" height="650" class="img_ev3q"></p>
<p>The exporters can recover a bit faster than the processing, but we are for a while not able to accept
any commands.</p>
<p>In version 1.2 on the other hand we are able to almost immediately continue with the processing, some
metrics are not even able to show a gap in between, like the current events.</p>
<p><img loading="lazy" alt="12-general-state-and-throughput-recover-general-zoom.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/12-general-state-and-throughput-recovery-general-zoom-cbb1fd991e637f0f84eded0bcb33ba3f.png" width="1191" height="680" class="img_ev3q"></p>
<h1>Result</h1>
<p>In general, we were able to show that the new approach of building state on followers, gives us an
excellent benefit in transitioning between Follower and Leader. Furthermore, it allows us to handle
much larger state, since this doesn't need to be replicated on a regular basis.</p>
<h1>Found Bugs</h1>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="running-instances">Running Instances<a href="https://zeebe-io.github.io/zeebe-chaos/2021/10/05/recovery-time#running-instances" class="hash-link" aria-label="Direct link to Running Instances" title="Direct link to Running Instances">​</a></h2>
<p>When experimenting with the clusters, building the state and deploying the steady load I
accidentally deployed to many workers. This caused to complete all existing running instances. The
issues here is that on the new leader the metric is zero, which results in a negative metric.</p>
<p><img loading="lazy" alt="broken-metric" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/broken-metric-11b08dba5d36a8392efda2c2ebe5580d.png" width="1193" height="196" class="img_ev3q"></p>
<p>More problematic is actually that if you than build state again, you might reach the zero and if you
observe the cluster you can't be sure what the actual count of instances are. This makes the metric
kind of useless.</p>
<p><img loading="lazy" alt="broken-metric" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/broken-metric-zero-5d8e95304f288e82921bf536402882d5.png" width="1191" height="825" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance">Performance<a href="https://zeebe-io.github.io/zeebe-chaos/2021/10/05/recovery-time#performance" class="hash-link" aria-label="Direct link to Performance" title="Direct link to Performance">​</a></h2>
<p>During the experimenting it looked like that the performance of 1.2 degraded compared to 1.1. At the
end I had on each benchmark one starter with 100 PI/s and one worker with capacity 12.</p>
<p>With version 1.1 it looked like we reached ~100 PI/s created/completed
<img loading="lazy" alt="base-general-state-and-throughput-recovery-general-perf.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/base-general-state-and-throughput-recovery-general-perf-cfb3b2c8bfa21e6c6499cda6b58d19f0.png" width="1193" height="928" class="img_ev3q"></p>
<p>With version 1.2 we just reached ~30, which means it reduced by factor 3.
<img loading="lazy" alt="12-general-state-and-throughput-recovery-general-perf.png" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/12-general-state-and-throughput-recovery-general-perf-2e3b08a10dd42bd106818643de200518.png" width="1188" height="912" class="img_ev3q"></p>
<p>I think we need to verify whether this is really the case.</p>
<p><strong>Update:</strong></p>
<p>I run again a benchmark for both versions, with one worker and one starter. It showed no significant
difference on throughput.</p>
<table><thead><tr><th><strong>Version</strong></th><th><strong>1.1</strong></th><th><strong>1.2</strong></th></tr></thead><tbody><tr><td>Performance</td><td><a target="_blank" href="https://zeebe-io.github.io/zeebe-chaos/assets/files/perf-11-a3343c029716f6f663f5b3d93db133bc.png"><img loading="lazy" alt="perf-11" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/perf-11-a3343c029716f6f663f5b3d93db133bc.png" width="2468" height="789" class="img_ev3q"></a></td><td><a target="_blank" href="https://zeebe-io.github.io/zeebe-chaos/assets/files/perf-12-92bc1dfd1a0442252e1541a3bd41b310.png"><img loading="lazy" alt="perf-12" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/perf-12-92bc1dfd1a0442252e1541a3bd41b310.png" width="2483" height="786" class="img_ev3q"></a></td></tr></tbody></table>
<p>My current assumption is that it was related to the previous build up state and switching between
different worker configurations etc. Let us see whether we can observe this again.</p>
<p><strong>Update 2:</strong></p>
<p>The second benchmark failed several days again, without any intervention. I investigated that issue further and it seem to be related to frequent install requests, which are sent by the leader. See for more information the related issue <a href="https://github.com/camunda-cloud/zeebe/issues/7955" target="_blank" rel="noopener noreferrer">https://github.com/camunda-cloud/zeebe/issues/7955</a></p>]]></content:encoded>
            <category>availability</category>
        </item>
        <item>
            <title><![CDATA[Old-Clients]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2021/09/23/Old-Clients</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2021/09/23/Old-Clients</guid>
            <pubDate>Thu, 23 Sep 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[It has been awhile since the last post, I'm happy to be back.]]></description>
            <content:encoded><![CDATA[<p>It has been awhile since the last post, I'm happy to be back.</p>
<p>In today's chaos day we want to verify the hypothesis from <a href="https://github.com/zeebe-io/zeebe-chaos/issues/34" target="_blank" rel="noopener noreferrer">zeebe-chaos#34</a> that old
clients can't disrupt a running cluster.</p>
<p>It might happen that after upgrading your Zeebe to the newest shiny version, you might forget to
update some of your workers or starters etc. This should normally not an issue since Zeebe is
backwards compatible, client wise since 1.x. But what happens when older clients are used. Old
clients should not have a negative effect on a running cluster.</p>
<p><strong>TLDR</strong> Older clients (0.26) have no negative impact on a running cluster (1.2), and clients after
1.x are still working with the latest version.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2021/09/23/Old-Clients#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">​</a></h2>
<p>We will run a simple setup with, three nodes and three partitions (replication factor 3). The
version we use is the latest release candidate (1.2.0). Normally we run a load of 200 process
instances per second (pi/s) on our benchmarks. This time we will put a load of 100 pi/s to get
something running and start an old starter (v0.26.x) with the same frequency. Later we will scale
the old starter to see whether it makes any effect.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2021/09/23/Old-Clients#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>We expect that we can start and complete the 100 pi/s, since we can normally run 200 pi/s.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2021/09/23/Old-Clients#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<p>The cluster was first started with starters of the same version, and we saw a stable load of ~100
process instances completed per second. After starting the old starters (with version 0.26.3), we
can't observe any difference.</p>
<p>Interesting is even when scaling the starters up to 10 replicas, which means 1000 PI creations per
second, it doesn't seem to make any effect. <em>Side note:</em> The
<a href="https://github.com/camunda-cloud/zeebe/tree/develop/benchmarks/project" target="_blank" rel="noopener noreferrer">starters</a> have been
modified, such they only start instances without deploying the model.</p>
<p><img loading="lazy" alt="old26-general" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/old26-general-1cbfdf95d7c9b19cad8ca10aa921f34b.png" width="2481" height="992" class="img_ev3q"></p>
<p>The drops we see in the processing are related to restart's.</p>
<p>The gateway and grpc metrics doesn't indicate that more requests are sent.</p>
<p><img loading="lazy" alt="old26-grpc" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/old26-grpc-b5da2bbcf038492c59dea93f36619e69.png" width="2480" height="641" class="img_ev3q">
<img loading="lazy" alt="old26-gateway" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/old26-gateway-dd4afa5333796343795b4d80ad498e6b.png" width="2469" height="650" class="img_ev3q"></p>
<p>If we take a look in the clients log, we can see that the request are failing because the RPC Method names have been changed between 0.26 and 1.0.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">java.util.concurrent.ExecutionException: io.grpc.StatusRuntimeException: UNIMPLEMENTED: Method not found: gateway_protocol.Gateway/CreateWorkflowInstance</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Caused by: io.grpc.StatusRuntimeException: UNIMPLEMENTED: Method not found: gateway_protocol.Gateway/CreateWorkflowInstance</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	...</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>It seems this kind of "old" requests can be blocked quite early in the request chain to make no effect.</p>
<p>In order to experiment a bit further I created a starter image with version 1.0 to see whether this still works with our newest release candidate 1.2.</p>
<p>We can see in the metrics right after starting the starter that the throughput goes up and we can reach our 200 pi/s.</p>
<p><img loading="lazy" alt="old10-general" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/old10-general-90bb179937d9178c12b16f0cdea22281.png" width="2484" height="1000" class="img_ev3q"></p>
<p>We run the benchmark overnight, and we haven't seen any issues. Be aware that the throughput is calculated over the 24h which makes is lower than 200.</p>
<p><img loading="lazy" alt="general" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/general-67c5d494df6c66211457861139475c6c.png" width="2481" height="994" class="img_ev3q"></p>
<p>Furthermore, taking a look at the resource consumption, especially at the gateway, gives no evidence that something wrong is going on.</p>
<p><img loading="lazy" alt="res" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/res-951c069149e3ae14d08a997e6fe974b2.png" width="2473" height="647" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2021/09/23/Old-Clients#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">​</a></h3>
<p>We were able to confirm the hypothesis written in <a href="https://github.com/zeebe-io/zeebe-chaos/issues/34" target="_blank" rel="noopener noreferrer">zeebe-chaos#34</a>, that an old client can't disrupt a running cluster.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="found-bugs">Found Bugs<a href="https://zeebe-io.github.io/zeebe-chaos/2021/09/23/Old-Clients#found-bugs" class="hash-link" aria-label="Direct link to Found Bugs" title="Direct link to Found Bugs">​</a></h2>
<p>None this time :)</p>]]></content:encoded>
            <category>availability</category>
        </item>
        <item>
            <title><![CDATA[Slow Network]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2021/07/06/Slow-Network</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2021/07/06/Slow-Network</guid>
            <pubDate>Tue, 06 Jul 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[On a previous Chaos Day we played around with ToxiProxy , which allows injecting failures on the network level. For example dropping packages, causing latency etc.]]></description>
            <content:encoded><![CDATA[<p>On a previous <a href="https://zeebe-io.github.io/zeebe-chaos/2020/10/06/toxi-proxy">Chaos Day</a> we played around with <a href="https://github.com/Shopify/toxiproxy" target="_blank" rel="noopener noreferrer">ToxiProxy</a> , which allows injecting failures on the network level. For example dropping packages, causing latency etc.</p>
<p>Last week <a href="https://github.com/deepthidevaki" target="_blank" rel="noopener noreferrer">@Deepthi</a> mentioned to me that we can do similar things with <a href="https://man7.org/linux/man-pages/man8/tc.8.html" target="_blank" rel="noopener noreferrer">tc</a>, which is a built-in linux command. Today I wanted to experiment with latency between leader and followers using <code>tc</code>.</p>
<p><strong>TL;DR;</strong> The experiment failed; With adding 100ms network delay to the Leader we broke the complete processing throughput. <!-- -->💥</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2021/07/06/Slow-Network#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">​</a></h2>
<p>We want to experiment with network latency and what kind of effect has a slow network on the cluster.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="hypothesis">Hypothesis<a href="https://zeebe-io.github.io/zeebe-chaos/2021/07/06/Slow-Network#hypothesis" class="hash-link" aria-label="Direct link to Hypothesis" title="Direct link to Hypothesis">​</a></h3>
<p>We expect that we can handle certain network latency, due to our heartbeat and election time timeouts. After, reaching the deadlines we expect fail overs and followers which are lagging behind.</p>
<p>This means under a certain threshold we should be able to still process user commands, with slightly delay but without real issues. After reaching the deadline and the fail overs, it should be possible to continue, since we will add only to one node the delay.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="experiment">Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2021/07/06/Slow-Network#experiment" class="hash-link" aria-label="Direct link to Experiment" title="Direct link to Experiment">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="tc">TC<a href="https://zeebe-io.github.io/zeebe-chaos/2021/07/06/Slow-Network#tc" class="hash-link" aria-label="Direct link to TC" title="Direct link to TC">​</a></h4>
<p>TC is a built in linux command, the manpage summarizes it as <code>tc - show / manipulate traffic control settings</code>.</p>
<p>In order to <a href="https://netbeez.net/blog/how-to-use-the-linux-traffic-control/" target="_blank" rel="noopener noreferrer">add delay to a network interface</a>, we can run the following:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">tc qdisc add dev eth0 root netem delay 200ms</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>More details (<a href="https://netbeez.net/blog/how-to-use-the-linux-traffic-control/" target="_blank" rel="noopener noreferrer">taken from the blog post</a>):</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">qdisc: modify the scheduler (aka queuing discipline)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">add: add a new rule</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dev eth0: rules will be applied on device eth0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">root: modify the outbound traffic scheduler (aka known as the egress qdisc)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">netem: use the network emulator to emulate a WAN property</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">delay: the network property that is modified</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">200ms: introduce delay of 200 ms</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Adding this kind of rule means that we add a delay to all outgoing connections, which are going over this network interface.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2021/07/06/Slow-Network#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h4>
<p>In order to reduce the blast radius we will run the experiment with one partition on a three broker cluster (replication factor 3).</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="steady-state">Steady State<a href="https://zeebe-io.github.io/zeebe-chaos/2021/07/06/Slow-Network#steady-state" class="hash-link" aria-label="Direct link to Steady State" title="Direct link to Steady State">​</a></h5>
<p>As we can see in the benchmark we are able to reach in avg. ~77 process instance creation and completions per second.</p>
<p><img loading="lazy" alt="base" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/general-18fcb0bda36206ab196aeb507a0c1eac.png" width="1194" height="963" class="img_ev3q"></p>
<p>The process instance execution time (from start to end) is under 1 second.
<img loading="lazy" alt="base" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/latency-50564f2ce63c84257c134178924d2c57.png" width="1189" height="636" class="img_ev3q"></p>
<p>The commit latency is about 100 ms.
<img loading="lazy" alt="base" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/commit-lat-9b72095b6933ef77b97f994ece9d17f9.png" width="594" height="265" class="img_ev3q"></p>
<p>We can see that one of the followers is a bit lagging behind, but not too far.</p>
<p><img loading="lazy" alt="base" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/raft-follower-7e8113946fa0a082e57f5ae190a21baa.png" width="1187" height="575" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="100-ms">100 ms<a href="https://zeebe-io.github.io/zeebe-chaos/2021/07/06/Slow-Network#100-ms" class="hash-link" aria-label="Direct link to 100 ms" title="Direct link to 100 ms">​</a></h5>
<p>In the first iteration of the experiment we added a 100 ms delay to the leaders outgoing traffic.</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[zell zell-chaos-day/ cluster: zeebe-cluster ns:zell-chaos-day]$ k exec -it zell-chaos-day-zeebe-gateway-579c76978f-npz2k -- zbctl status --insecure</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Cluster size: 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Partitions count: 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Replication factor: 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Gateway version: 1.1.0-SNAPSHOT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Brokers:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Broker 0 - zell-chaos-day-zeebe-0.zell-chaos-day-zeebe.zell-chaos-day.svc.cluster.local:26501</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Version: 1.1.0-SNAPSHOT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Partition 1 : Follower, Healthy  Broker 1 - zell-chaos-day-zeebe-1.zell-chaos-day-zeebe.zell-chaos-day.svc.cluster.local:26501</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Version: 1.1.0-SNAPSHOT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Partition 1 : Follower, Healthy  Broker 2 - zell-chaos-day-zeebe-2.zell-chaos-day-zeebe.zell-chaos-day.svc.cluster.local:26501</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Version: 1.1.0-SNAPSHOT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Partition 1 : Leader, Healthy</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Based on the <code>zbctl</code> output, or the grafana dashboard we can find out who is the leader. Note that the output of <code>zbctl</code> looks still a bit broken, related issue <a href="https://github.com/camunda-cloud/zeebe/issues/6692" target="_blank" rel="noopener noreferrer">#6692</a>.</p>
<p>With the following commands we can add the delay of 100 ms to the leaders outgoing traffic.</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[zell zell-chaos-day/ cluster: zeebe-cluster ns:zell-chaos-day]$ k exec -it zell-chaos-day-zeebe-2 -- bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">root@zell-chaos-day-zeebe-2:/usr/local/zeebe# tc qdisc add dev eth0 root netem delay 100ms</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">root@zell-chaos-day-zeebe-2:/usr/local/zeebe# tc -s qdisc</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">qdisc noqueue 0: dev lo root refcnt 2 </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> Sent 0 bytes 0 pkt (dropped 0, overlimits 0 requeues 0) </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> backlog 0b 0p requeues 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">qdisc netem 8001: dev eth0 root refcnt 2 limit 1000 delay 100.0ms</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> Sent 11635496 bytes 10086 pkt (dropped 0, overlimits 0 requeues 0) </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> backlog 339773b 77p requeues 0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Almost immediately we see a drop in our general section of the Grafana Dashboard.</p>
<p><img loading="lazy" alt="base" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/100ms-general-a6a99e2144909bf47c029ebcd8543f33.png" width="1196" height="962" class="img_ev3q"></p>
<p>The backpressure increased significantly. As expected the commit latency increased.</p>
<p><img loading="lazy" alt="base" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/100ms-commit-lat-e9f2fb099ca82d84761ef6ffaca428db.png" width="597" height="266" class="img_ev3q"></p>
<p>The processing latency as well.</p>
<p><img loading="lazy" alt="base" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/100ms-latency-85f7dc47d9d5606469244efc363cc638.png" width="1191" height="642" class="img_ev3q"></p>
<p>It was unexpected that the throughput breaks down so much. We can see in the send request that a lot of the requests are ended with timeouts or with resource exhausted.</p>
<p><img loading="lazy" alt="base" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/100ms-grpc-5c44c33e0cfa6d55da14c7cc5092c705.png" width="1187" height="640" class="img_ev3q">
<img loading="lazy" alt="base" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/100ms-gateway-767136da5cb5e9032275d4ee41b05fff.png" width="1191" height="647" class="img_ev3q"></p>
<p>Interesting is that no worker is able to activate nor complete any job. This cause increasing of the running process instances, so the state is growing.</p>
<p><img loading="lazy" alt="base" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/100ms-running-proc-8f4fadc0b12cf5ae463c8f82894c5cd5.png" width="1181" height="419" class="img_ev3q"></p>
<p>Taking a look at the raft metrics we see that this already caused some heartbeat misses, but no leader change.</p>
<p><img loading="lazy" alt="base" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/100ms-heartbeats-1b9a59af419679228f9d703afe1819e9.png" width="1193" height="613" class="img_ev3q"></p>
<p><img loading="lazy" alt="base" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/100ms-follower-93ff4bcec9b9cba018a65268f6f069d0.png" width="1194" height="576" class="img_ev3q"></p>
<p>The follower is now lagging far more behind. We can see in the logs that the Leader tries to send <code>InstallRequests</code>, but these are also timing out.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">RaftServer{raft-partition-partition-1} - InstallRequest{currentTerm=1, leader=2, index=1173627, term=1, version=1, chunkId=HeapByteBuffer{position=0, remaining=10, limit=10, capacity=10, mark=java.nio.HeapByteBuffer[pos=0 lim=10 cap=10], hash=1744147670}, nextChunkId=HeapByteBuffer{position=0, remaining=7, limit=7, capacity=7, mark=java.nio.HeapByteBuffer[pos=0 lim=7 cap=7], hash=1283029304}, data=HeapByteBuffer{position=0, remaining=10626817, limit=10626817, capacity=10626817, mark=java.nio.HeapByteBuffer[pos=0 lim=10626817 cap=10626817], hash=1083445787}, initial=false, complete=false} to 1 failed: java.util.concurrent.CompletionException: java.util.concurrent.TimeoutException: Request ProtocolRequest{id=489616, subject=raft-partition-partition-1-install, sender=zell-chaos-day-zeebe-2.zell-chaos-day-zeebe.zell-chaos-day.svc.cluster.local:26502, payload=byte[]{length=10647731, hash=1655826849}} to zell-chaos-day-zeebe-1.zell-chaos-day-zeebe.zell-chaos-day.svc.cluster.local:26502 timed out in PT5S"</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The follower is starting regularly elections, but is not able to overturn the existing leader.</p>
<p>In general, in the Gateway logs we can see the start of the delay injection quite good.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">D 2021-07-06T10:05:51.263195Z Received REACHABILITY_CHANGED for broker 2, do nothing.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">D 2021-07-06T10:05:53.264480Z Received REACHABILITY_CHANGED for broker 1, do nothing.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">D 2021-07-06T10:05:54.184981Z Received REACHABILITY_CHANGED for broker 2, do nothing.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">D 2021-07-06T10:05:54.213904Z Received REACHABILITY_CHANGED for broker 1, do nothing.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">D 2021-07-06T10:05:54.361408Z Received REACHABILITY_CHANGED for broker 0, do nothing.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">D 2021-07-06T10:05:54.986270Z Received REACHABILITY_CHANGED for broker 0, do nothing.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">D 2021-07-06T10:05:56.617134Z Received REACHABILITY_CHANGED for broker 2, do nothing.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">D 2021-07-06T10:05:57.072707Z Expected to handle gRPC request, but request timed out between gateway and broker</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">D 2021-07-06T10:05:57.126207Z Expected to handle gRPC request, but request timed out between gateway and broker</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">D 2021-07-06T10:05:57.157683Z Expected to handle gRPC request, but request timed out between gateway and broker</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Similar logs we see on the broker side.</p>
<p>In general, we can say the experiment failed. The cluster was not able to run our normal workload. It seem to behave quite bad, but there were no leader change at all.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="250-ms">250 ms<a href="https://zeebe-io.github.io/zeebe-chaos/2021/07/06/Slow-Network#250-ms" class="hash-link" aria-label="Direct link to 250 ms" title="Direct link to 250 ms">​</a></h5>
<p>In order to verify whether 250 ms, will cause a leader election we reconfigured the delay. It looked quite similar, performance wise, but the heartbeats for one of the followers increased. Still it was not enough to cause a leader change.</p>
<p>After several minutes (~30) of running this configuration we were able to observe that one of the other followers missed heartbeats as well. This finally caused a leader change.</p>
<p><img loading="lazy" alt="base" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/250ms-raft-55d2027e863459de3a070d017e813d59.png" width="1204" height="603" class="img_ev3q"></p>
<p>The throughput came back, it was similar to what is was before.</p>
<p><img loading="lazy" alt="base" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/250ms-general-95e282a9fbe58ff95fe883e7d80c2739.png" width="1191" height="964" class="img_ev3q"></p>
<p>The processing execution latency was higher than usual.</p>
<p><img loading="lazy" alt="base" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/250ms-latency-0dd3474f142f7d3642605a2b8353186d.png" width="1187" height="645" class="img_ev3q"></p>
<p>Similar to the commit latency, interesting to see such an affect caused by a follower with network issues.</p>
<p><img loading="lazy" alt="base" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/250ms-commit-lat-0a8e3826a19cdea9b948f42fa639bd6f.png" width="597" height="265" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2021/07/06/Slow-Network#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">​</a></h3>
<p>As written before the experiment failed, the hypothesis was not met. We were not able to add latency to the network, which is much lower than our deadlines (heartbeat timeout is 2.5 seconds), without causing any harm to our processing throughput/latency.</p>
<p>Still we had some interesting observations we can use for our next experiments and insight which we need to consider on setting up Zeebe in environment where the network might be unreliable/slow.</p>]]></content:encoded>
            <category>availability</category>
        </item>
        <item>
            <title><![CDATA[Full Disk Recovery]]></title>
            <link>https://zeebe-io.github.io/zeebe-chaos/2021/06/08/Full-Disk</link>
            <guid>https://zeebe-io.github.io/zeebe-chaos/2021/06/08/Full-Disk</guid>
            <pubDate>Tue, 08 Jun 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[On this chaos day we wanted to experiment with OOD recovery and ELS connection issues. This is related to the following issues from our hypothesis backlog: zeebe-chaos#32 and zeebe-chaos#14. This time @Nico joined me.]]></description>
            <content:encoded><![CDATA[<p>On this chaos day we wanted to experiment with OOD recovery and ELS connection issues. This is related to the following issues from our hypothesis backlog: <a href="https://github.com/zeebe-io/zeebe-chaos/issues/32" target="_blank" rel="noopener noreferrer">zeebe-chaos#32</a> and <a href="https://github.com/zeebe-io/zeebe-chaos/issues/14" target="_blank" rel="noopener noreferrer">zeebe-chaos#14</a>. This time <a href="https://github.com/korthout" target="_blank" rel="noopener noreferrer">@Nico</a> joined me.</p>
<p><strong>TL;DR</strong> The experiment was successful <!-- -->💪<!-- --> and we found several things in the dashboard which we can improve :)</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chaos-experiment">Chaos Experiment<a href="https://zeebe-io.github.io/zeebe-chaos/2021/06/08/Full-Disk#chaos-experiment" class="hash-link" aria-label="Direct link to Chaos Experiment" title="Direct link to Chaos Experiment">​</a></h2>
<p>With this experiment we want to verify that Zeebe can recover after OOD, which was caused by not exporting to ELS. For that we want to disconnect Zeebe and ELS first and see how it behaves. Afterwards we connect the services again and expect a recovery of the system.</p>
<p>As usual, we have set up a normal benchmark cluster with three nodes, three partitions and replication factor three. We run 200 PI/s and 12 workers against that cluster.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expected">Expected<a href="https://zeebe-io.github.io/zeebe-chaos/2021/06/08/Full-Disk#expected" class="hash-link" aria-label="Direct link to Expected" title="Direct link to Expected">​</a></h3>
<p>We expect the following properties:</p>
<ul>
<li>at the beginning the system is stable (we can start instances without issues)</li>
<li>after disconnecting ELS we start to fill the disk, since we can't export (which means we can't compact)</li>
<li>after reaching the disk limits, Zeebe doesn't accept any commands anymore</li>
<li>after connecting ELS, Zeebe should start to export again (compacting should be possible again)</li>
<li>after come below the limit, Zeebe should accept commands again</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="network-disconnect-to-els">Network disconnect to ELS<a href="https://zeebe-io.github.io/zeebe-chaos/2021/06/08/Full-Disk#network-disconnect-to-els" class="hash-link" aria-label="Direct link to Network disconnect to ELS" title="Direct link to Network disconnect to ELS">​</a></h4>
<p>In order to disconnect the Brokers with ELS, we wanted to reuse one of our network disconnect scripts, e.g. <a href="https://github.com/zeebe-io/zeebe-chaos/blob/master/chaos-experiments/scripts/disconnect-leaders.sh" target="_blank" rel="noopener noreferrer">disconnect-leaders.sh</a>. This resolves the IP's of the brokers and creates an unreachable route via the <code>ip</code> tool at the given brokers.</p>
<p>We copied that and adjusted it to our needs:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#!/bin/bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">set -exuo pipefail</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">source utils.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">partition=1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">namespace=$(getNamespace)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticName="elasticsearch-master"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">broker0=$(getBroker 0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">broker2=$(getBroker 2)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">broker1=$(getBroker 1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elastic0Ip=$(kubectl get pod "$elasticName-0" -n "$namespace" --template="{{.status.podIP}}")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elastic1Ip=$(kubectl get pod "$elasticName-1" -n "$namespace" --template="{{.status.podIP}}")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elastic2Ip=$(kubectl get pod "$elasticName-2" -n "$namespace" --template="{{.status.podIP}}")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># we put all into one function because we need to make sure that even after preemption the </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># dependency is installed</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">function disconnect() {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> toChangedPod="$1"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> targetIp="$2"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> # update to have access to ip</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> kubectl exec -n "$namespace" "$toChangedPod" -- apt update</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> kubectl exec -n "$namespace" "$toChangedPod" -- apt install -y iproute2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> kubectl exec "$toChangedPod" -n "$namespace" -- ip route add unreachable "$targetIp"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">retryUntilSuccess disconnect "$broker0" "$elastic0Ip"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">retryUntilSuccess disconnect "$broker0" "$elastic1Ip"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">retryUntilSuccess disconnect "$broker0" "$elastic2Ip"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">retryUntilSuccess disconnect "$broker1" "$elastic0Ip"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">retryUntilSuccess disconnect "$broker1" "$elastic1Ip"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">retryUntilSuccess disconnect "$broker1" "$elastic2Ip"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">retryUntilSuccess disconnect "$broker2" "$elastic0Ip"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">retryUntilSuccess disconnect "$broker2" "$elastic1Ip"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">retryUntilSuccess disconnect "$broker2" "$elastic2Ip"</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><em>Small note in order to run this against the benchmark cluster you need to set the following environment variables:</em></p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">export NAMESPACE=$(kubens -c) # the namespace where the resources are located</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export CHAOS_SETUP=helm # indicates that the installation is done via helm, necessary since we use different labels in the helm charts and in CC.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Running the script above didn't work as expected. We still saw records being exported. The issue was that we need to use the service IP instead of the IP's of the elastic search pods. The Broker uses only the service to connect with ELS. In order to get the IP we can use this <code>kubectl get services elasticsearch-master --template "{{.spec.clusterIP}}"</code>.</p>
<p>The service will take care of the request routing, which means we just need to block one IP. This helps to simplify the disconnect script.</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#!/bin/bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">set -exuo pipefail</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">source utils.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">partition=1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">namespace=$(getNamespace)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticName="elasticsearch-master"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">broker0=$(getBroker 0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">broker2=$(getBroker 2)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">broker1=$(getBroker 1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elasticServiceIp=$(kubectl get services elasticsearch-master --template "{{.spec.clusterIP}}")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># we put all into one function because we need to make sure that even after preemption the </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># dependency is installed</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">function disconnect() {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> toChangedPod="$1"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> targetIp="$2"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> # update to have access to ip</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> kubectl exec -n "$namespace" "$toChangedPod" -- apt update</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> kubectl exec -n "$namespace" "$toChangedPod" -- apt install -y iproute2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> kubectl exec "$toChangedPod" -n "$namespace" -- ip route add unreachable "$targetIp"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">retryUntilSuccess disconnect "$broker0" "$elasticServiceIp"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">retryUntilSuccess disconnect "$broker1" "$elasticServiceIp"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">retryUntilSuccess disconnect "$broker2" "$elasticServiceIp"</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="actual">Actual<a href="https://zeebe-io.github.io/zeebe-chaos/2021/06/08/Full-Disk#actual" class="hash-link" aria-label="Direct link to Actual" title="Direct link to Actual">​</a></h3>
<p>In this section we will describe how we experienced the chaos experiment and what we observed.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="first-try">First Try<a href="https://zeebe-io.github.io/zeebe-chaos/2021/06/08/Full-Disk#first-try" class="hash-link" aria-label="Direct link to First Try" title="Direct link to First Try">​</a></h4>
<p>We run the disconnect script and were able to observe that the exporting stopped.</p>
<p><img loading="lazy" alt="elastic-disconnect" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/elastic-disconnect-5638a32fadfab9b778b02fe14a1d3ed7.png" width="1195" height="961" class="img_ev3q"></p>
<p>As expected we were no longer able to compact, which cause an increasing of log segments.</p>
<p><img loading="lazy" alt="increase-segments" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/increase-segments-bd8431b8424f7c0b8fb0d44307c2ab42.png" width="598" height="311" class="img_ev3q"></p>
<p>We realized that our current disk size might be too big (it would take a while until we fill it), so we decided to setup a new benchmark with smaller size and different watermarks.</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># ...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">env</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">value</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"0.6"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ZEEBE_BROKER_DATA_DISKUSAGEREPLICATIONWATERMARK</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">value</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"0.8"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># PVC</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">pvcAccessMode</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">"ReadWriteOnce"</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">pvcSize</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> 16Gi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">pvcStorageClassName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ssd</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We thought that we might have different performance, because of such a smaller disk size, but this was not the case. We were able to reach the same level, might be worth to think about reducing the disk sizes more in our benchmarks.</p>
<p><img loading="lazy" alt="base" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/next-try-base-12b9f5871392bd43fe1f31224479aa6d.png" width="1198" height="919" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="second-try">Second Try<a href="https://zeebe-io.github.io/zeebe-chaos/2021/06/08/Full-Disk#second-try" class="hash-link" aria-label="Direct link to Second Try" title="Direct link to Second Try">​</a></h4>
<p><img loading="lazy" alt="base1" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/next-try-base1-649226bc28407a654bad7078dca639a0.png" width="1189" height="911" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="disconnecting">Disconnecting<a href="https://zeebe-io.github.io/zeebe-chaos/2021/06/08/Full-Disk#disconnecting" class="hash-link" aria-label="Direct link to Disconnecting" title="Direct link to Disconnecting">​</a></h5>
<p>After running our disconnect script we can immediately see that the exporting is stopping.</p>
<p><img loading="lazy" alt="drop-base" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/next-try-drop-base-4fe3db248fb58bb7fdfef0b08e8b8cd1.png" width="1195" height="912" class="img_ev3q"></p>
<p>Interesting is the elastic section where we see one of our new panels in actions which shows the failure rate. There are two dots, which show the 100% failure rate.</p>
<p><img loading="lazy" alt="drop-elastic" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/next-try-drop-elastic-section-3e81b323923abc8ed78de26765ad9cfe.png" width="1190" height="795" class="img_ev3q"></p>
<p>After reaching our disk watermark we can see that the processing stops, and we no longer accept commands.</p>
<p><img loading="lazy" alt="drop-base-2" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/next-try-drop-base-2-908ab8f573d0460900504da7b122c5e9.png" width="1195" height="906" class="img_ev3q"></p>
<p>The cluster turns to unhealthy, which is expected.</p>
<p>Interesting is that we have no metrics at all on the gateway side after reaching the watermark.</p>
<p><img loading="lazy" alt="drop-gw" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/next-try-drop-gw-a0e7f885194b47559bb07c6ad46942d0.png" width="1198" height="642" class="img_ev3q"></p>
<p>We were able to verify that snapshots are still taken, but no compaction.</p>
<p><img loading="lazy" alt="drop-snapshot" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/next-try-drop-snapshot-d38bd5b1657f7b5a4fa763b26ebba239.png" width="1182" height="637" class="img_ev3q"></p>
<p>No segments are deleted during this time.</p>
<p><img loading="lazy" alt="drop-segments" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/next-try-drop-segments-3d49aaadb3d3455c25a920281a6c9595.png" width="1189" height="613" class="img_ev3q"></p>
<p>If we take a look at the processing section we can see that the exporters lag way behind, which of course makes sense.</p>
<p><img loading="lazy" alt="drop-processing" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/next-try-drop-processing-4dc3f1fafd42d2e6560cde27e53a3aa2.png" width="1187" height="410" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="connecting">Connecting<a href="https://zeebe-io.github.io/zeebe-chaos/2021/06/08/Full-Disk#connecting" class="hash-link" aria-label="Direct link to Connecting" title="Direct link to Connecting">​</a></h5>
<p>Luckily we were able to reuse on of our already written reconnect scripts for this experiment, see <a href="https://github.com/zeebe-io/zeebe-chaos/blob/master/chaos-experiments/scripts/connect-leaders.sh" target="_blank" rel="noopener noreferrer">connect-leaders.sh</a>.</p>
<p>After removing the ip route (connecting the Brokers with ELS again) we can see that it immediately starts to export again.</p>
<p><img loading="lazy" alt="connect-base" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/next-try-connect-base-dfe3501b990f198861825cec2fb00735.png" width="1196" height="913" class="img_ev3q"></p>
<p>When we went under the disk watermarks the processing started again and we accepted new commands.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="result">Result<a href="https://zeebe-io.github.io/zeebe-chaos/2021/06/08/Full-Disk#result" class="hash-link" aria-label="Direct link to Result" title="Direct link to Result">​</a></h3>
<p><img loading="lazy" alt="connect-base2" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/next-try-connect-base2-375310b94ccc02fe3333b76954351a44.png" width="1197" height="959" class="img_ev3q"></p>
<p><strong>The experiment was successful, our system was able to recover after an elastic network outage and handled it properly.</strong> <!-- -->✅<!-- --> <!-- -->💪</p>
<p>We noted several issues with the Dashboard, during the chaos experiment observation. For example the Brokers, which went OOD, never went back to the <code>Healthy</code> state again.</p>
<p><img loading="lazy" alt="connect-healthy" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/next-try-connect-healthy-124040b24b536d608e5c1d94eebabbc6.png" width="1185" height="865" class="img_ev3q"></p>
<p>Furthermore, the not exported panel seems to be broken, depending on the selected time frame.</p>
<p><img loading="lazy" alt="connect-not-exported" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/next-try-connect-not-exported-afa9d7092c5a219305b92e807e874d06.png" width="1188" height="409" class="img_ev3q"></p>
<p>There have been also other issues with the panels and sections which we should take a look at. I have listed them below.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="possible-improvements">Possible Improvements<a href="https://zeebe-io.github.io/zeebe-chaos/2021/06/08/Full-Disk#possible-improvements" class="hash-link" aria-label="Direct link to Possible Improvements" title="Direct link to Possible Improvements">​</a></h3>
<p>We observed several issues with the grafana dashboard which I wrote down here. I will create issues or PR's to resolve them.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="general-metric-section">General Metric Section<a href="https://zeebe-io.github.io/zeebe-chaos/2021/06/08/Full-Disk#general-metric-section" class="hash-link" aria-label="Direct link to General Metric Section" title="Direct link to General Metric Section">​</a></h4>
<p>If we take a look at the screenshot where we reach our disk watermarks, and the processing stops, the backpressure metrics are not correctly updated. We would expect that the backpressure shows 100%, since all requests are rejected.</p>
<p><img loading="lazy" alt="drop-base-2" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/next-try-drop-base-2-908ab8f573d0460900504da7b122c5e9.png" width="1195" height="906" class="img_ev3q"></p>
<p>After the cluster actually becomes healthy again (it accepts new commands) it is not shown as healthy in the panels. The metrics seems not to be updated.</p>
<p>Another possible improvement would be to make it more visible that the exporting stopped. One idea is to split the processing into exporting and processing, so having two graphs might help.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="processing-section">Processing Section<a href="https://zeebe-io.github.io/zeebe-chaos/2021/06/08/Full-Disk#processing-section" class="hash-link" aria-label="Direct link to Processing Section" title="Direct link to Processing Section">​</a></h4>
<p>Depending on the time frame the panel <code>Number of records not exported</code>, seems to show quite high values.</p>
<p><img loading="lazy" alt="connect-not-exported" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/next-try-connect-not-exported-afa9d7092c5a219305b92e807e874d06.png" width="1188" height="409" class="img_ev3q"></p>
<p>If we take a look at other metrics, this doesn't make any sense. If we had such a backlog we wouldn't expect to compact to one segment for example. Furthemore the tables on the right side show numbers which are quite close to each other.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="elastic-metrics-section">Elastic Metrics Section<a href="https://zeebe-io.github.io/zeebe-chaos/2021/06/08/Full-Disk#elastic-metrics-section" class="hash-link" aria-label="Direct link to Elastic Metrics Section" title="Direct link to Elastic Metrics Section">​</a></h4>
<p>We probably can improve the failure panel, such that it shows a graph, and the limit is not set to 130%.</p>
<p><img loading="lazy" alt="drop-elastic" src="https://zeebe-io.github.io/zeebe-chaos/assets/images/next-try-drop-elastic-section-3e81b323923abc8ed78de26765ad9cfe.png" width="1190" height="795" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="grpc-metric-section">GRPC Metric Section<a href="https://zeebe-io.github.io/zeebe-chaos/2021/06/08/Full-Disk#grpc-metric-section" class="hash-link" aria-label="Direct link to GRPC Metric Section" title="Direct link to GRPC Metric Section">​</a></h4>
<p>The panel <code>gRPC requests</code> should have an dec ordering on the tooltip and should be renamed to <code>Total gRPC requests</code> it was a bit confusing to us.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="throughput-section">Throughput Section<a href="https://zeebe-io.github.io/zeebe-chaos/2021/06/08/Full-Disk#throughput-section" class="hash-link" aria-label="Direct link to Throughput Section" title="Direct link to Throughput Section">​</a></h4>
<p>The StreamProcessor vs Exporter panel has no data.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="snapshot-section">Snapshot Section<a href="https://zeebe-io.github.io/zeebe-chaos/2021/06/08/Full-Disk#snapshot-section" class="hash-link" aria-label="Direct link to Snapshot Section" title="Direct link to Snapshot Section">​</a></h4>
<p>We saw that snapshots are created, but the Snapshot replication panel show no data. It seem to be broken (again?).</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="resources-section">Resources Section<a href="https://zeebe-io.github.io/zeebe-chaos/2021/06/08/Full-Disk#resources-section" class="hash-link" aria-label="Direct link to Resources Section" title="Direct link to Resources Section">​</a></h4>
<p>The JVM panel has the legend on the right side, which makes it hard to see the metrics if you have multiple windows open on one screen.</p>]]></content:encoded>
            <category>availability</category>
        </item>
    </channel>
</rss>