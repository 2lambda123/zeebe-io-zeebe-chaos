"use strict";(self.webpackChunkzell_chaos=self.webpackChunkzell_chaos||[]).push([[2620],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>m});var n=a(7294);function s(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){s(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function r(e,t){if(null==e)return{};var a,n,s=function(e,t){if(null==e)return{};var a,n,s={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(s[a]=e[a]);return s}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(s[a]=e[a])}return s}var l=n.createContext({}),c=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},p=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},h="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,s=e.mdxType,i=e.originalType,l=e.parentName,p=r(e,["components","mdxType","originalType","parentName"]),h=c(a),u=s,m=h["".concat(l,".").concat(u)]||h[u]||d[u]||i;return a?n.createElement(m,o(o({ref:t},p),{},{components:a})):n.createElement(m,o({ref:t},p))}));function m(e,t){var a=arguments,s=t&&t.mdxType;if("string"==typeof e||s){var i=a.length,o=new Array(i);o[0]=u;var r={};for(var l in t)hasOwnProperty.call(t,l)&&(r[l]=t[l]);r.originalType=e,r[h]="string"==typeof e?e:s,o[1]=r;for(var c=2;c<i;c++)o[c]=a[c];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},955:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>i,metadata:()=>r,toc:()=>c});var n=a(7462),s=(a(7294),a(3905));const i={layout:"posts",title:"Continuing SST Partitioning toggle",date:new Date("2023-05-19T00:00:00.000Z"),categories:["chaos_experiment","configuration"],tags:["availability","data"],authors:"zell"},o="Chaos Day Summary",r={permalink:"/zeebe-chaos/2023/05/19/Continuing-SST-Partitioning-toggle",editUrl:"https://github.com/zeebe-io/zeebe-chaos/blob/master/chaos-days/blog/2023-05-19-Continuing-SST-Partitioning-toggle/index.md",source:"@site/blog/2023-05-19-Continuing-SST-Partitioning-toggle/index.md",title:"Continuing SST Partitioning toggle",description:"Today we want to continue with the experiment from last Chaos day, but this time",date:"2023-05-19T00:00:00.000Z",formattedDate:"May 19, 2023",tags:[{label:"availability",permalink:"/zeebe-chaos/tags/availability"},{label:"data",permalink:"/zeebe-chaos/tags/data"}],readingTime:8.105,hasTruncateMarker:!0,authors:[{name:"Christopher Zell",title:"Chaos Engineer @ Zeebe",url:"https://github.com/zelldon",imageURL:"https://github.com/zelldon.png",key:"zell"}],frontMatter:{layout:"posts",title:"Continuing SST Partitioning toggle",date:"2023-05-19T00:00:00.000Z",categories:["chaos_experiment","configuration"],tags:["availability","data"],authors:"zell"},nextItem:{title:"SST Partitioning toggle",permalink:"/zeebe-chaos/2023/05/15/SST-Partitioning-toggle"}},l={authorsImageUrls:[void 0]},c=[{value:"Chaos Experiment",id:"chaos-experiment",level:2},{value:"Expected",id:"expected",level:3},{value:"Actual",id:"actual",level:3},{value:"First Experiment: Verify Steady state",id:"first-experiment-verify-steady-state",level:4},{value:"First Experiment: Chaos Action",id:"first-experiment-chaos-action",level:4},{value:"First Experiment: Verify Steady state",id:"first-experiment-verify-steady-state-1",level:4},{value:"Second Experiment: Chaos Action",id:"second-experiment-chaos-action",level:4},{value:"Second Experiment: Verify Steady state",id:"second-experiment-verify-steady-state",level:4},{value:"SST Partitioning and compaction",id:"sst-partitioning-and-compaction",level:4},{value:"Conclusion",id:"conclusion",level:2},{value:"Found Bugs",id:"found-bugs",level:2}],p={toc:c},h="wrapper";function d(e){let{components:t,...i}=e;return(0,s.kt)(h,(0,n.Z)({},p,i,{components:t,mdxType:"MDXLayout"}),(0,s.kt)("p",null,"Today we want to continue with the experiment from ",(0,s.kt)("a",{parentName:"p",href:"/zeebe-chaos/2023/05/15/SST-Partitioning-toggle"},"last Chaos day"),", but this time\nwith a bit more load. This should make sure that we trigger the compaction of RocksDB and cause the SST partitioning to happen, for real."),(0,s.kt)("p",null,"The reasons stay the same we want to find out whether it would be possible to enable and disable the flag/configuration without issues."),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"TL;DR;")," Today's, experiments succeeded \ud83d\ude80. We were able to show that even with a higher number of process instances (bigger state) we can easily disable and enable the SST partitioning flag without issues. I also got a confirmation from a RocksDb contributor that our observations are correct, and that we can easily toggle this feature without issues."),(0,s.kt)("h2",{id:"chaos-experiment"},"Chaos Experiment"),(0,s.kt)("p",null,"Similar setup to the ",(0,s.kt)("a",{parentName:"p",href:"/zeebe-chaos/2023/05/15/SST-Partitioning-toggle#chaos-experiment"},"last Chaos day"),".\nExcept this time we will enable Operate as well, in order to verify easily whether all instances have been completed.\nOther than that we use the standard benchmark configuration, without clients."),(0,s.kt)("p",null,"The verification of the steady state will consist, of checking the readiness and healthiness of the cluster, via zbchaos and metrics. Furthermore, we will verify that we can access operate and that no instances are running. As defined in chaos engineering principles the process of a chaos experiment looks always the same, Verify the steady state, introduce chaos, and verify the steady state."),(0,s.kt)("p",null,"In our first experiment, we will enable the SST partitioning."),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"First chaos action")),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"Deploy a process model (which contains a ",(0,s.kt)("a",{parentName:"li",href:"https://github.com/zeebe-io/zeebe-chaos/blob/main/go-chaos/internal/bpmn/one_task.bpmn"},"simple model"),")"),(0,s.kt)("li",{parentName:"ul"},"Start 1000 process instances (PIs), with a service task"),(0,s.kt)("li",{parentName:"ul"},"Enable the SST partitioning"),(0,s.kt)("li",{parentName:"ul"},"Restart the cluster, and await readiness"),(0,s.kt)("li",{parentName:"ul"},"Complete the jobs (in consequence the PIs)")),(0,s.kt)("p",null,"In our second experiment, we will disable the SST partitioning again."),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"Second chaos action:")),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"Start 1000 process instances (PIs), with a service task"),(0,s.kt)("li",{parentName:"ul"},"Disable the SST partitioning"),(0,s.kt)("li",{parentName:"ul"},"Restart the cluster, and await readiness"),(0,s.kt)("li",{parentName:"ul"},"Complete the jobs (in consequence the PIs)")),(0,s.kt)("h3",{id:"expected"},"Expected"),(0,s.kt)("blockquote",null,(0,s.kt)("p",{parentName:"blockquote"},"When operating a cluster, I can enable and disable the SST partitioning without an impact on executing existing process instances. Existing PIs should still be executable and completable.")),(0,s.kt)("h3",{id:"actual"},"Actual"),(0,s.kt)("p",null,"As linked above I used again our ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/camunda/zeebe/tree/main/benchmarks/setup"},"benchmark/setup")," scripts to set up a cluster."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-shell"},'$ diff ../default/values.yaml values.yaml \n40c40\n<   replicas: 3\n---\n>   replicas: 0\n47c47\n<   replicas: 1\n---\n>   replicas: 0\n85a86\n>     zeebe.broker.experimental.rocksdb.enableSstPartitioning: "false"\n96a98,100\n>     identity:\n>       auth:\n>         enabled: false\n326c330\n<     enabled: false\n---\n>     enabled: true\n')),(0,s.kt)("h4",{id:"first-experiment-verify-steady-state"},"First Experiment: Verify Steady state"),(0,s.kt)("p",null,"To verify the readiness and run all actions I used the ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/zeebe-io/zeebe-chaos/tree/zbchaos-v1.0.0"},"zbchaos")," tool."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-shell"},"$ zbchaos verify readiness\nAll Zeebe nodes are running.\n")),(0,s.kt)("p",null,"Looking at the metrics shows that everything looks healthy. The only weird part is the topology panel which seems to be broken.\n",(0,s.kt)("img",{alt:"start",src:a(2531).Z,width:"1853",height:"906"})),(0,s.kt)("p",null,"When requesting the topology via ",(0,s.kt)("inlineCode",{parentName:"p"},"zbchaos")," we retrieve this:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-shell"},"$ zbchaos topology\n{1 LEADER -1  10  msg false 1 LEADER -1 2 LEADER -1 1684476531915 false false true false false 30 false -1 benchmark 30  }\nNode      |Partition 1         |Partition 2         |Partition 3\n1         |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)    |FOLLOWER (HEALTHY)\n0         |LEADER (HEALTHY)    |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)\n2         |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)\n")),(0,s.kt)("p",null,"For now, we assume the dashboard has an issue and continue with the experiment."),(0,s.kt)("p",null,"We are able to access operate without issues, and see no instances yet."),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"operate",src:a(8665).Z,width:"1901",height:"752"})),(0,s.kt)("h4",{id:"first-experiment-chaos-action"},"First Experiment: Chaos Action"),(0,s.kt)("p",null,"After the verification stage, we start with our chaos action, injecting chaos into the system.\nThe first step is to deploy the mentioned simple process model:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-shell"},"$ zbchaos deploy process -v\nConnecting to zell-chaos\nRunning experiment in self-managed environment.\nPort forward to zell-chaos-zeebe-gateway-7bbdf9fd58-dl97j\nSuccessfully created port forwarding tunnel\nDeploy file bpmn/one_task.bpmn (size: 2526 bytes).\nDeployed process model bpmn/one_task.bpmn successful with key 2251799813685249.\nDeployed given process model , under key 2251799813685249!\n")),(0,s.kt)("p",null,"This is then as well visible in operate."),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"operate-process",src:a(2279).Z,width:"1091",height:"503"})),(0,s.kt)("p",null,"As the next step, we will create 1000 process instances of our simple process model, with one service task.\nFor that, we can ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/zeebe-io/zeebe-chaos/tree/zell-chaos-create-count-of-instances"},"use a new functionality")," of ",(0,s.kt)("inlineCode",{parentName:"p"},"zbchaos")," I built for this chaos day."),(0,s.kt)("p",null,"On the first try, I had smaller issues, with timeouts etc."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-shell"},"Send create process instance command, with BPMN process ID 'benchmark' and version '-1' (-1 means latest) [variables: '', awaitResult: false]\n[299/999] Created process instance with key 6755399441056339 on partition 3.\npanic: Expected to create 999 process instances, but timed out after 30s created 299 instances.\n")),(0,s.kt)("p",null,"This is the reason why I had to retry the creations in the end the count is not exactly 1000 :)"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-shell"},"./dist/zbchaos verify instance-count --instanceCount 697 -v --timeoutInSec 300\n...\n[695/697] Created process instance with key 4503599627372489 on partition 2.\nSend create process instance command, with BPMN process ID 'benchmark' and version '-1' (-1 means latest) [variables: '', awaitResult: false]\n[696/697] Created process instance with key 6755399441057737 on partition 3.\nSend create process instance command, with BPMN process ID 'benchmark' and version '-1' (-1 means latest) [variables: '', awaitResult: false]\n[697/697] Created process instance with key 2251799813687255 on partition 1.\nThe steady state was successfully verified!\n")),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"pi",src:a(4168).Z,width:"1905",height:"510"})),(0,s.kt)("p",null,"Now we are coming to the interesting part. Enabling SST partitioning."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-shell"},'$ diff ../default/values.yaml values.yaml \n85a86\n>     zeebe.broker.experimental.rocksdb.enableSstPartitioning: "true"\n$ make update \nhelm upgrade --namespace zell-chaos zell-chaos zeebe-benchmark/zeebe-benchmark -f values.yaml\n')),(0,s.kt)("blockquote",null,(0,s.kt)("p",{parentName:"blockquote"},(0,s.kt)("strong",{parentName:"p"},"Note"),"\nChanging the configmap doesn't restart pods! We need to delete all Zeebe pods, to apply the configuration.")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-shell"},'$ k delete pod -l app=camunda-platform\npod "zell-chaos-zeebe-0" deleted\npod "zell-chaos-zeebe-1" deleted\npod "zell-chaos-zeebe-2" deleted\npod "zell-chaos-zeebe-gateway-7bbdf9fd58-8j7d6" deleted\npod "zell-chaos-zeebe-gateway-7bbdf9fd58-dl97j" deleted\n')),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-shell"},"$ zbchaos verify readiness \nAll Zeebe nodes are running.\n")),(0,s.kt)("p",null,"Now starting to complete the previously created jobs, we can use again a new feature in ",(0,s.kt)("inlineCode",{parentName:"p"},"zbchaos")," (",(0,s.kt)("a",{parentName:"p",href:"https://github.com/zeebe-io/zeebe-chaos/tree/zell-chaos-create-count-of-instances"},"which has been added during the chaos day"),")\nUnfortunately, I missed using the verbose flag."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-shell"},"$ ./dist/zbchaos verify job-completion --jobCount 1001 --timeoutInSec 1200\nThe steady-state was successfully verified!\n")),(0,s.kt)("h4",{id:"first-experiment-verify-steady-state-1"},"First Experiment: Verify Steady state"),(0,s.kt)("p",null,"The job completions worked without issues. The metrics are looking good, the topology panel seems to work again as well."),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"complete",src:a(4692).Z,width:"1845",height:"894"})),(0,s.kt)("p",null,"In operate we can see that there are no longer any running instances and all of them have been completed."),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"complete-operate",src:a(5750).Z,width:"1894",height:"500"}),"\n",(0,s.kt)("img",{alt:"complete-operate2",src:a(8171).Z,width:"1887",height:"793"})),(0,s.kt)("p",null,"The first part of the experiment worked as expected \u2705"),(0,s.kt)("h4",{id:"second-experiment-chaos-action"},"Second Experiment: Chaos Action"),(0,s.kt)("p",null,"We are skipping the verification step, due to previous verification, we directly start with creating 1000 process instances."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"$ ./dist/zbchaos verify instance-count --instanceCount 1000 -v --timeoutInSec 300\n\nSend create process instance command, with BPMN process ID 'benchmark' and version '-1' (-1 means latest) [variables: '', awaitResult: false]\n[1000/1000] Successful command sent, got response with key 2251799813690599 on partition 1.\nThe steady-state was successfully verified!\n")),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"second",src:a(2642).Z,width:"1890",height:"892"})),(0,s.kt)("p",null,"Disable the SST partitioning flag and update the cluster."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-shell"},"$ make update \n$ k delete pod -l app=camunda-platform\n$ zbchaos verify readiness\nAll Zeebe nodes are running.\n")),(0,s.kt)("p",null,"Complete all jobs:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-shell"},"$ ./dist/zbchaos verify job-completion --jobCount 1000 --timeoutInSec 1200 -v\n[999/1000] Successful command sent, got response with key 6755399441061073 on partition 3.\nSend job activate command, with job type 'benchmark-task'\n[1000/1000] Successful command sent, got response with key 2251799813690604 on partition 1.\nThe steady-state was successfully verified!\n")),(0,s.kt)("h4",{id:"second-experiment-verify-steady-state"},"Second Experiment: Verify Steady state"),(0,s.kt)("p",null,"Again the experiment succeeded, we were able to show that even with a higher number of process instances we can easily disable and enable the SST partitioning flag."),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"verify",src:a(1602).Z,width:"1840",height:"892"}),"\n",(0,s.kt)("img",{alt:"op-complete",src:a(6904).Z,width:"1087",height:"614"})),(0,s.kt)("p",null,"In the snapshots at we can see that some more files are used."),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"snap",src:a(2638).Z,width:"878",height:"850"})),(0,s.kt)("p",null,"But in RocksDb metrics we see no real compaction going on, which is why we will retry the same with a higher amount of data."),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"rocks",src:a(973).Z,width:"884",height:"422"})),(0,s.kt)("h4",{id:"sst-partitioning-and-compaction"},"SST Partitioning and compaction"),(0,s.kt)("p",null,"I tried to run the experiment again but with more data (~11K instances)."),(0,s.kt)("p",null,"Even when the metrics don't show the compaction, I was able to see in the RocksDB that compacting is happening."),(0,s.kt)("p",null,"Around 11:56 between different loads"),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"thirdrun",src:a(9090).Z,width:"1849",height:"891"})),(0,s.kt)("p",null,"We see in the metrics of RocksDB that nothing"),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"rocks",src:a(3787).Z,width:"1860",height:"451"})),(0,s.kt)("p",null,"But when checking the RocksDB logs"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},'$ cat data/raft-partition/partitions/1/runtime/LOG.old.1684493206724692 \n...\n\n2023/05/19-09:56:40.652111 140580419004160  Options.sst_partitioner_factory: SstPartitionerFixedPrefixFactory\n\n...\n2023/05/19-09:56:41.354244 140579153618688 (Original Log Time 2023/05/19-09:56:41.354149) EVENT_LOG_v1 {"time_micros": 1684490201354123, "job": 2, "event": "compaction_finished", "compaction_time_micros": 374078, "compaction_time_cpu_micros": 72361, "output_level": 3, "num_output_files": 14, "total_output_size": 6283132, "num_input_records": 69787, "num_output_records": 39118, "num_subcompactions": 1, "output_compression": "NoCompression", "num_single_delete_mismatches": 0, "num_single_delete_fallthrough": 0, "lsm_state": [0, 0, 0, 14]}\n2023/05/19-09:56:41.354763 140579153618688 [le/delete_scheduler.cc:77] Deleted file /usr/local/zeebe/data/raft-partition/partitions/1/runtime/000045.sst immediately, rate_bytes_per_sec 0, total_trash_size 0 max_trash_db_ratio 0.250000\n2023/05/19-09:56:41.354786 140579153618688 EVENT_LOG_v1 {"time_micros": 1684490201354782, "job": 2, "event": "table_file_deletion", "file_number": 45}\n2023/05/19-09:56:41.355217 140579153618688 [le/delete_scheduler.cc:77] Deleted file /usr/local/zeebe/data/raft-partition/partitions/1/runtime/000044.sst immediately, rate_bytes_per_sec 0, total_trash_size 0 max_trash_db_ratio 0.250000\n2023/05/19-09:56:41.355247 140579153618688 EVENT_LOG_v1 {"time_micros": 1684490201355243, "job": 2, "event": "table_file_deletion", "file_number": 44}\n2023/05/19-09:56:41.355765 140579153618688 [le/delete_scheduler.cc:77] Deleted file /usr/local/zeebe/data/raft-partition/partitions/1/runtime/000043.sst immediately, rate_bytes_per_sec 0, total_trash_size 0 max_trash_db_ratio 0.250000\n')),(0,s.kt)("p",null,"We see several lines which indicate the compaction."),(0,s.kt)("h2",{id:"conclusion"},"Conclusion"),(0,s.kt)("p",null," We have seen that even when we toggle the SST partitioning, we are able to make progress and our stored data is not impacted. This is a great out come since it means we can easily enable such configuration on existing clusters and gains the performance benefits for larger states as we have seen in previous benchmarks."),(0,s.kt)("p",null,"I have posted a question related to this topic in the ",(0,s.kt)("a",{parentName:"p",href:"https://groups.google.com/g/rocksdb/c/Ys-yZIznZwU"},"RocksDb google group")," and I got a private answer which contains the following:"),(0,s.kt)("blockquote",null,(0,s.kt)("p",{parentName:"blockquote"},"Partitioner is just a hinter when compaction should split the file. Default compaction is also splitting by file size. So it has no functional effect and you can change configuration anytime."),(0,s.kt)("p",{parentName:"blockquote"},"Partitioner does not need to be simple prefix only, but one can use more complicated strategy.")),(0,s.kt)("p",null,"This confirms our observation and makes it much more trustworthy."),(0,s.kt)("h2",{id:"found-bugs"},"Found Bugs"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"Grafana Topology Panel seems to be buggy from time to time"),(0,s.kt)("li",{parentName:"ul"},"RocksDB compaction panel seems to show no data (might be related to a short time frame)")))}d.isMDXComponent=!0},3787:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/compacting-16d643497e24f39e3aef93cabb91a0b7.png"},4692:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/metrics-complete-6a55f56851581c51bf703a1431d75c3b.png"},5750:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/operate-complete-d4f703e6d9711b157856fd244294999a.png"},8171:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/operate-complete2-9a77531ed33a8b2a74c2d2b4bf5ff090.png"},4168:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/operate-pi-14b1db18f29dfd9c2858179dde92da41.png"},2279:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/operate-process-c2f4b5eac01d3b5334749518b3ed7eed.png"},8665:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/operate-c8609205a0832ffb0852c1c14c527e7e.png"},6904:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/second-exp-operate-complete-fb1b93e473c3b44f74af441a0758c6e0.png"},973:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/second-exp-rocks-ad699b1447a827a6cadc97e38b7e4536.png"},2638:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/second-exp-snap-619bf47a82dce280aed6013c81dde883.png"},1602:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/second-exp-verify-027ddb4d82b084f1da4fb7cf0804cd31.png"},2642:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/second-exp-e3fd7780bec7f168375839276a153572.png"},2531:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/start-bfbabb5034107afa1b8f0a19e81c72eb.png"},9090:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/thirdrun-d169e0524892c8521172f5d181e3c59d.png"}}]);