"use strict";(self.webpackChunkzell_chaos=self.webpackChunkzell_chaos||[]).push([[9158],{3905:function(e,t,n){n.d(t,{Zo:function(){return h},kt:function(){return u}});var a=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var c=a.createContext({}),l=function(e){var t=a.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},h=function(e){var t=l(e.components);return a.createElement(c.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},p=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,c=e.parentName,h=i(e,["components","mdxType","originalType","parentName"]),p=l(n),u=o,m=p["".concat(c,".").concat(u)]||p[u]||d[u]||r;return n?a.createElement(m,s(s({ref:t},h),{},{components:n})):a.createElement(m,s({ref:t},h))}));function u(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,s=new Array(r);s[0]=p;var i={};for(var c in t)hasOwnProperty.call(t,c)&&(i[c]=t[c]);i.originalType=e,i.mdxType="string"==typeof e?e:o,s[1]=i;for(var l=2;l<r;l++)s[l]=n[l];return a.createElement.apply(null,s)}return a.createElement.apply(null,n)}p.displayName="MDXCreateElement"},357:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return i},contentTitle:function(){return c},metadata:function(){return l},assets:function(){return h},toc:function(){return d},default:function(){return u}});var a=n(7462),o=n(3366),r=(n(7294),n(3905)),s=["components"],i={layout:"posts",title:"Message Correlation after Network Partition",date:new Date("2022-08-31T00:00:00.000Z"),categories:["chaos_experiment","bpmn"],tags:["availability"],authors:"zell"},c="Chaos Day Summary",l={permalink:"/zeebe-chaos/2022/08/31/Message-Correlation-after-Network-Partition",editUrl:"https://github.com/zeebe-io/zeebe-chaos/blob/master/chaos-days/blog/2022-08-31-Message-Correlation-after-Network-Partition/index.md",source:"@site/blog/2022-08-31-Message-Correlation-after-Network-Partition/index.md",title:"Message Correlation after Network Partition",description:"In the last weeks, we made several changes in our core components, we introduce some new abstractions, and changed how we communicate between partitions.",date:"2022-08-31T00:00:00.000Z",formattedDate:"August 31, 2022",tags:[{label:"availability",permalink:"/zeebe-chaos/tags/availability"}],readingTime:9.97,truncated:!0,authors:[{name:"Christopher Zell",title:"Chaos Engineer @ Zeebe",url:"https://github.com/zelldon",imageURL:"https://github.com/zelldon.png",key:"zell"}],nextItem:{title:"Bring Deployment distribution experiment back",permalink:"/zeebe-chaos/2022/08/02/deployment-distribution"}},h={authorsImageUrls:[void 0]},d=[{value:"Chaos Experiment",id:"chaos-experiment",children:[{value:"Expected",id:"expected",children:[]},{value:"Actual",id:"actual",children:[]}]},{value:"Found Bugs",id:"found-bugs",children:[]}],p={toc:d};function u(e){var t=e.components,i=(0,o.Z)(e,s);return(0,r.kt)("wrapper",(0,a.Z)({},p,i,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"In the last weeks, we made several changes in our core components, we introduce some new abstractions, and changed how we communicate between partitions."),(0,r.kt)("p",null,"Due to these changes, we thought it might make sense to run some more chaos experiments in that direction and area since our benchmarks also recently found some interesting edge cases."),(0,r.kt)("p",null,"Today we experimented with Message Correlation and what happens when a network partition disturbs the correlation process."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"TL;DR;")," The experiment was partially successful (after retry), we were able to publish messages during a network partition that have been correlated after the network partition. We need to verify whether we can also publish messages before a network partition and during the partition create the related instances."),(0,r.kt)("h2",{id:"chaos-experiment"},"Chaos Experiment"),(0,r.kt)("p",null,"The experiment is related to our previously described ",(0,r.kt)("a",{parentName:"p",href:"/zeebe-chaos/2022/08/02/deployment-distribution"},"deployment distribution experiment"),"."),(0,r.kt)("p",null,"When a user/client publishes a message, the message will be sent to a certain partition, based on the correlation key. There is some calculation going on related to the hashcode and the partition count.\nThis calculation is deterministic in order to find later the message again if we reach a message catch event."),(0,r.kt)("p",null,"A message can specify a time-to-live (TTL), ",(0,r.kt)("a",{parentName:"p",href:"https://docs.camunda.io/docs/components/concepts/messages/#message-buffering"},"which allows buffering that message"),". If later a process instance is created and the TTL is not exceeded the message can be still correlated. The creation of process instances\nhappens round-robin on the existing/available partitions (this is controlled by the gateway). When a process instance is created and reaches a message catch event it will be based on the correlation key search for a message on the expected partition. ",(0,r.kt)("em",{parentName:"p"},"Actually this happens based on subscriptions, for more details see the ",(0,r.kt)("a",{parentName:"em",href:"https://docs.camunda.io/docs/components/concepts/messages/#message-subscriptions"},"docs")," or the ",(0,r.kt)("a",{parentName:"em",href:"https://github.com/zeebe-io/enhancements/blob/master/ZEP004-wf-stream-processing.md#message-intermediate-catch-event"},"ZEP-4"),".")," If the message still exists (TTL didn't expire) and this message ",(0,r.kt)("a",{parentName:"p",href:"https://docs.camunda.io/docs/components/concepts/messages/#message-cardinality"},"wasn't already correlated to the same process definition")," then it will be correlated."),(0,r.kt)("p",null,"Since both partitions can be on different leader nodes this requires some network communication, which can be interrupted/disturbed."),(0,r.kt)("h3",{id:"expected"},"Expected"),(0,r.kt)("p",null,"We expect that if the network between the partition where the message was published and where the process instance was created is interrupted that no message correlation happens. But after the network recovers, we expect further that the message will be correlated and the process instance can continue."),(0,r.kt)("h3",{id:"actual"},"Actual"),(0,r.kt)("p",null,"As a setup, I installed our benchmarks, with Operate enabled.\nThis allows us to also view the details in Operate."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"$ diff zeebe-values.yaml ../default/zeebe-values.yaml \n5,8d4\n<   identity:\n<     auth:\n<       enabled: false\n< \n28c24\n<   containerSecurityContext:\n---\n>   podSecurityContext:\n139c135\n<   enabled: true\n---\n>   enabled: false\n")),(0,r.kt)("p",null,"During the experiment, it turned out that the ",(0,r.kt)("inlineCode",{parentName:"p"},"podSecurityContext")," is outdated."),(0,r.kt)("h4",{id:"experiment-description"},"Experiment Description"),(0,r.kt)("p",null,"Since we want to automate this experiment soon, or later I thought it would be a good idea to use the ",(0,r.kt)("a",{parentName:"p",href:"https://docs.camunda.io/docs/components/concepts/process-instance-creation/#create-and-await-results"},"create process instance with result"),". We would start the following process:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"msg-catch",src:n(2260).Z})),(0,r.kt)("p",null,"Before we start the process we need to publish the message to a certain partition and create a network partition between two partitions. After that, we can create the PI and verify that the message correlation shouldn't happen. Afterward, we would delete the network partition and verify that the process instance is completed."),(0,r.kt)("h4",{id:"details"},"Details"),(0,r.kt)("p",null,"To make the experiment easier to reproduce and allow us to experiment in different directions later as well I extend our new chaos cli (zbchaos), which I created during the last hack days. I will write a separate blog post about this tool soon."),(0,r.kt)("h5",{id:"message-publish"},"Message Publish"),(0,r.kt)("p",null,"I added a new feature (",(0,r.kt)("a",{parentName:"p",href:"https://github.com/zeebe-io/zeebe-chaos/pull/166"},"PR #166"),") that allows us to publish a message to a specific partition:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"$ ./zbchaos publish message -v --partitionId 3\nConnecting to zell-chaos\nSuccessfully created port forwarding tunnel\nSend message 'msg', with correaltion key '2' (ASCII: 50) \nMessage was sent and returned key 6755399441055796, which corresponds to partition: 3\n")),(0,r.kt)("h5",{id:"extend-steady-state-verification"},"Extend Steady-state verification"),(0,r.kt)("p",null,"For the steady-state verification, multiple enhancements have been added."),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Previously the ",(0,r.kt)("inlineCode",{parentName:"li"},"zbchaos")," didn't allow us to create instances of specific models, which is now added as new feature (",(0,r.kt)("a",{parentName:"li",href:"https://github.com/zeebe-io/zeebe-chaos/pull/167"},"PR #167"),")."),(0,r.kt)("li",{parentName:"ol"},"In order to await the process instance completion a new flag was added ",(0,r.kt)("inlineCode",{parentName:"li"},"--awaitResult"),", which allows us to await the PI completeness."),(0,r.kt)("li",{parentName:"ol"},"To make sure that our message can be correlated we have to set the right correlationKey/value. This means we need to create instances with certain variables, which is now possible as well (",(0,r.kt)("inlineCode",{parentName:"li"},"--variables"),").")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"./zbchaos verify steady-state -h\nVerifies the steady state of the Zeebe system.\nA process model will be deployed and process instances are created until the required partition is reached.\n\nUsage:\n  zbchaos verify steady-state [flags]\n\nFlags:\n      --awaitResult               Specify whether the completion of the created process instance should be awaited.\n  -h, --help                      help for steady-state\n      --partitionId int           Specify the id of the partition (default 1)\n      --processModelPath string   Specify the path to a BPMN process model, which should be deployed and an instance should be created of.\n      --variables string          Specify the variables for the process instance. Expect json string.\n\nGlobal Flags:\n  -v, --verbose   verbose output\n\n")),(0,r.kt)("h4",{id:"execution-of-the-experiment"},"Execution of the Experiment"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"$./zbchaos verify readiness -v\nConnecting to zell-chaos\nAll Zeebe nodes are running.\n")),(0,r.kt)("p",null,"After checking the readiness we can check what the current topology is:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"$ ./zbchaos topology\nNode      |Partition 1         |Partition 2         |Partition 3\n0         |LEADER (HEALTHY)    |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)\n1         |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)    |FOLLOWER (HEALTHY)\n2         |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)\n")),(0,r.kt)("p",null,"We can see that the leaders are well distributed. I pick partition 3 as our message publish partition, and partition 1 as our partition for the process instance. Since we can't control really the round-robin mechanism, we need to create multiple messages and multiple process instances (for each partition). During our experiment, we will only look at the instance on partition one."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"$ ./zbchaos publish message -v --partitionId 3\nConnecting to zell-chaos\nSuccessfully created port forwarding tunnel\nSend message 'msg', with correaltion key '2' (ASCII: 50) \nMessage was sent and returned key 6755399441055745, which corresponds to partition: 3\n[zell go-chaos/ cluster: zeebe-cluster ns:zell-chaos]$ ./zbchaos publish message -v --partitionId 3\nConnecting to zell-chaos\nSuccessfully created port forwarding tunnel\nSend message 'msg', with correaltion key '2' (ASCII: 50) \nMessage was sent and returned key 6755399441055746, which corresponds to partition: 3\n[zell go-chaos/ cluster: zeebe-cluster ns:zell-chaos]$ ./zbchaos publish message -v --partitionId 3\nConnecting to zell-chaos\nSuccessfully created port forwarding tunnel\nSend message 'msg', with correaltion key '2' (ASCII: 50) \nMessage was sent and returned key 6755399441055747, which corresponds to partition: 3\n")),(0,r.kt)("p",null,"Creating the network partition:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},'./zbchaos disconnect brokers --broker1PartitionId 3 --broker1Role LEADER --broker2PartitionId 1 --broker2Role LEADER -v\n...\nSuccessfully created port forwarding tunnel\nFound Broker zell-chaos-zeebe-2 as LEADER for partition 3.\nFound Broker zell-chaos-zeebe-0 as LEADER for partition 1.\nExecute ["apt" "-qq" "update"] on pod zell-chaos-zeebe-2\n...\nDisconnect zell-chaos-zeebe-2 from zell-chaos-zeebe-0\n...\nDisconnect zell-chaos-zeebe-0 from zell-chaos-zeebe-2\n')),(0,r.kt)("p",null,"Creating the process instance and await the result:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},'$ ./zbchaos verify steady-state --awaitResult --partitionId 1 --processModelPath ../msg-catch.bpmn --variables \'{"key":"2"}\'\n\n\n')),(0,r.kt)("p",null,"Unfortunately, I missed the verbose flag so we can't really see the output. But if failed later with:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"Encountered an error during process instance creation. Error: rpc error: code = DeadlineExceeded desc = Time out between gateway and broker: Request ProtocolRequest{id=422, subject=command-api-1, sender=10.0.20.4:26502, payload=byte[]{length=153, hash=1559826040}} to zell-chaos-zeebe-2.zell-chaos-zeebe.zell-chaos.svc:26501 timed out in PT15S\nEncountered an error during process instance creation. Error: rpc error: code = DeadlineExceeded desc = Time out between gateway and broker: Request ProtocolRequest{id=441, subject=command-api-2, sender=10.0.20.4:26502, payload=byte[]{length=153, hash=-1786651527}} to zell-chaos-zeebe-1.zell-chaos-zeebe.zell-chaos.svc:26501 timed out in PT15S\nEncountered an error during process instance creation. Error: rpc error: code = NotFound desc = Command 'CREATE_WITH_AWAITING_RESULT' rejected with code 'NOT_FOUND': Expected to find process definition with key '2251799813685249', but none found\npanic: Expected to create process instance on partition 1, but timed out after 30s.\n\ngoroutine 1 [running]:\ngithub.com/zeebe-io/zeebe-chaos/go-chaos/cmd.glob..func10(0x247f740?, {0x1758c60?, 0x7?, 0x7?})\n    /home/zell/goPath/src/github.com/zeebe-io/zeebe-chaos/go-chaos/cmd/verify.go:97 +0x1c5\ngithub.com/spf13/cobra.(*Command).execute(0x247f740, {0xc000426540, 0x7, 0x7})\n    /home/zell/goPath/pkg/mod/github.com/spf13/cobra@v1.5.0/command.go:876 +0x67b\ngithub.com/spf13/cobra.(*Command).ExecuteC(0x24808c0)\n    /home/zell/goPath/pkg/mod/github.com/spf13/cobra@v1.5.0/command.go:990 +0x3bd\ngithub.com/spf13/cobra.(*Command).Execute(...)\n    /home/zell/goPath/pkg/mod/github.com/spf13/cobra@v1.5.0/command.go:918\ngithub.com/zeebe-io/zeebe-chaos/go-chaos/cmd.Execute()\n    /home/zell/goPath/src/github.com/zeebe-io/zeebe-chaos/go-chaos/cmd/root.go:61 +0x25\nmain.main()\n    /home/zell/goPath/src/github.com/zeebe-io/zeebe-chaos/go-chaos/main.go:8 +0x17\n")),(0,r.kt)("p",null,"I retried it:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},'$ ./zbchaos verify steady-state --awaitResult --partitionId 1 --processModelPath ../msg-catch.bpmn --variables \'{"key":"2"}\' -v\nConnecting to zell-chaos\nSuccessfully created port forwarding tunnel\nDeploy file ../msg-catch.bpmn (size: 2980 bytes).\nDeployed process model ../msg-catch.bpmn successful with key 2251799813685249.\nCreate process instance with defition key 2251799813685249 [variables: \'{"key":"2"}\', awaitResult: true]\nEncountered an error during process instance creation. Error: rpc error: code = DeadlineExceeded desc = Time out between gateway and broker: Request ProtocolRequest{id=509, subject=command-api-1, sender=10.0.20.4:26502, payload=byte[]{length=153, hash=1559826040}} to zell-chaos-zeebe-2.zell-chaos-zeebe.zell-chaos.svc:26501 timed out in PT15S\nCreate process instance with defition key 2251799813685249 [variables: \'{"key":"2"}\', awaitResult: true]\nEncountered an error during process instance creation. Error: rpc error: code = DeadlineExceeded desc = Time out between gateway and broker: Request ProtocolRequest{id=530, subject=command-api-2, sender=10.0.20.4:26502, payload=byte[]{length=153, hash=-1786651527}} to zell-chaos-zeebe-1.zell-chaos-zeebe.zell-chaos.svc:26501 timed out in PT14.999S\nCreate process instance with defition key 2251799813685249 [variables: \'{"key":"2"}\', awaitResult: true]\nEncountered an error during process instance creation. Error: rpc error: code = NotFound desc = Command \'CREATE_WITH_AWAITING_RESULT\' rejected with code \'NOT_FOUND\': Expected to find process definition with key \'2251799813685249\', but none found\npanic: Expected to create process instance on partition 1, but timed out after 30s.\n\ngoroutine 1 [running]:\ngithub.com/zeebe-io/zeebe-chaos/go-chaos/cmd.glob..func10(0x247f740?, {0x1758c60?, 0x8?, 0x8?})\n    /home/zell/goPath/src/github.com/zeebe-io/zeebe-chaos/go-chaos/cmd/verify.go:97 +0x1c5\ngithub.com/spf13/cobra.(*Command).execute(0x247f740, {0xc00007e500, 0x8, 0x8})\n    /home/zell/goPath/pkg/mod/github.com/spf13/cobra@v1.5.0/command.go:876 +0x67b\ngithub.com/spf13/cobra.(*Command).ExecuteC(0x24808c0)\n    /home/zell/goPath/pkg/mod/github.com/spf13/cobra@v1.5.0/command.go:990 +0x3bd\ngithub.com/spf13/cobra.(*Command).Execute(...)\n    /home/zell/goPath/pkg/mod/github.com/spf13/cobra@v1.5.0/command.go:918\ngithub.com/zeebe-io/zeebe-chaos/go-chaos/cmd.Execute()\n    /home/zell/goPath/src/github.com/zeebe-io/zeebe-chaos/go-chaos/cmd/root.go:61 +0x25\nmain.main()\n    /home/zell/goPath/src/github.com/zeebe-io/zeebe-chaos/go-chaos/main.go:8 +0x17\n')),(0,r.kt)("p",null,"And got a similar exception. Taking a look at Operate we can see that process instances are created. It is likely that the await timed out since the message hasn't been correlated but the returned error is a bit unclear. Interesting is that on partition two the message is also not correlated."),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"operate",src:n(5707).Z})),(0,r.kt)("p",null,"Removing the network partition:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},'$ ./zbchaos connect brokers -v\nConnecting to zell-chaos\nExecute ["sh" "-c" "command -v ip"] on pod zell-chaos-zeebe-0\n/usr/sbin/ip\nExecute ["sh" "-c" "ip route | grep -m 1 unreachable"] on pod zell-chaos-zeebe-0\nExecute ["sh" "-c" "ip route del unreachable 10.0.17.8"] on pod zell-chaos-zeebe-0\nConnected zell-chaos-zeebe-0 again, removed unreachable routes.\nExecute ["sh" "-c" "command -v ip"] on pod zell-chaos-zeebe-1\nError on connection Broker: zell-chaos-zeebe-1. Error: Execution exited with exit code 127 (Command not found). It is likely that the broker was not disconnected or restarted in between.\nExecute ["sh" "-c" "command -v ip"] on pod zell-chaos-zeebe-2\nError on connection Broker: zell-chaos-zeebe-2. Error: Execution exited with exit code 127 (Command not found). It is likely that the broker was not disconnected or restarted in between.\n')),(0,r.kt)("p",null,"It looks like the Broker-2 was restarted in between, which is really the case if we check the ",(0,r.kt)("inlineCode",{parentName:"p"},"kubectl get pods")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"[zell go-chaos/ cluster: zeebe-cluster ns:zell-chaos]$ kgpo\nNAME                                        READY   STATUS      RESTARTS   AGE\ncamunda-platform-curator-27698835-pwdjh     0/1     Completed   0          9m20s\nelasticsearch-master-0                      1/1     Running     0          12m\nelasticsearch-master-1                      1/1     Running     0          12m\nelasticsearch-master-2                      1/1     Running     0          12m\nzell-chaos-operate-64bbc6794d-vqtnc         1/1     Running     0          12m\nzell-chaos-zeebe-0                          1/1     Running     0          12m\nzell-chaos-zeebe-1                          1/1     Running     0          12m\nzell-chaos-zeebe-2                          1/1     Running     0          2m48s\nzell-chaos-zeebe-gateway-795f87fd64-c9mf4   1/1     Running     0          12m\nzell-chaos-zeebe-gateway-795f87fd64-h5d9c   1/1     Running     0          12m\nzell-chaos-zeebe-gateway-795f87fd64-nlr5v   1/1     Running     0          12m\n")),(0,r.kt)("p",null,"The topology has also completely changed."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"$ ./zbchaos topology\nNode      |Partition 1         |Partition 2         |Partition 3\n0         |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)\n1         |LEADER (HEALTHY)    |FOLLOWER (HEALTHY)  |FOLLOWER (HEALTHY)\n2         |FOLLOWER (HEALTHY)  |LEADER (HEALTHY)    |FOLLOWER (HEALTHY)\n")),(0,r.kt)("p",null,"After connecting again the instances haven't been executed. My guess is that the TTL was already reached."),(0,r.kt)("h5",{id:"rerun"},"Rerun"),(0,r.kt)("p",null,"I will disconnect again partitions one and three and publish a message to partition three. Afterward I will connect them again and see whether the message is correlated."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"./zbchaos disconnect brokers --broker1PartitionId 3 --broker1Role LEADER --broker2PartitionId 1 --broker2Role LEADER -v\n./zbchaos publish message -v --partitionId 3\n./zbchaos publish message -v --partitionId 3\n./zbchaos publish message -v --partitionId 3\n./zbchaos connect brokers -v\n")),(0,r.kt)("p",null,"Take a look at Operate again:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"operate2",src:n(751).Z})),(0,r.kt)("p",null,"We can see that the experiment was successful, and the message has been correlated even if they are published during a network partition. \ud83c\udf89"),(0,r.kt)("h2",{id:"found-bugs"},"Found Bugs"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"I learned that the go zeebe client, doesn't set a default TTL which was interesting to find out (and somehow unexpected)."),(0,r.kt)("li",{parentName:"ul"},"The zbchaos uses always the same port for connecting to the kubernetes and zeebe cluster, which makes it impossible to run multiple commands. We should use random ports to make this possible.")))}u.isMDXComponent=!0},2260:function(e,t,n){t.Z=n.p+"assets/images/msg-catch-dba2526317c719b66db25ef1dfaff2a4.png"},5707:function(e,t,n){t.Z=n.p+"assets/images/operate-efd0c9d98a1666f44bf235ba5bf4cdf2.png"},751:function(e,t,n){t.Z=n.p+"assets/images/operate2-c96a932956d4207bff7ce70f78cb7544.png"}}]);