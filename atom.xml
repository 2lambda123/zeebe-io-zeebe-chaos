<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://zeebe-io.github.io/zeebe-chaos/</id>
    <title>Zeebe Chaos Blog</title>
    <updated>2021-10-29T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://zeebe-io.github.io/zeebe-chaos/"/>
    <subtitle>Zeebe Chaos Blog</subtitle>
    <icon>https://zeebe-io.github.io/zeebe-chaos/img/zeebe-logo.png</icon>
    <entry>
        <title type="html"><![CDATA[Throughput on big state]]></title>
        <id>Throughput on big state</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2021/10/29/Throughput-on-big-state"/>
        <updated>2021-10-29T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[In this chaos day we wanted to prove the hypothesis that the throughput should not significantly change even if we have bigger state, see zeebe-chaos#64]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Recovery (Fail Over) time]]></title>
        <id>Recovery (Fail Over) time</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2021/10/05/recovery-time"/>
        <updated>2021-10-05T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[In the last quarter we worked on a new "feature" which is called "building state on followers". In short,]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Old-Clients]]></title>
        <id>Old-Clients</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2021/09/23/Old-Clients"/>
        <updated>2021-09-23T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[It has been awhile since the last post, I'm happy to be back.]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Slow Network]]></title>
        <id>Slow Network</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2021/07/06/Slow-Network"/>
        <updated>2021-07-06T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[On a previous Chaos Day we played around with ToxiProxy , which allows injecting failures on the network level. For example dropping packages, causing latency etc.]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Full Disk Recovery]]></title>
        <id>Full Disk Recovery</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2021/06/08/Full-Disk"/>
        <updated>2021-06-08T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[On this chaos day we wanted to experiment with OOD recovery and ELS connection issues. This is related to the following issues from our hypothesis backlog: zeebe-chaos#32 and zeebe-chaos#14. This time @Nico joined me.]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Time travel Experiment]]></title>
        <id>Time travel Experiment</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2021/05/25/Reset-Clock"/>
        <updated>2021-05-25T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Recently we run a Game day where a lot of messages with high TTL have been stored in the state. This was based on an earlier incident, which we had seen in production. One suggested approach to resolve that incident was to increase the time, such that all messages are removed from the state. This and the fact that summer and winter time shifts can cause in other systems evil bugs, we wanted to find out how our system can handle time shifts. Phil joined me as participant and observer. There was a related issue which covers this topic as well, zeebe-chaos#3.]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Corrupted Snapshot Experiment Investigation]]></title>
        <id>Corrupted Snapshot Experiment Investigation</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2021/04/29/Corrupted-Snapshot"/>
        <updated>2021-04-29T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[A while ago we have written an experiment, which should verify that followers are not able to become leader, if they have a corrupted snapshot. You can find that specific experiment here. This experiment was executed regularly against Production-M and Production-S Camunda Cloud cluster plans. With the latest changes, in the upcoming 1.0 release, we changed some behavior in regard to detect snapshot corruption on followers.]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BPMN meets Chaos Engineering]]></title>
        <id>BPMN meets Chaos Engineering</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2021/04/03/bpmn-meets-chaos-engineering"/>
        <updated>2021-04-03T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[On the first of April (2021) we ran our Spring Hackday at Camunda. This is an event where the developers at camunda come together to work on projects they like or on new ideas/approaches they want to try out. This time we (Philipp and me) wanted to orchestrate our Chaos Experiments with BPMN. If you already know how we automated our chaos experiments before, you can skip the next section]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Set file immutable]]></title>
        <id>Set file immutable</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2021/03/30/set-file-immutable"/>
        <updated>2021-03-30T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[This chaos day was a bit different. Actually I wanted to experiment again with camunda cloud and verify that our high load chaos experiments are now working with the newest cluster plans, see zeebe-cluster-testbench#135.]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Camunda Cloud network partition]]></title>
        <id>Camunda Cloud network partition</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2021/03/23/camunda-cloud-network-partition"/>
        <updated>2021-03-23T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[This time Deepthi was joining me on my regular Chaos Day.]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fault-tolerant processing of process instances]]></title>
        <id>Fault-tolerant processing of process instances</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2021/03/09/cont-workflow-instance"/>
        <updated>2021-03-09T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Today I wanted to add another chaos experiment, to increase our automated chaos experiments collection. This time we will deploy a process model (with timer start event), restart a node and complete the process instance via zbctl.]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Automating Deployment Distribution Chaos Experiment]]></title>
        <id>Automating Deployment Distribution Chaos Experiment</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2021/02/23/automate-deployments-dist"/>
        <updated>2021-02-23T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[This time I wanted to automate a chaos experiment via the ChaosToolkit, which I did on the last chaos day. For a recap check out the last chaos day summary.]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deployment Distribution]]></title>
        <id>Deployment Distribution</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2021/01/26/deployments"/>
        <updated>2021-01-26T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[On this chaos day we wanted to experiment a bit with deployment's and there distribution.]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Network partitions]]></title>
        <id>Network partitions</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2021/01/19/network-partition"/>
        <updated>2021-01-19T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[As you can see, I migrated the old chaos day summaries to github pages, for better readability.]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Disconnect Leader and one Follower]]></title>
        <id>Disconnect Leader and one Follower</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2021/01/07/disconnect-leader-and-follower"/>
        <updated>2021-01-07T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Happy new year everyone]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Message Correlation after Failover]]></title>
        <id>Message Correlation after Failover</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2020/11/24/message-correlation-after-failover"/>
        <updated>2020-11-24T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Today I wanted to finally implement an experiment which I postponed for long time, see #24.]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Many Job Timeouts]]></title>
        <id>Many Job Timeouts</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2020/11/11/job-timeouts"/>
        <updated>2020-11-11T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[In the last game day (on friday 06.11.2020) I wanted to test whether we can break a partition if many messages time out at the same time. What I did was I send many many messages with a decreasing TTL, which all targeting a specific point in time, such that they will all timeout at the same time. I expected that if this happens that the processor will try to time out all at once and break because the batch is to big. Fortunately this didn't happen, the processor was able to handle this.]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Investigate failing Chaos Tests]]></title>
        <id>Investigate failing Chaos Tests</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2020/11/03/investigate-failing-tests"/>
        <updated>2020-11-03T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Today as part of the Chaos Day I wanted to investigate why our current Chaos Tests are failing and why our targeting cluster has been broken by them,]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Non-graceful Shutdown Broker]]></title>
        <id>Non-graceful Shutdown Broker</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2020/10/20/non-graceful-shutdown"/>
        <updated>2020-10-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Today I had not much time for the chaos day, because of writing Gameday Summary, Incident review, taking part of incidents etc. So enough chaos for one day :)]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gateway memory consumption]]></title>
        <id>Gateway memory consumption</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2020/10/27/standalone-gw-memory"/>
        <updated>2020-10-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[In the last weeks I check multiple benchmarks and clusters in incidents. Often I had the feeling that the memory consumption from the gateway is not ideal]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multiple Leader Changes]]></title>
        <id>Multiple Leader Changes</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2020/10/13/multiple-leader-changes"/>
        <updated>2020-10-13T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Today I wanted to add new chaostoolkit experiment, which we can automate.]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Play around with ToxiProxy]]></title>
        <id>Play around with ToxiProxy</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2020/10/06/toxi-proxy"/>
        <updated>2020-10-06T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[First chaos day since my parental leave.]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Experiment with Camunda Cloud]]></title>
        <id>Experiment with Camunda Cloud</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2020/08/20/experiment-with-camunda-cloud"/>
        <updated>2020-08-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[In order to make our chaos experiments more realistic we have setup a new gke cluster, which is similar to the Camunda Cloud gke cluster.]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Experiment with Low Load]]></title>
        <id>Experiment with Low Load</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2020/08/06/low-load"/>
        <updated>2020-08-06T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[* Run a benchmark with low load]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Experiment without Exporters]]></title>
        <id>Experiment without Exporters</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2020/07/30/experiment-without-exporters"/>
        <updated>2020-07-30T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[* Run a chaos experiment without exporters]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Big Multi Instance]]></title>
        <id>Big Multi Instance</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2020/07/16/big-multi-instance"/>
        <updated>2020-07-16T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[* investigate and fix automated chaos experiments - works again with 88c404f and cd8d685]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Experiment with Timers and Huge Variables]]></title>
        <id>Experiment with Timers and Huge Variables</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2020/07/09/timer-and-huge-variables"/>
        <updated>2020-07-09T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[* Failure documentation about RAFT]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Extract K8 resources from namespace]]></title>
        <id>Extract K8 resources from namespace</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2020/07/02/extract-k8-resources"/>
        <updated>2020-07-02T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[* Research: Read about DiRT (Disaster Recovery Tests) @ google - gave me same new ideas for more game days]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gateway Network Partition]]></title>
        <id>Gateway Network Partition</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2020/06/25/gateway-network-partition"/>
        <updated>2020-06-25T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[* Documented failure cases for AsyncSnasphortDirector. Gave me some ideas where it might make sense to reinstall partition. Discussed a bit with @Deepthi]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Correlate Message after failover]]></title>
        <id>Correlate Message after failover</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2020/06/18/correlate-message-after-failover"/>
        <updated>2020-06-18T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[* Documented failure cases for engine and stream processor. I think almost all possible failure cases I can think of we already handle, except problems on reading, which I think can't be handled.]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[High CPU load on Standalone Gateway]]></title>
        <id>High CPU load on Standalone Gateway</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2020/06/11/high-cpu-gateway"/>
        <updated>2020-06-11T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[* Updated failure cases documentation for exporter based on review]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[First Chaos Day!]]></title>
        <id>First Chaos Day!</id>
        <link href="https://zeebe-io.github.io/zeebe-chaos/2020/06/04/first-chaos-day"/>
        <updated>2020-06-04T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[First Chaos day]]></summary>
        <author>
            <name>Christopher Zell</name>
            <uri>https://github.com/zelldon</uri>
        </author>
    </entry>
</feed>